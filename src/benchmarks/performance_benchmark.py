"""
ç»¼åˆæ€§èƒ½åŸºå‡†æµ‹è¯•å’Œåˆ†æå·¥å…·
æä¾›è®­ç»ƒã€æ¨ç†ã€æ•°æ®åŠ è½½ç­‰å„æ–¹é¢çš„æ€§èƒ½æµ‹è¯•å’Œä¼˜åŒ–å»ºè®®
"""
import os
import time
import json
import warnings
from typing import Dict, List, Any, Optional, Tuple, Callable
from dataclasses import dataclass, asdict
from pathlib import Path
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import psutil

# å¯¼å…¥æˆ‘ä»¬çš„ä¼˜åŒ–æ¨¡å—
import sys
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from training.memory_optimizer import MemoryOptimizer, MemoryConfig
from training.training_monitor import TrainingMonitor
from data.high_performance_loader import DataLoadingConfig, create_high_performance_dataloader


@dataclass
class BenchmarkConfig:
    """åŸºå‡†æµ‹è¯•é…ç½®"""
    # æµ‹è¯•èŒƒå›´
    test_batch_sizes: List[int] = None
    test_sequence_lengths: List[int] = None
    test_model_sizes: List[str] = None

    # æµ‹è¯•å‚æ•°
    warmup_steps: int = 5
    test_steps: int = 50
    num_repeats: int = 3

    # è¾“å‡ºé…ç½®
    save_results: bool = True
    save_plots: bool = True
    output_dir: str = "benchmark_results"

    # æµ‹è¯•æ¨¡å¼
    test_training: bool = True
    test_inference: bool = True
    test_data_loading: bool = True
    test_memory_optimization: bool = True

    def __post_init__(self):
        if self.test_batch_sizes is None:
            self.test_batch_sizes = [1, 4, 8, 16, 32, 64]
        if self.test_sequence_lengths is None:
            self.test_sequence_lengths = [128, 256, 512, 1024]
        if self.test_model_sizes is None:
            self.test_model_sizes = ["tiny", "small"]


@dataclass
class BenchmarkResult:
    """åŸºå‡†æµ‹è¯•ç»“æœ"""
    test_name: str
    config: Dict[str, Any]
    metrics: Dict[str, float]
    timestamp: float
    device: str
    error: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


class ModelFactory:
    """æ¨¡å‹å·¥å‚ï¼Œç”¨äºåˆ›å»ºä¸åŒå¤§å°çš„æµ‹è¯•æ¨¡å‹"""

    @staticmethod
    def create_test_transformer(model_size: str, vocab_size: int = 10000) -> nn.Module:
        """åˆ›å»ºæµ‹è¯•ç”¨çš„Transformeræ¨¡å‹"""
        configs = {
            "tiny": {"d_model": 128, "n_heads": 2, "n_layers": 4, "d_ff": 512},
            "small": {"d_model": 256, "n_heads": 4, "n_layers": 6, "d_ff": 1024},
            "medium": {"d_model": 512, "n_heads": 8, "n_layers": 8, "d_ff": 2048},
        }

        if model_size not in configs:
            raise ValueError(f"Unsupported model size: {model_size}")

        config = configs[model_size]

        class SimpleTransformer(nn.Module):
            def __init__(self, vocab_size, d_model, n_heads, n_layers, d_ff):
                super().__init__()
                self.embedding = nn.Embedding(vocab_size, d_model)
                self.pos_encoding = nn.Parameter(torch.randn(2048, d_model))

                # Transformerå±‚
                encoder_layer = nn.TransformerEncoderLayer(
                    d_model=d_model,
                    nhead=n_heads,
                    dim_feedforward=d_ff,
                    dropout=0.1,
                    activation='relu',
                    batch_first=True
                )
                self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)
                self.output_proj = nn.Linear(d_model, vocab_size)

            def forward(self, x):
                seq_len = x.size(1)
                x = self.embedding(x) + self.pos_encoding[:seq_len].unsqueeze(0)
                x = self.transformer(x)
                return self.output_proj(x)

        return SimpleTransformer(**config, vocab_size=vocab_size)

    @staticmethod
    def get_model_params(model: nn.Module) -> int:
        """è·å–æ¨¡å‹å‚æ•°æ•°é‡"""
        return sum(p.numel() for p in model.parameters())


class TrainingBenchmark:
    """è®­ç»ƒæ€§èƒ½åŸºå‡†æµ‹è¯•"""

    def __init__(self, device: torch.device):
        self.device = device

    def benchmark_training_speed(self, model: nn.Module, batch_size: int,
                                seq_len: int, steps: int = 50) -> Dict[str, float]:
        """æµ‹è¯•è®­ç»ƒé€Ÿåº¦"""
        model.train()
        optimizer = optim.AdamW(model.parameters(), lr=1e-4)
        criterion = nn.CrossEntropyLoss()

        # åˆ›å»ºè™šæ‹Ÿæ•°æ®
        vocab_size = model.output_proj.out_features
        dummy_input = torch.randint(0, vocab_size, (batch_size, seq_len), device=self.device)
        dummy_target = torch.randint(0, vocab_size, (batch_size, seq_len), device=self.device)

        # é¢„çƒ­
        for _ in range(5):
            optimizer.zero_grad()
            output = model(dummy_input)
            loss = criterion(output.reshape(-1, vocab_size), dummy_target.reshape(-1))
            loss.backward()
            optimizer.step()

        # æ¸…ç†å†…å­˜
        if self.device.type == 'cuda':
            torch.cuda.empty_cache()
            torch.cuda.reset_peak_memory_stats()

        # åŸºå‡†æµ‹è¯•
        start_time = time.time()
        start_memory = self._get_memory_usage()

        for step in range(steps):
            optimizer.zero_grad()
            output = model(dummy_input)
            loss = criterion(output.reshape(-1, vocab_size), dummy_target.reshape(-1))
            loss.backward()
            optimizer.step()

        # åŒæ­¥GPU
        if self.device.type == 'cuda':
            torch.cuda.synchronize()

        end_time = time.time()
        end_memory = self._get_memory_usage()

        elapsed_time = end_time - start_time
        samples_per_sec = (steps * batch_size) / elapsed_time
        memory_used = end_memory - start_memory

        return {
            'samples_per_sec': samples_per_sec,
            'elapsed_time': elapsed_time,
            'memory_used_mb': memory_used,
            'loss': loss.item()
        }

    def benchmark_with_optimizations(self, model: nn.Module, batch_size: int,
                                   seq_len: int, config: MemoryConfig) -> Dict[str, float]:
        """æµ‹è¯•å¸¦ä¼˜åŒ–çš„è®­ç»ƒæ€§èƒ½"""
        optimizer = optim.AdamW(model.parameters(), lr=1e-4)
        memory_optimizer = MemoryOptimizer(model, config, self.device)

        vocab_size = model.output_proj.out_features
        dummy_input = torch.randint(0, vocab_size, (batch_size, seq_len), device=self.device)
        dummy_target = torch.randint(0, vocab_size, (batch_size, seq_len), device=self.device)

        start_time = time.time()
        start_memory = self._get_memory_usage()

        steps = 50
        for step in range(steps):
            try:
                with memory_optimizer.optimize_step_context(optimizer) as ctx:
                    output = model(dummy_input)
                    loss = nn.CrossEntropyLoss()(
                        output.reshape(-1, vocab_size),
                        dummy_target.reshape(-1)
                    )

                    optimized_loss = memory_optimizer.compute_loss(loss)
                    memory_optimizer.backward(optimized_loss)

            except Exception as e:
                if "out of memory" in str(e).lower():
                    continue
                else:
                    raise e

        if self.device.type == 'cuda':
            torch.cuda.synchronize()

        end_time = time.time()
        end_memory = self._get_memory_usage()

        elapsed_time = end_time - start_time
        samples_per_sec = (steps * batch_size) / elapsed_time

        stats = memory_optimizer.get_memory_stats()

        return {
            'samples_per_sec': samples_per_sec,
            'elapsed_time': elapsed_time,
            'memory_used_mb': end_memory - start_memory,
            'amp_scale': stats.get('amp_scale', 1.0),
            'oom_count': stats.get('oom_count', 0)
        }

    def _get_memory_usage(self) -> float:
        """è·å–å†…å­˜ä½¿ç”¨é‡(MB)"""
        if self.device.type == 'cuda':
            return torch.cuda.memory_allocated() / 1024 / 1024
        else:
            return psutil.Process().memory_info().rss / 1024 / 1024


class InferenceBenchmark:
    """æ¨ç†æ€§èƒ½åŸºå‡†æµ‹è¯•"""

    def __init__(self, device: torch.device):
        self.device = device

    def benchmark_inference_speed(self, model: nn.Module, batch_sizes: List[int],
                                 seq_len: int = 512) -> Dict[int, Dict[str, float]]:
        """æµ‹è¯•ä¸åŒæ‰¹å¤„ç†å¤§å°çš„æ¨ç†é€Ÿåº¦"""
        model.eval()
        results = {}

        vocab_size = model.output_proj.out_features

        with torch.no_grad():
            for batch_size in batch_sizes:
                try:
                    # åˆ›å»ºæµ‹è¯•æ•°æ®
                    dummy_input = torch.randint(0, vocab_size, (batch_size, seq_len), device=self.device)

                    # é¢„çƒ­
                    for _ in range(5):
                        _ = model(dummy_input)

                    # æ¸…ç†å†…å­˜
                    if self.device.type == 'cuda':
                        torch.cuda.empty_cache()

                    # åŸºå‡†æµ‹è¯•
                    steps = 100
                    start_time = time.time()
                    start_memory = self._get_memory_usage()

                    for _ in range(steps):
                        output = model(dummy_input)

                    if self.device.type == 'cuda':
                        torch.cuda.synchronize()

                    end_time = time.time()
                    end_memory = self._get_memory_usage()

                    elapsed_time = end_time - start_time
                    samples_per_sec = (steps * batch_size) / elapsed_time
                    tokens_per_sec = samples_per_sec * seq_len

                    results[batch_size] = {
                        'samples_per_sec': samples_per_sec,
                        'tokens_per_sec': tokens_per_sec,
                        'elapsed_time': elapsed_time,
                        'memory_used_mb': end_memory - start_memory,
                        'latency_ms': (elapsed_time / steps) * 1000
                    }

                except RuntimeError as e:
                    if "out of memory" in str(e).lower():
                        results[batch_size] = {'error': 'OOM'}
                        if self.device.type == 'cuda':
                            torch.cuda.empty_cache()
                    else:
                        raise e

        return results

    def _get_memory_usage(self) -> float:
        """è·å–å†…å­˜ä½¿ç”¨é‡(MB)"""
        if self.device.type == 'cuda':
            return torch.cuda.memory_allocated() / 1024 / 1024
        else:
            return psutil.Process().memory_info().rss / 1024 / 1024


class DataLoadingBenchmark:
    """æ•°æ®åŠ è½½æ€§èƒ½åŸºå‡†æµ‹è¯•"""

    def __init__(self, device: torch.device):
        self.device = device

    def benchmark_data_loading(self, config: DataLoadingConfig) -> Dict[str, float]:
        """æµ‹è¯•æ•°æ®åŠ è½½æ€§èƒ½"""
        # åˆ›å»ºè™šæ‹Ÿtokenizer
        class DummyTokenizer:
            def __init__(self):
                self.vocab_size = 10000
                self.pad_id = 0
                self.bos_id = 1
                self.eos_id = 2

            def encode(self, text, add_special_tokens=True):
                # æ¨¡æ‹Ÿç¼–ç 
                tokens = list(range(3, min(len(text) // 4 + 3, config.max_length - 2)))
                if add_special_tokens:
                    tokens = [self.bos_id] + tokens + [self.eos_id]
                return tokens

            def get_vocab_size(self):
                return self.vocab_size

        tokenizer = DummyTokenizer()

        # åˆ›å»ºè™šæ‹Ÿæ•°æ®æ–‡ä»¶
        dummy_data_path = "dummy_data.jsonl"
        self._create_dummy_data(dummy_data_path, 1000)

        try:
            config.data_path = dummy_data_path

            # æµ‹è¯•æ•°æ®åŠ è½½å™¨
            start_time = time.time()

            # ç”±äºå®é™…çš„high_performance_loaderéœ€è¦çœŸå®æ–‡ä»¶ï¼Œæˆ‘ä»¬æ¨¡æ‹Ÿæµ‹è¯•
            # åˆ›å»ºç®€å•çš„DataLoaderè¿›è¡ŒåŸºå‡†æµ‹è¯•
            dummy_dataset = TensorDataset(
                torch.randint(0, tokenizer.vocab_size, (1000, config.max_length))
            )

            dataloader = DataLoader(
                dummy_dataset,
                batch_size=config.batch_size,
                num_workers=config.num_workers,
                pin_memory=config.pin_memory and torch.cuda.is_available()
            )

            # æµ‹è¯•æ•°æ®åŠ è½½é€Ÿåº¦
            total_samples = 0
            load_times = []

            for batch_idx, batch in enumerate(dataloader):
                if batch_idx >= 50:  # é™åˆ¶æµ‹è¯•æ‰¹æ¬¡æ•°
                    break

                batch_start = time.time()
                batch_data = batch[0].to(self.device)
                batch_end = time.time()

                load_times.append(batch_end - batch_start)
                total_samples += len(batch_data)

            end_time = time.time()
            total_time = end_time - start_time

            return {
                'total_samples': total_samples,
                'total_time': total_time,
                'samples_per_sec': total_samples / total_time,
                'avg_batch_time_ms': np.mean(load_times) * 1000,
                'std_batch_time_ms': np.std(load_times) * 1000
            }

        finally:
            # æ¸…ç†è™šæ‹Ÿæ–‡ä»¶
            if os.path.exists(dummy_data_path):
                os.remove(dummy_data_path)

    def _create_dummy_data(self, filepath: str, num_samples: int):
        """åˆ›å»ºè™šæ‹Ÿæ•°æ®æ–‡ä»¶"""
        with open(filepath, 'w', encoding='utf-8') as f:
            for i in range(num_samples):
                dummy_conversation = {
                    "conversations": [
                        {"role": "user", "content": f"This is a test question {i}"},
                        {"role": "assistant", "content": f"This is a test answer {i}"}
                    ]
                }
                f.write(json.dumps(dummy_conversation, ensure_ascii=False) + '\n')


class PerformanceBenchmarkSuite:
    """ç»¼åˆæ€§èƒ½åŸºå‡†æµ‹è¯•å¥—ä»¶"""

    def __init__(self, config: BenchmarkConfig):
        self.config = config
        self.device = torch.device('cuda' if torch.cuda.is_available()
                                 else 'mps' if torch.backends.mps.is_available()
                                 else 'cpu')

        # åˆå§‹åŒ–å„ä¸ªåŸºå‡†æµ‹è¯•å™¨
        self.training_benchmark = TrainingBenchmark(self.device)
        self.inference_benchmark = InferenceBenchmark(self.device)
        self.data_loading_benchmark = DataLoadingBenchmark(self.device)

        # ç»“æœå­˜å‚¨
        self.results = []

        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(config.output_dir, exist_ok=True)

        print(f"ğŸ”¬ Performance Benchmark Suite initialized")
        print(f"   Device: {self.device}")
        print(f"   Output: {config.output_dir}")

    def run_all_benchmarks(self) -> List[BenchmarkResult]:
        """è¿è¡Œæ‰€æœ‰åŸºå‡†æµ‹è¯•"""
        print("ğŸš€ Starting comprehensive performance benchmarks...")

        if self.config.test_training:
            self._run_training_benchmarks()

        if self.config.test_inference:
            self._run_inference_benchmarks()

        if self.config.test_data_loading:
            self._run_data_loading_benchmarks()

        if self.config.test_memory_optimization:
            self._run_memory_optimization_benchmarks()

        # ç”ŸæˆæŠ¥å‘Š
        self._generate_report()

        return self.results

    def _run_training_benchmarks(self):
        """è¿è¡Œè®­ç»ƒåŸºå‡†æµ‹è¯•"""
        print("ğŸ“Š Running training benchmarks...")

        for model_size in self.config.test_model_sizes:
            model = ModelFactory.create_test_transformer(model_size)
            model.to(self.device)

            for batch_size in self.config.test_batch_sizes:
                for seq_len in self.config.test_sequence_lengths:
                    try:
                        # åŸºç¡€è®­ç»ƒæµ‹è¯•
                        result = self.training_benchmark.benchmark_training_speed(
                            model, batch_size, seq_len, self.config.test_steps
                        )

                        self.results.append(BenchmarkResult(
                            test_name="training_baseline",
                            config={
                                'model_size': model_size,
                                'batch_size': batch_size,
                                'seq_len': seq_len,
                                'model_params': ModelFactory.get_model_params(model)
                            },
                            metrics=result,
                            timestamp=time.time(),
                            device=str(self.device)
                        ))

                        print(f"   {model_size} model, batch={batch_size}, seq={seq_len}: "
                              f"{result['samples_per_sec']:.1f} samples/sec")

                    except RuntimeError as e:
                        if "out of memory" in str(e).lower():
                            print(f"   OOM: {model_size}, batch={batch_size}, seq={seq_len}")
                            if self.device.type == 'cuda':
                                torch.cuda.empty_cache()
                        else:
                            print(f"   Error: {e}")

    def _run_inference_benchmarks(self):
        """è¿è¡Œæ¨ç†åŸºå‡†æµ‹è¯•"""
        print("ğŸ” Running inference benchmarks...")

        for model_size in self.config.test_model_sizes:
            model = ModelFactory.create_test_transformer(model_size)
            model.to(self.device)

            results = self.inference_benchmark.benchmark_inference_speed(
                model, self.config.test_batch_sizes
            )

            for batch_size, metrics in results.items():
                if 'error' not in metrics:
                    self.results.append(BenchmarkResult(
                        test_name="inference",
                        config={
                            'model_size': model_size,
                            'batch_size': batch_size,
                            'model_params': ModelFactory.get_model_params(model)
                        },
                        metrics=metrics,
                        timestamp=time.time(),
                        device=str(self.device)
                    ))

                    print(f"   {model_size} model, batch={batch_size}: "
                          f"{metrics['tokens_per_sec']:.0f} tokens/sec")

    def _run_data_loading_benchmarks(self):
        """è¿è¡Œæ•°æ®åŠ è½½åŸºå‡†æµ‹è¯•"""
        print("ğŸ“¦ Running data loading benchmarks...")

        for batch_size in self.config.test_batch_sizes:
            for num_workers in [0, 2, 4]:
                config = DataLoadingConfig(
                    data_path="dummy",  # å°†è¢«æ›¿æ¢
                    batch_size=batch_size,
                    num_workers=num_workers,
                    max_length=512
                )

                try:
                    result = self.data_loading_benchmark.benchmark_data_loading(config)

                    self.results.append(BenchmarkResult(
                        test_name="data_loading",
                        config={
                            'batch_size': batch_size,
                            'num_workers': num_workers,
                            'max_length': config.max_length
                        },
                        metrics=result,
                        timestamp=time.time(),
                        device=str(self.device)
                    ))

                    print(f"   batch={batch_size}, workers={num_workers}: "
                          f"{result['samples_per_sec']:.1f} samples/sec")

                except Exception as e:
                    print(f"   Error in data loading test: {e}")

    def _run_memory_optimization_benchmarks(self):
        """è¿è¡Œå†…å­˜ä¼˜åŒ–åŸºå‡†æµ‹è¯•"""
        print("ğŸ§  Running memory optimization benchmarks...")

        model = ModelFactory.create_test_transformer("small")
        model.to(self.device)

        # æµ‹è¯•ä¸åŒä¼˜åŒ–é…ç½®
        configs = [
            MemoryConfig(enable_amp=False, gradient_accumulation_steps=1),
            MemoryConfig(enable_amp=True, gradient_accumulation_steps=1),
            MemoryConfig(enable_amp=True, gradient_accumulation_steps=4),
            MemoryConfig(enable_amp=True, gradient_accumulation_steps=4,
                        enable_gradient_checkpointing=True)
        ]

        for i, mem_config in enumerate(configs):
            try:
                result = self.training_benchmark.benchmark_with_optimizations(
                    model, 16, 512, mem_config
                )

                config_name = f"optimization_config_{i}"
                self.results.append(BenchmarkResult(
                    test_name=config_name,
                    config={
                        'enable_amp': mem_config.enable_amp,
                        'gradient_accumulation_steps': mem_config.gradient_accumulation_steps,
                        'enable_gradient_checkpointing': mem_config.enable_gradient_checkpointing
                    },
                    metrics=result,
                    timestamp=time.time(),
                    device=str(self.device)
                ))

                print(f"   Config {i}: {result['samples_per_sec']:.1f} samples/sec, "
                      f"memory: {result['memory_used_mb']:.1f}MB")

            except Exception as e:
                print(f"   Error in config {i}: {e}")

    def _generate_report(self):
        """ç”ŸæˆåŸºå‡†æµ‹è¯•æŠ¥å‘Š"""
        if not self.config.save_results:
            return

        # ä¿å­˜åŸå§‹ç»“æœ
        results_file = os.path.join(self.config.output_dir, "benchmark_results.json")
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump([r.to_dict() for r in self.results], f, indent=2, ensure_ascii=False)

        # ç”Ÿæˆå¯è§†åŒ–
        if self.config.save_plots:
            self._create_visualizations()

        # ç”Ÿæˆæ€§èƒ½åˆ†ææŠ¥å‘Š
        self._create_performance_analysis()

        print(f"ğŸ“‹ Benchmark report saved to: {self.config.output_dir}")

    def _create_visualizations(self):
        """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
        plt.style.use('seaborn-v0_8')

        # è®­ç»ƒæ€§èƒ½å¯¹æ¯”
        training_results = [r for r in self.results if r.test_name == "training_baseline"]
        if training_results:
            self._plot_training_performance(training_results)

        # æ¨ç†æ€§èƒ½å¯¹æ¯”
        inference_results = [r for r in self.results if r.test_name == "inference"]
        if inference_results:
            self._plot_inference_performance(inference_results)

        # å†…å­˜ä¼˜åŒ–æ•ˆæœ
        opt_results = [r for r in self.results if "optimization" in r.test_name]
        if opt_results:
            self._plot_optimization_effects(opt_results)

    def _plot_training_performance(self, results: List[BenchmarkResult]):
        """ç»˜åˆ¶è®­ç»ƒæ€§èƒ½å›¾è¡¨"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('Training Performance Analysis', fontsize=16)

        # æŒ‰æ¨¡å‹å¤§å°åˆ†ç»„
        for model_size in self.config.test_model_sizes:
            model_results = [r for r in results if r.config['model_size'] == model_size]

            batch_sizes = [r.config['batch_size'] for r in model_results]
            throughputs = [r.metrics['samples_per_sec'] for r in model_results]
            memory_usage = [r.metrics['memory_used_mb'] for r in model_results]

            # ååé‡ vs æ‰¹å¤„ç†å¤§å°
            axes[0, 0].plot(batch_sizes, throughputs, marker='o', label=f'{model_size} model')
            axes[0, 0].set_xlabel('Batch Size')
            axes[0, 0].set_ylabel('Samples/sec')
            axes[0, 0].set_title('Training Throughput')
            axes[0, 0].legend()

            # å†…å­˜ä½¿ç”¨ vs æ‰¹å¤„ç†å¤§å°
            axes[0, 1].plot(batch_sizes, memory_usage, marker='s', label=f'{model_size} model')
            axes[0, 1].set_xlabel('Batch Size')
            axes[0, 1].set_ylabel('Memory Usage (MB)')
            axes[0, 1].set_title('Memory Usage')
            axes[0, 1].legend()

        plt.tight_layout()
        plt.savefig(os.path.join(self.config.output_dir, 'training_performance.png'), dpi=300)
        plt.close()

    def _plot_inference_performance(self, results: List[BenchmarkResult]):
        """ç»˜åˆ¶æ¨ç†æ€§èƒ½å›¾è¡¨"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
        fig.suptitle('Inference Performance Analysis', fontsize=16)

        for model_size in self.config.test_model_sizes:
            model_results = [r for r in results if r.config['model_size'] == model_size]

            batch_sizes = [r.config['batch_size'] for r in model_results]
            tokens_per_sec = [r.metrics['tokens_per_sec'] for r in model_results]
            latency = [r.metrics['latency_ms'] for r in model_results]

            ax1.plot(batch_sizes, tokens_per_sec, marker='o', label=f'{model_size} model')
            ax1.set_xlabel('Batch Size')
            ax1.set_ylabel('Tokens/sec')
            ax1.set_title('Inference Throughput')
            ax1.legend()

            ax2.plot(batch_sizes, latency, marker='s', label=f'{model_size} model')
            ax2.set_xlabel('Batch Size')
            ax2.set_ylabel('Latency (ms)')
            ax2.set_title('Inference Latency')
            ax2.legend()

        plt.tight_layout()
        plt.savefig(os.path.join(self.config.output_dir, 'inference_performance.png'), dpi=300)
        plt.close()

    def _plot_optimization_effects(self, results: List[BenchmarkResult]):
        """ç»˜åˆ¶ä¼˜åŒ–æ•ˆæœå›¾è¡¨"""
        if not results:
            return

        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
        fig.suptitle('Memory Optimization Effects', fontsize=16)

        config_names = [f"Config {i}" for i in range(len(results))]
        throughputs = [r.metrics['samples_per_sec'] for r in results]
        memory_usage = [r.metrics['memory_used_mb'] for r in results]

        ax1.bar(config_names, throughputs, color='skyblue')
        ax1.set_ylabel('Samples/sec')
        ax1.set_title('Training Throughput')
        ax1.tick_params(axis='x', rotation=45)

        ax2.bar(config_names, memory_usage, color='lightcoral')
        ax2.set_ylabel('Memory Usage (MB)')
        ax2.set_title('Memory Usage')
        ax2.tick_params(axis='x', rotation=45)

        plt.tight_layout()
        plt.savefig(os.path.join(self.config.output_dir, 'optimization_effects.png'), dpi=300)
        plt.close()

    def _create_performance_analysis(self):
        """åˆ›å»ºæ€§èƒ½åˆ†ææŠ¥å‘Š"""
        analysis = {
            'device_info': {
                'device': str(self.device),
                'device_name': self._get_device_name(),
                'memory_gb': self._get_device_memory()
            },
            'summary': {},
            'recommendations': []
        }

        # è®­ç»ƒæ€§èƒ½æ€»ç»“
        training_results = [r for r in self.results if r.test_name == "training_baseline"]
        if training_results:
            max_throughput = max(r.metrics['samples_per_sec'] for r in training_results)
            best_config = next(r for r in training_results
                             if r.metrics['samples_per_sec'] == max_throughput)

            analysis['summary']['best_training_config'] = {
                'throughput': max_throughput,
                'config': best_config.config
            }

        # æ¨ç†æ€§èƒ½æ€»ç»“
        inference_results = [r for r in self.results if r.test_name == "inference"]
        if inference_results:
            max_tokens = max(r.metrics['tokens_per_sec'] for r in inference_results)
            best_inference = next(r for r in inference_results
                                if r.metrics['tokens_per_sec'] == max_tokens)

            analysis['summary']['best_inference_config'] = {
                'tokens_per_sec': max_tokens,
                'config': best_inference.config
            }

        # ç”Ÿæˆå»ºè®®
        analysis['recommendations'] = self._generate_recommendations()

        # ä¿å­˜åˆ†ææŠ¥å‘Š
        analysis_file = os.path.join(self.config.output_dir, "performance_analysis.json")
        with open(analysis_file, 'w', encoding='utf-8') as f:
            json.dump(analysis, f, indent=2, ensure_ascii=False)

    def _get_device_name(self) -> str:
        """è·å–è®¾å¤‡åç§°"""
        if self.device.type == 'cuda':
            return torch.cuda.get_device_name()
        elif self.device.type == 'mps':
            return "Apple Silicon GPU (MPS)"
        else:
            return "CPU"

    def _get_device_memory(self) -> float:
        """è·å–è®¾å¤‡å†…å­˜(GB)"""
        if self.device.type == 'cuda':
            return torch.cuda.get_device_properties(self.device).total_memory / 1024**3
        else:
            return psutil.virtual_memory().total / 1024**3

    def _generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆæ€§èƒ½ä¼˜åŒ–å»ºè®®"""
        recommendations = []

        # åŸºäºç»“æœç”Ÿæˆå»ºè®®
        training_results = [r for r in self.results if r.test_name == "training_baseline"]
        if training_results:
            # æ‰¾åˆ°æœ€ä½³æ‰¹å¤„ç†å¤§å°
            throughputs = [(r.config['batch_size'], r.metrics['samples_per_sec']) for r in training_results]
            best_batch_size = max(throughputs, key=lambda x: x[1])[0]
            recommendations.append(f"æ¨èè®­ç»ƒæ‰¹å¤„ç†å¤§å°: {best_batch_size}")

        # å†…å­˜ä½¿ç”¨å»ºè®®
        if self.device.type == 'cuda':
            recommendations.append("å»ºè®®å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒä»¥èŠ‚çœGPUå†…å­˜")
            recommendations.append("è€ƒè™‘ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯æ¥å¤„ç†æ›´å¤§çš„æœ‰æ•ˆæ‰¹å¤„ç†å¤§å°")

        # æ•°æ®åŠ è½½å»ºè®®
        data_results = [r for r in self.results if r.test_name == "data_loading"]
        if data_results:
            best_workers = max(data_results, key=lambda x: x.metrics['samples_per_sec'])
            recommendations.append(f"æ¨èæ•°æ®åŠ è½½workeræ•°é‡: {best_workers.config['num_workers']}")

        return recommendations


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # é…ç½®åŸºå‡†æµ‹è¯•
    config = BenchmarkConfig(
        test_batch_sizes=[4, 8, 16, 32],
        test_sequence_lengths=[256, 512],
        test_model_sizes=["tiny", "small"],
        test_steps=20,  # å‡å°‘æµ‹è¯•æ­¥æ•°ä»¥åŠ å¿«æµ‹è¯•
        output_dir="benchmark_results"
    )

    # è¿è¡ŒåŸºå‡†æµ‹è¯•
    benchmark_suite = PerformanceBenchmarkSuite(config)
    results = benchmark_suite.run_all_benchmarks()

    print(f"\nâœ… Benchmark completed! {len(results)} tests run.")
    print(f"ğŸ“Š Results saved to: {config.output_dir}")

    # æ‰“å°æœ€ä½³é…ç½®
    training_results = [r for r in results if r.test_name == "training_baseline"]
    if training_results:
        best_result = max(training_results, key=lambda x: x.metrics['samples_per_sec'])
        print(f"\nğŸ† Best training configuration:")
        print(f"   Model: {best_result.config['model_size']}")
        print(f"   Batch size: {best_result.config['batch_size']}")
        print(f"   Sequence length: {best_result.config['seq_len']}")
        print(f"   Throughput: {best_result.metrics['samples_per_sec']:.1f} samples/sec")