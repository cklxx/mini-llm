"""Command-line entry point for MiniGPT training."""
from __future__ import annotations

import argparse

from config.training_config import get_config

from .app import MiniGPTTrainer


def build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(description="MiniGPTè®­ç»ƒè„šæœ¬")
    parser.add_argument(
        "--mode",
        choices=["pretrain", "sft", "dpo", "rlhf"],
        default="sft",
        help="è®­ç»ƒæ¨¡å¼ (pretrain: é¢„è®­ç»ƒ, sft: ç›‘ç£å¾®è°ƒ, dpo: ç›´æ¥åå¥½ä¼˜åŒ–, rlhf: å¼ºåŒ–å­¦ä¹ )",
    )
    parser.add_argument(
        "--config",
        choices=["tiny", "small", "small_30m", "medium", "large", "foundation", "moe"],
        default="medium",
        help="æ¨¡å‹é…ç½®å¤§å° (tiny: ~1M, small: ~25M, small_30m: ~30M, medium: ~80M, large: ~350M, foundation: ~200M, moe: MOEæ¨¡å‹)",
    )
    parser.add_argument(
        "--retrain-tokenizer",
        action="store_true",
        help="é‡æ–°è®­ç»ƒåˆ†è¯å™¨",
    )
    parser.add_argument(
        "--resume",
        "--resume-from-checkpoint",
        type=str,
        default=None,
        dest="resume_from_checkpoint",
        help="ä»æŒ‡å®šcheckpointæ–‡ä»¶ç»§ç»­è®­ç»ƒï¼ˆä¾‹å¦‚: checkpoints/sft_medium/checkpoint_step_5000.ptï¼‰",
    )
    parser.add_argument(
        "--auto-resume",
        action="store_true",
        help="è‡ªåŠ¨ä»æœ€æ–°çš„checkpointæ¢å¤è®­ç»ƒã€‚æ³¨æ„ï¼šSFT/DPO/RLHFæ¨¡å¼ä¼šè‡ªåŠ¨åŠ è½½pretrainæƒé‡ä½œä¸ºåˆå§‹åŒ–",
    )
    parser.add_argument("--learning-rate", type=float, default=None, help="å­¦ä¹ ç‡")
    parser.add_argument("--max-steps", type=int, default=None, help="æœ€å¤§è®­ç»ƒæ­¥æ•°")
    parser.add_argument("--batch-size", type=int, default=None, help="æ‰¹æ¬¡å¤§å°")
    parser.add_argument(
        "--warmup-steps",
        type=int,
        default=None,
        help="å­¦ä¹ ç‡warmupæ­¥æ•°ï¼ˆå¦‚æœä¸æŒ‡å®šï¼Œå°†æ ¹æ®è®­ç»ƒæ¨¡å¼è‡ªåŠ¨è®¾ç½®ï¼‰",
    )
    return parser


def apply_mode_defaults(config, mode: str, overrides) -> None:
    if mode == "pretrain":
        config.max_steps = overrides.max_steps or config.max_steps or 50000
        if overrides.learning_rate is None:
            config.learning_rate = 1e-4
        config.warmup_steps = min(500, int(config.max_steps * 0.05))
        print("ğŸ“š é¢„è®­ç»ƒæ¨¡å¼ï¼šå»ºç«‹åŸºç¡€è¯­è¨€ç†è§£èƒ½åŠ›")
        print(f"   å­¦ä¹ ç‡: {config.learning_rate:.2e}")
        print(f"   Warmup steps: {config.warmup_steps} (å‰{config.warmup_steps/config.max_steps*100:.1f}%)")
    elif mode == "sft":
        config.max_steps = overrides.max_steps or config.max_steps or 10000
        if overrides.learning_rate is None:
            config.learning_rate = 5e-5
        config.warmup_steps = min(200, int(config.max_steps * 0.02))
        print("ğŸ¯ ç›‘ç£å¾®è°ƒæ¨¡å¼ï¼šè®­ç»ƒå¯¹è¯å’Œç‰¹å®šä»»åŠ¡èƒ½åŠ›")
        print(f"   å­¦ä¹ ç‡: {config.learning_rate:.2e} (æ¯”é¢„è®­ç»ƒä½ï¼Œä¿æŠ¤å·²å­¦çŸ¥è¯†)")
        print(f"   Warmup steps: {config.warmup_steps} (å‰{config.warmup_steps/config.max_steps*100:.1f}%)")
        print("   ğŸ’¡ æ¨¡å‹å·²æœ‰é¢„è®­ç»ƒåŸºç¡€ï¼Œä½¿ç”¨çŸ­warmupå¿«é€Ÿè¿›å…¥è¡°å‡é˜¶æ®µ")
    elif mode == "dpo":
        config.max_steps = overrides.max_steps or config.max_steps or 5000
        if overrides.learning_rate is None:
            config.learning_rate = 1e-5
        config.warmup_steps = min(100, int(config.max_steps * 0.02))
        print("âš–ï¸  ç›´æ¥åå¥½ä¼˜åŒ–æ¨¡å¼ï¼šæ ¹æ®äººç±»åå¥½è°ƒæ•´å“åº”")
        print(f"   å­¦ä¹ ç‡: {config.learning_rate:.2e}")
        print(f"   Warmup steps: {config.warmup_steps} (å‰{config.warmup_steps/config.max_steps*100:.1f}%)")
        print("   ğŸ’¡ åœ¨SFTåŸºç¡€ä¸Šä¼˜åŒ–ï¼Œä½¿ç”¨æçŸ­warmup")
    elif mode == "rlhf":
        config.max_steps = overrides.max_steps or config.max_steps or 3000
        if overrides.learning_rate is None:
            config.learning_rate = 1e-5
        config.warmup_steps = min(100, int(config.max_steps * 0.02))
        print("ğŸ”„ å¼ºåŒ–å­¦ä¹ å¾®è°ƒæ¨¡å¼ï¼šé€šè¿‡å¥–åŠ±æ¨¡å‹ä¼˜åŒ–")
        print(f"   å­¦ä¹ ç‡: {config.learning_rate:.2e}")
        print(f"   Warmup steps: {config.warmup_steps} (å‰{config.warmup_steps/config.max_steps*100:.1f}%)")
        print("   ğŸ’¡ åœ¨å·²è®­ç»ƒæ¨¡å‹ä¸Šå¼ºåŒ–å­¦ä¹ ï¼Œä½¿ç”¨æçŸ­warmup")
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„è®­ç»ƒæ¨¡å¼: {mode}")


def run_cli(argv: list[str] | None = None) -> str:
    parser = build_parser()
    args = parser.parse_args(argv)

    config = get_config(args.config)

    if args.learning_rate is not None:
        config.learning_rate = args.learning_rate
    if args.max_steps is not None:
        config.max_steps = args.max_steps
    if args.batch_size is not None:
        config.batch_size = args.batch_size

    apply_mode_defaults(config, args.mode, args)

    if args.warmup_steps is not None:
        config.warmup_steps = args.warmup_steps
        print(f"âš™ï¸  ä½¿ç”¨è‡ªå®šä¹‰warmupæ­¥æ•°: {config.warmup_steps} (å‰{config.warmup_steps/config.max_steps*100:.1f}%)")

    trainer = MiniGPTTrainer(config, mode=args.mode)

    if args.auto_resume:
        print("ğŸ”„ å¯ç”¨è‡ªåŠ¨æ¢å¤æ¨¡å¼")
    elif args.resume_from_checkpoint:
        print(f"ğŸ”„ å°†ä»checkpointæ¢å¤: {args.resume_from_checkpoint}")

    final_model_path = trainer.train(
        resume_from=args.resume_from_checkpoint,
        auto_resume=args.auto_resume,
        retrain_tokenizer=args.retrain_tokenizer,
    )

    print(f"\nâœ… è®­ç»ƒå®Œæˆï¼æ¨¡å‹ä¿å­˜åœ¨: {final_model_path}")

    if args.mode == "pretrain":
        print("\nğŸ’¡ å»ºè®®ä¸‹ä¸€æ­¥è¿è¡ŒSFTè®­ç»ƒ:")
        print(f"uv run python scripts/train.py --mode sft --config {args.config} --resume {final_model_path}")
    elif args.mode == "sft":
        print("\nğŸ’¡ å»ºè®®ä¸‹ä¸€æ­¥è¿è¡ŒDPOè®­ç»ƒ:")
        print(f"uv run python scripts/train.py --mode dpo --config {args.config} --resume {final_model_path}")

    return final_model_path
