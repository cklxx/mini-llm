"""
è®­ç»ƒå™¨æ¨¡å—
æ”¯æŒé¢„è®­ç»ƒã€SFTã€DPOç­‰å¤šç§è®­ç»ƒæ¨¡å¼
"""
import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from typing import Dict, List, Optional, Tuple
import json
from tqdm import tqdm
import matplotlib.pyplot as plt


class LanguageModelingDataset(Dataset):
    """è¯­è¨€æ¨¡å‹æ•°æ®é›†"""
    
    def __init__(self, texts: List[str], tokenizer, max_length: int = 512):
        self.texts = texts
        self.tokenizer = tokenizer
        self.max_length = max_length
        print(f"ğŸ“Š æ•°æ®é›†åˆå§‹åŒ–: {len(texts)} æ¡æ–‡æœ¬, æœ€å¤§é•¿åº¦: {max_length}")
    
    def __len__(self):
        return len(self.texts)
    
    def __getitem__(self, idx):
        try:
            text = self.texts[idx]
            
            # ç¼–ç æ–‡æœ¬
            token_ids = self.tokenizer.encode(text, add_special_tokens=True)
            
            # æˆªæ–­æˆ–å¡«å……åˆ°å›ºå®šé•¿åº¦
            if len(token_ids) > self.max_length:
                token_ids = token_ids[:self.max_length]
            else:
                token_ids.extend([self.tokenizer.pad_id] * (self.max_length - len(token_ids)))
            
            result = torch.tensor(token_ids, dtype=torch.long)
            return result
            
        except Exception as e:
            print(f"âŒ å¤„ç†æ•°æ®é¡¹ {idx} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            print(f"âŒ é”™è¯¯æ–‡æœ¬é•¿åº¦: {len(text)}")
            print(f"âŒ é”™è¯¯æ–‡æœ¬é¢„è§ˆ: {text[:200]}...")
            import traceback
            traceback.print_exc()
            raise e


class ConversationDataset(Dataset):
    """å¯¹è¯æ•°æ®é›†"""
    
    def __init__(self, conversations: List[Dict], tokenizer, max_length: int = 512):
        self.conversations = conversations
        self.tokenizer = tokenizer
        self.max_length = max_length
    
    def __len__(self):
        return len(self.conversations)
    
    def __getitem__(self, idx):
        conv = self.conversations[idx]
        
        # æ„é€ è¾“å…¥å’Œæ ‡ç­¾
        input_text = conv['input']
        output_text = conv['output']
        
        # ç¼–ç è¾“å…¥å’Œè¾“å‡º
        input_ids = self.tokenizer.encode(input_text, add_special_tokens=False)
        output_ids = self.tokenizer.encode(output_text, add_special_tokens=False)
        
        # æ„é€ å®Œæ•´åºåˆ—ï¼š<BOS> input output <EOS>
        full_sequence = [self.tokenizer.bos_id] + input_ids + output_ids + [self.tokenizer.eos_id]
        
        # æˆªæ–­åˆ°æœ€å¤§é•¿åº¦
        if len(full_sequence) > self.max_length:
            full_sequence = full_sequence[:self.max_length]
        
        # åˆ›å»ºæ ‡ç­¾ï¼ˆç”¨äºè®¡ç®—æŸå¤±ï¼‰
        labels = full_sequence[1:] + [self.tokenizer.pad_id]  # å‘å·¦ç§»åŠ¨ä¸€ä½
        
        # å¡«å……
        while len(full_sequence) < self.max_length:
            full_sequence.append(self.tokenizer.pad_id)
            labels.append(self.tokenizer.pad_id)
        
        return {
            'input_ids': torch.tensor(full_sequence, dtype=torch.long),
            'labels': torch.tensor(labels, dtype=torch.long)
        }


class PreTrainer:
    """é¢„è®­ç»ƒå™¨"""
    
    def __init__(self, model, tokenizer, device='cpu'):
        self.model = model
        self.tokenizer = tokenizer
        self.device = device
        self.model.to(device)
        
        # ä¼˜åŒ–å™¨
        self.optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=1000)
        
        # è®°å½•è®­ç»ƒè¿‡ç¨‹
        self.train_losses = []
        self.val_losses = []
    
    def compute_loss(self, logits: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:
        """è®¡ç®—è¯­è¨€æ¨¡å‹æŸå¤±"""
        # å±•å¹³å¼ é‡
        logits = logits.reshape(-1, logits.size(-1))
        labels = labels.reshape(-1)
        
        # å¿½ç•¥PAD token
        loss_fn = nn.CrossEntropyLoss(ignore_index=self.tokenizer.pad_id)
        loss = loss_fn(logits, labels)
        
        return loss
    
    def train_epoch(self, dataloader: DataLoader) -> float:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0
        num_batches = 0
        
        print(f"ğŸš€ å¼€å§‹è®­ç»ƒepochï¼Œæ•°æ®æ‰¹æ¬¡: {len(dataloader)}")
        print(f"ğŸ“Š è®¾å¤‡: {self.device}")
        
        progress_bar = tqdm(dataloader, desc="é¢„è®­ç»ƒ")
        print("ğŸ“¦ å¼€å§‹éå†æ•°æ®æ‰¹æ¬¡...")
        
        try:
            for batch_idx, batch in enumerate(progress_bar):
                # å…³é—­è°ƒè¯•æ¨¡å¼ï¼Œæ­£å¸¸è®­ç»ƒæ‰€æœ‰batch
                debug_mode = False
                
                if debug_mode:
                    print(f"\n--- ğŸ”„ å¤„ç†batch {batch_idx + 1} ---")
                
                if isinstance(batch, dict):
                    input_ids = batch['input_ids'].to(self.device)
                    labels = batch['labels'].to(self.device)
                    if debug_mode:
                        print(f"ğŸ“¦ å­—å…¸æ ¼å¼ - input_ids: {input_ids.shape}")
                else:
                    input_ids = batch.to(self.device)
                    # å¯¹äºé¢„è®­ç»ƒï¼Œæ ‡ç­¾å°±æ˜¯è¾“å…¥å‘å³ç§»åŠ¨ä¸€ä½
                    labels = torch.cat([input_ids[:, 1:], 
                                      torch.full((input_ids.size(0), 1), 
                                               self.tokenizer.pad_id, device=self.device)], dim=1)
                    if debug_mode:
                        print(f"ğŸ“¦ Tensoræ ¼å¼ - input_ids: {input_ids.shape}")
                
                if debug_mode:
                    print("ğŸ§  æ¨¡å‹å‰å‘ä¼ æ’­...")
                
                # å‰å‘ä¼ æ’­
                logits = self.model(input_ids)
                loss = self.compute_loss(logits, labels)
                
                if debug_mode:
                    print(f"ğŸ“‰ æŸå¤±: {loss.item():.4f}")
                
                # åå‘ä¼ æ’­
                self.optimizer.zero_grad()
                loss.backward()
                
                # æ¢¯åº¦è£å‰ª
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
                
                self.optimizer.step()
                self.scheduler.step()
                
                total_loss += loss.item()
                num_batches += 1
                
                if debug_mode:
                    print(f"âœ… Batch {batch_idx + 1} å®Œæˆ")
                
                # æ›´æ–°è¿›åº¦æ¡
                progress_bar.set_postfix({
                    'loss': f'{loss.item():.4f}',
                    'lr': f'{self.scheduler.get_last_lr()[0]:.6f}'
                })
                
                # è°ƒè¯•æ¨¡å¼ä¸‹åªå¤„ç†å‰å‡ ä¸ªbatch
                if debug_mode and batch_idx >= 2:
                    print("ğŸ” è°ƒè¯•æ¨¡å¼ï¼šå¤„ç†3ä¸ªbatchååœæ­¢")
                    break
                    
        except Exception as e:
            print(f"âŒ è®­ç»ƒé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            raise e
        
        avg_loss = total_loss / num_batches if num_batches > 0 else 0
        print(f"ğŸ¯ Epochå®Œæˆï¼Œå¹³å‡æŸå¤±: {avg_loss:.4f}")
        return avg_loss
    
    def validate(self, dataloader: DataLoader) -> float:
        """éªŒè¯"""
        self.model.eval()
        total_loss = 0
        num_batches = 0
        
        with torch.no_grad():
            for batch in tqdm(dataloader, desc="éªŒè¯"):
                if isinstance(batch, dict):
                    input_ids = batch['input_ids'].to(self.device)
                    labels = batch['labels'].to(self.device)
                else:
                    input_ids = batch.to(self.device)
                    labels = torch.cat([input_ids[:, 1:], 
                                      torch.full((input_ids.size(0), 1), 
                                               self.tokenizer.pad_id, device=self.device)], dim=1)
                
                logits = self.model(input_ids)
                loss = self.compute_loss(logits, labels)
                
                total_loss += loss.item()
                num_batches += 1
        
        return total_loss / num_batches
    
    def train(self, train_dataloader: DataLoader, val_dataloader: Optional[DataLoader] = None, 
              num_epochs: int = 10, save_dir: str = "checkpoints"):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        os.makedirs(save_dir, exist_ok=True)
        best_val_loss = float('inf')
        
        for epoch in range(num_epochs):
            print(f"\nEpoch {epoch + 1}/{num_epochs}")
            
            # è®­ç»ƒ
            train_loss = self.train_epoch(train_dataloader)
            self.train_losses.append(train_loss)
            
            print(f"è®­ç»ƒæŸå¤±: {train_loss:.4f}")
            
            # éªŒè¯
            if val_dataloader:
                val_loss = self.validate(val_dataloader)
                self.val_losses.append(val_loss)
                print(f"éªŒè¯æŸå¤±: {val_loss:.4f}")
                
                # ä¿å­˜æœ€ä½³æ¨¡å‹
                if val_loss < best_val_loss:
                    best_val_loss = val_loss
                    self.save_checkpoint(os.path.join(save_dir, "best_model.pt"))
                    print("ä¿å­˜æœ€ä½³æ¨¡å‹")
            
            # å®šæœŸä¿å­˜checkpoint
            if (epoch + 1) % 5 == 0:
                self.save_checkpoint(os.path.join(save_dir, f"checkpoint_epoch_{epoch + 1}.pt"))
        
        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
        self.plot_training_curve(save_dir)
    
    def save_checkpoint(self, path: str):
        """ä¿å­˜æ¨¡å‹checkpoint"""
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'train_losses': self.train_losses,
            'val_losses': self.val_losses
        }, path)
    
    def load_checkpoint(self, path: str):
        """åŠ è½½æ¨¡å‹checkpoint"""
        checkpoint = torch.load(path, map_location=self.device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        self.train_losses = checkpoint.get('train_losses', [])
        self.val_losses = checkpoint.get('val_losses', [])
    
    def plot_training_curve(self, save_dir: str):
        """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
        plt.figure(figsize=(10, 6))
        
        epochs = range(1, len(self.train_losses) + 1)
        plt.plot(epochs, self.train_losses, 'b-', label='è®­ç»ƒæŸå¤±')
        
        if self.val_losses:
            plt.plot(epochs, self.val_losses, 'r-', label='éªŒè¯æŸå¤±')
        
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.title('è®­ç»ƒè¿‡ç¨‹')
        plt.legend()
        plt.grid(True)
        
        plt.savefig(os.path.join(save_dir, 'training_curve.png'))
        plt.close()


class SFTTrainer(PreTrainer):
    """ç›‘ç£å¾®è°ƒè®­ç»ƒå™¨"""
    
    def __init__(self, model, tokenizer, device='cpu'):
        super().__init__(model, tokenizer, device)
        
        # SFTä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡
        self.optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)
    
    def compute_loss(self, logits: torch.Tensor, labels: torch.Tensor, 
                    input_length: Optional[torch.Tensor] = None) -> torch.Tensor:
        """è®¡ç®—SFTæŸå¤±ï¼Œåªå¯¹è¾“å‡ºéƒ¨åˆ†è®¡ç®—æŸå¤±"""
        # å±•å¹³å¼ é‡
        logits = logits.reshape(-1, logits.size(-1))
        labels = labels.reshape(-1)
        
        # åˆ›å»ºæ©ç ï¼Œåªå¯¹éPAD tokenè®¡ç®—æŸå¤±
        mask = (labels != self.tokenizer.pad_id)
        
        if mask.sum() == 0:
            return torch.tensor(0.0, device=logits.device, requires_grad=True)
        
        # è®¡ç®—æŸå¤±
        loss_fn = nn.CrossEntropyLoss(reduction='none')
        losses = loss_fn(logits, labels)
        
        # åº”ç”¨æ©ç 
        masked_losses = losses * mask.float()
        
        return masked_losses.sum() / mask.sum()


class DPOTrainer:
    """DPO (Direct Preference Optimization) è®­ç»ƒå™¨"""
    
    def __init__(self, model, reference_model, tokenizer, device='cpu', beta=0.1):
        self.model = model
        self.reference_model = reference_model
        self.tokenizer = tokenizer
        self.device = device
        self.beta = beta
        
        self.model.to(device)
        self.reference_model.to(device)
        
        # å†»ç»“å‚è€ƒæ¨¡å‹
        for param in self.reference_model.parameters():
            param.requires_grad = False
        
        self.optimizer = optim.AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)
    
    def compute_dpo_loss(self, chosen_logits: torch.Tensor, rejected_logits: torch.Tensor,
                        chosen_labels: torch.Tensor, rejected_labels: torch.Tensor,
                        ref_chosen_logits: torch.Tensor, ref_rejected_logits: torch.Tensor) -> torch.Tensor:
        """è®¡ç®—DPOæŸå¤±"""
        
        def get_log_probs(logits, labels):
            log_probs = torch.log_softmax(logits, dim=-1)
            selected_log_probs = torch.gather(log_probs, dim=-1, index=labels.unsqueeze(-1)).squeeze(-1)
            
            # åªå¯¹éPAD tokenè®¡ç®—
            mask = (labels != self.tokenizer.pad_id)
            masked_log_probs = selected_log_probs * mask.float()
            
            return masked_log_probs.sum(dim=-1) / mask.sum(dim=-1)
        
        # è®¡ç®—ç­–ç•¥æ¨¡å‹çš„logæ¦‚ç‡
        policy_chosen_log_probs = get_log_probs(chosen_logits, chosen_labels)
        policy_rejected_log_probs = get_log_probs(rejected_logits, rejected_labels)
        
        # è®¡ç®—å‚è€ƒæ¨¡å‹çš„logæ¦‚ç‡
        ref_chosen_log_probs = get_log_probs(ref_chosen_logits, chosen_labels)
        ref_rejected_log_probs = get_log_probs(ref_rejected_logits, rejected_labels)
        
        # è®¡ç®—DPOæŸå¤±
        policy_diff = policy_chosen_log_probs - policy_rejected_log_probs
        ref_diff = ref_chosen_log_probs - ref_rejected_log_probs
        
        loss = -torch.log(torch.sigmoid(self.beta * (policy_diff - ref_diff))).mean()
        
        return loss


def create_trainer(training_type: str, model, tokenizer, device='cpu', **kwargs):
    """åˆ›å»ºè®­ç»ƒå™¨å·¥å‚å‡½æ•°"""
    if training_type == 'pretrain':
        return PreTrainer(model, tokenizer, device)
    elif training_type == 'sft':
        return SFTTrainer(model, tokenizer, device)
    elif training_type == 'dpo':
        reference_model = kwargs.get('reference_model')
        if reference_model is None:
            raise ValueError("DPOè®­ç»ƒéœ€è¦æä¾›å‚è€ƒæ¨¡å‹")
        return DPOTrainer(model, reference_model, tokenizer, device, kwargs.get('beta', 0.1))
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„è®­ç»ƒç±»å‹: {training_type}")


if __name__ == "__main__":
    # æµ‹è¯•è®­ç»ƒå™¨
    print("è®­ç»ƒå™¨æ¨¡å—æµ‹è¯•å®Œæˆ")