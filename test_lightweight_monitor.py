#!/usr/bin/env python3
"""
æµ‹è¯•è½»é‡çº§ç›‘æ§çš„æ€§èƒ½å½±å“
å¯¹æ¯”å®Œæ•´ç›‘æ§ vs è½»é‡çº§ç›‘æ§ vs æ— ç›‘æ§çš„è®­ç»ƒé€Ÿåº¦
"""
import os
import sys
import time
import torch
import torch.nn as nn

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.append(os.path.join(project_root, 'src'))

from training.training_monitor import TrainingMonitor


def create_test_model(size="small"):
    """åˆ›å»ºæµ‹è¯•æ¨¡å‹"""
    if size == "small":
        return nn.Sequential(
            nn.Linear(512, 1024),
            nn.ReLU(),
            nn.Linear(1024, 1024),
            nn.ReLU(),
            nn.Linear(1024, 512)
        )
    else:  # medium - ç±»ä¼¼çœŸå®è®­ç»ƒ
        return nn.Sequential(
            nn.Linear(1024, 2048),
            nn.ReLU(),
            nn.Linear(2048, 4096),
            nn.ReLU(),
            nn.Linear(4096, 2048),
            nn.ReLU(),
            nn.Linear(2048, 1024)
        )


def benchmark_training(model, num_steps=500, monitor_mode="none"):
    """
    åŸºå‡†æµ‹è¯•è®­ç»ƒé€Ÿåº¦

    Args:
        model: PyTorchæ¨¡å‹
        num_steps: è®­ç»ƒæ­¥æ•°
        monitor_mode: ç›‘æ§æ¨¡å¼ ("none", "lightweight", "full")
    """
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model = model.to(device)

    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)
    criterion = nn.MSELoss()

    # åˆå§‹åŒ–ç›‘æ§å™¨
    monitor = None
    if monitor_mode == "lightweight":
        monitor = TrainingMonitor(
            model=model,
            log_dir=f"benchmark_logs/lightweight_{int(time.time())}",
            enable_tensorboard=True,
            enable_real_time_plots=False,
            lightweight_mode=True,
            log_interval=10
        )
    elif monitor_mode == "full":
        monitor = TrainingMonitor(
            model=model,
            log_dir=f"benchmark_logs/full_{int(time.time())}",
            enable_tensorboard=True,
            enable_real_time_plots=False,
            lightweight_mode=False,
            log_interval=1
        )

    # è®­ç»ƒå¾ªç¯
    model.train()
    start_time = time.time()
    step_times = []

    for step in range(num_steps):
        step_start = time.time()

        # æ¨¡æ‹Ÿè®­ç»ƒ
        batch_size = 32
        x = torch.randn(batch_size, 1024 if "2048" in str(model) else 512, device=device)
        y = torch.randn(batch_size, 1024 if "2048" in str(model) else 512, device=device)

        optimizer.zero_grad()
        output = model(x)
        loss = criterion(output, y)
        loss.backward()
        optimizer.step()

        # ä½¿ç”¨ç›‘æ§å™¨
        if monitor:
            monitor.log_step(
                step=step,
                epoch=0,
                loss=loss.item(),
                learning_rate=1e-4,
                batch_size=batch_size
            )

        step_time = time.time() - step_start
        step_times.append(step_time)

        if step % 100 == 0:
            avg_step_time = sum(step_times[-100:]) / len(step_times[-100:])
            print(f"[{monitor_mode.upper()}] Step {step:4d} | "
                  f"Loss: {loss.item():.4f} | "
                  f"Step time: {avg_step_time*1000:.2f}ms")

    total_time = time.time() - start_time
    avg_step_time = sum(step_times) / len(step_times)

    # å…³é—­ç›‘æ§å™¨
    if monitor:
        monitor.close()

    return {
        'mode': monitor_mode,
        'total_time': total_time,
        'avg_step_time': avg_step_time,
        'steps_per_sec': 1.0 / avg_step_time,
        'overhead_ms': avg_step_time * 1000
    }


def main():
    print("=" * 70)
    print("ğŸ§ª è½»é‡çº§ç›‘æ§æ€§èƒ½æµ‹è¯•")
    print("=" * 70)

    # æµ‹è¯•é…ç½®
    num_steps = 500
    model_size = "medium"  # ä½¿ç”¨ä¸­ç­‰å¤§å°æ¨¡å‹ï¼Œæ›´æ¥è¿‘å®é™…æƒ…å†µ

    print(f"\né…ç½®:")
    print(f"  æ¨¡å‹å¤§å°: {model_size}")
    print(f"  è®­ç»ƒæ­¥æ•°: {num_steps}")
    print(f"  è®¾å¤‡: {'CUDA' if torch.cuda.is_available() else 'CPU'}")

    # æµ‹è¯•ä¸‰ç§æ¨¡å¼
    results = []

    print(f"\n{'='*70}")
    print("1ï¸âƒ£  æµ‹è¯•ï¼šæ— ç›‘æ§")
    print("="*70)
    model1 = create_test_model(model_size)
    result1 = benchmark_training(model1, num_steps, "none")
    results.append(result1)
    del model1
    torch.cuda.empty_cache() if torch.cuda.is_available() else None
    time.sleep(2)

    print(f"\n{'='*70}")
    print("2ï¸âƒ£  æµ‹è¯•ï¼šè½»é‡çº§ç›‘æ§ (æ¯10æ­¥å®Œæ•´è®°å½•)")
    print("="*70)
    model2 = create_test_model(model_size)
    result2 = benchmark_training(model2, num_steps, "lightweight")
    results.append(result2)
    del model2
    torch.cuda.empty_cache() if torch.cuda.is_available() else None
    time.sleep(2)

    print(f"\n{'='*70}")
    print("3ï¸âƒ£  æµ‹è¯•ï¼šå®Œæ•´ç›‘æ§ (æ¯æ­¥å®Œæ•´è®°å½•)")
    print("="*70)
    model3 = create_test_model(model_size)
    result3 = benchmark_training(model3, num_steps, "full")
    results.append(result3)
    del model3
    torch.cuda.empty_cache() if torch.cuda.is_available() else None

    # æ‰“å°å¯¹æ¯”ç»“æœ
    print(f"\n{'='*70}")
    print("ğŸ“Š æ€§èƒ½å¯¹æ¯”ç»“æœ")
    print("="*70)

    baseline = results[0]['avg_step_time']

    print(f"\n{'æ¨¡å¼':<20} {'æ€»æ—¶é—´(s)':<15} {'å¹³å‡æ­¥æ—¶(ms)':<18} {'æ­¥æ•°/ç§’':<15} {'æ€§èƒ½æŸå¤±':<15}")
    print("-" * 85)

    for result in results:
        overhead_pct = ((result['avg_step_time'] - baseline) / baseline * 100) if baseline > 0 else 0
        print(f"{result['mode']:<20} "
              f"{result['total_time']:<15.2f} "
              f"{result['overhead_ms']:<18.2f} "
              f"{result['steps_per_sec']:<15.2f} "
              f"{overhead_pct:>6.2f}%")

    # æ€»ç»“å»ºè®®
    print(f"\n{'='*70}")
    print("ğŸ’¡ æ€§èƒ½åˆ†æä¸å»ºè®®")
    print("="*70)

    lightweight_overhead = ((results[1]['avg_step_time'] - baseline) / baseline * 100)
    full_overhead = ((results[2]['avg_step_time'] - baseline) / baseline * 100)

    print(f"\n1. è½»é‡çº§ç›‘æ§æ€§èƒ½å½±å“: {lightweight_overhead:.2f}%")
    print(f"2. å®Œæ•´ç›‘æ§æ€§èƒ½å½±å“: {full_overhead:.2f}%")
    print(f"3. è½»é‡çº§ç›¸æ¯”å®Œæ•´ç›‘æ§èŠ‚çœ: {full_overhead - lightweight_overhead:.2f}%")

    print("\næ¨èä½¿ç”¨åœºæ™¯:")
    if lightweight_overhead < 2:
        print("  âœ… è½»é‡çº§ç›‘æ§å¼€é”€æå° (<2%)ï¼Œæ¨èåœ¨æ‰€æœ‰è®­ç»ƒä¸­ä½¿ç”¨")
    elif lightweight_overhead < 5:
        print("  âœ… è½»é‡çº§ç›‘æ§å¼€é”€å¯æ¥å— (<5%)ï¼Œæ¨èåœ¨é•¿æ—¶é—´è®­ç»ƒä¸­ä½¿ç”¨")
    else:
        print("  âš ï¸  è½»é‡çº§ç›‘æ§å¼€é”€è¾ƒå¤§ (>5%)ï¼Œå»ºè®®ä»…åœ¨è°ƒè¯•æ—¶ä½¿ç”¨")

    if full_overhead > 10:
        print("  âš ï¸  å®Œæ•´ç›‘æ§å¼€é”€æ˜¾è‘— (>10%)ï¼Œä»…å»ºè®®åœ¨çŸ­æœŸè°ƒè¯•æ—¶ä½¿ç”¨")

    print(f"\n{'='*70}")
    print("âœ… æµ‹è¯•å®Œæˆï¼")
    print("="*70)


if __name__ == "__main__":
    main()

