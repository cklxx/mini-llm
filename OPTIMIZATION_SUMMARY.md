# A6000 GPU è®­ç»ƒä¼˜åŒ–æ€»ç»“

## ğŸ¯ ä¼˜åŒ–ç›®æ ‡
- **é—®é¢˜**: GPUåˆ©ç”¨ç‡ä»…30%ï¼Œæ˜¾å­˜å ç”¨å¤§
- **ç¡¬ä»¶**: NVIDIA A6000 (48GB VRAM), 16æ ¸CPU, 60GBå†…å­˜
- **ç›®æ ‡**: æå‡GPUåˆ©ç”¨ç‡è‡³70-90%ï¼ŒåŠ é€Ÿè®­ç»ƒ2-3å€

## ğŸ“Š ä¼˜åŒ–å¯¹æ¯”

### 1. Batch Sizeé…ç½®
| é¡¹ç›® | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æ”¹è¿› |
|------|--------|--------|------|
| batch_size | 12 | **32** | **+167%** |
| gradient_accumulation | 10 | **4** | ä¼˜åŒ–æµç¨‹ |
| æœ‰æ•ˆbatch | 120 | **128** | ä¿æŒç¨³å®š |

**æ–‡ä»¶**: `config/training_config.py:137-138`

### 2. æ•°æ®åŠ è½½ä¼˜åŒ–
| é¡¹ç›® | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æ”¹è¿› |
|------|--------|--------|------|
| num_workers | 0 | **8** | **å¹¶è¡ŒåŠ è½½** |
| prefetch_factor | None | **4** | **é¢„å–32ä¸ªbatch** |
| pin_memory | False | **True** | **åŠ é€Ÿä¼ è¾“** |
| persistent_workers | False | **True** | **å‡å°‘å¼€é”€** |

**æ–‡ä»¶**: `config/training_config.py:107-114`, `scripts/train.py:196-205`

### 3. æ··åˆç²¾åº¦è®­ç»ƒ
| é¡¹ç›® | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æ”¹è¿› |
|------|--------|--------|------|
| ç²¾åº¦ | FP32 | **FP16** | **æ˜¾å­˜å‡åŠ** |
| Tensor Core | æœªä½¿ç”¨ | **å¯ç”¨** | **2-3å€åŠ é€Ÿ** |
| GradScaler | æ—  | **å¯ç”¨** | **ç¨³å®šè®­ç»ƒ** |

**æ–‡ä»¶**: `scripts/train.py:316-320, 385-401`

### 4. å…¶ä»–ä¼˜åŒ–
| ä¼˜åŒ–é¡¹ | çŠ¶æ€ | è¯´æ˜ |
|--------|------|------|
| æ¢¯åº¦ç´¯ç§¯é€»è¾‘ | âœ… | å‡å°‘optimizer.step()è°ƒç”¨ |
| Non-blockingä¼ è¾“ | âœ… | CPU-GPUå¼‚æ­¥ä¼ è¾“ |
| æ¢¯åº¦æ£€æŸ¥ç‚¹ | âœ… | èŠ‚çœæ˜¾å­˜ |
| TF32åŠ é€Ÿ | âœ… | Ampereæ¶æ„ä¼˜åŒ– |

## ğŸš€ é¢„æœŸæ€§èƒ½æå‡

### è®­ç»ƒé€Ÿåº¦
- **GPUåˆ©ç”¨ç‡**: 30% â†’ **70-90%** (æå‡ **2-3å€**)
- **æ¯æ­¥è®­ç»ƒæ—¶é—´**: åŸºçº¿ â†’ **0.4-0.5å€** (å¿« **2-2.5å€**)
- **ååé‡**: åŸºçº¿ â†’ **2-3å€**

### èµ„æºåˆ©ç”¨
- **æ˜¾å­˜å ç”¨**: ~30GB â†’ **~20-25GB** (èŠ‚çœ **20-30%**)
- **æ˜¾å­˜åˆ©ç”¨ç‡**: ~62% â†’ **~50%** (æ›´é«˜æ•ˆ)
- **CPUåˆ©ç”¨ç‡**: ~10% â†’ **~50%** (8 workers)

### è®­ç»ƒæ•ˆç‡
- **æ•°æ®åŠ è½½ç“¶é¢ˆ**: æ¶ˆé™¤ (8 workers + é¢„å–)
- **GPUç©ºé—²æ—¶é—´**: å¤§å¹…å‡å°‘
- **batchå¤„ç†é€Ÿåº¦**: æå‡2-3å€

## ğŸ“ ä¿®æ”¹æ–‡ä»¶æ¸…å•

### 1. `config/training_config.py`
```python
# Line 137-150: Batch sizeä¼˜åŒ–
batch_size = 32  # 12 â†’ 32
gradient_accumulation_steps = 4  # 10 â†’ 4

# Line 107-114: æ•°æ®åŠ è½½ä¼˜åŒ–
num_workers = 8  # 0 â†’ 8
prefetch_factor = 4  # None â†’ 4
```

### 2. `scripts/train.py`
```python
# Line 196-205: DataLoaderé…ç½®
num_workers=config.num_workers,  # æ–°å¢
pin_memory=config.pin_memory,  # æ–°å¢
persistent_workers=config.persistent_workers,  # æ–°å¢
prefetch_factor=config.prefetch_factor,  # æ–°å¢

# Line 316-325: æ··åˆç²¾åº¦è®­ç»ƒ
scaler = torch.cuda.amp.GradScaler()  # æ–°å¢

# Line 356-449: è®­ç»ƒå¾ªç¯é‡æ„
- æ·»åŠ æ¢¯åº¦ç´¯ç§¯é€»è¾‘
- æ·»åŠ æ··åˆç²¾åº¦æ”¯æŒ
- æ·»åŠ non-blockingä¼ è¾“
```

### 3. æ–°å¢æ–‡æ¡£
- `docs/A6000_OPTIMIZATION_GUIDE.md`: è¯¦ç»†ä¼˜åŒ–æŒ‡å—
- `scripts/verify_optimization.py`: éªŒè¯è„šæœ¬
- `scripts/check_optimization.sh`: å¿«é€Ÿæ£€æŸ¥è„šæœ¬

## ğŸ”§ ä½¿ç”¨æ–¹æ³•

### 1. éªŒè¯ä¼˜åŒ–é…ç½®
```bash
# å¿«é€Ÿæ£€æŸ¥
bash scripts/check_optimization.sh

# è¯¦ç»†éªŒè¯ï¼ˆéœ€è¦PyTorchç¯å¢ƒï¼‰
python3 scripts/verify_optimization.py
```

### 2. å¼€å§‹è®­ç»ƒ
```bash
# Mediumæ¨¡å‹ (è‡ªåŠ¨åº”ç”¨æ‰€æœ‰ä¼˜åŒ–)
python3 scripts/train.py --mode pretrain --config medium

# æŸ¥çœ‹é…ç½®
python3 -c "from config.training_config import get_medium_config; get_medium_config()"
```

### 3. ç›‘æ§æ€§èƒ½
```bash
# å®æ—¶ç›‘æ§GPU
watch -n 1 nvidia-smi

# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
tail -f logs/training.log
```

## ğŸ“ˆ æ€§èƒ½ç›‘æ§æŒ‡æ ‡

### æœŸæœ›çœ‹åˆ°çš„æ”¹è¿›
- âœ… GPUåˆ©ç”¨ç‡: 70-90%
- âœ… GPUæ˜¾å­˜: 20-25GB (FP16)
- âœ… æ¯æ­¥æ—¶é—´: å‡å°‘50-60%
- âœ… æ•°æ®åŠ è½½: æ— æ˜æ˜¾ç­‰å¾…

### å¦‚ä½•éªŒè¯ä¼˜åŒ–ç”Ÿæ•ˆ
1. **GPUåˆ©ç”¨ç‡**:
   ```bash
   nvidia-smi dmon -s u
   # åº”è¯¥çœ‹åˆ°småˆ—(GPUåˆ©ç”¨ç‡)åœ¨70-90%
   ```

2. **æ˜¾å­˜ä½¿ç”¨**:
   ```bash
   nvidia-smi
   # Memory-Usageåº”è¯¥åœ¨20-25GBå·¦å³
   ```

3. **è®­ç»ƒæ—¥å¿—**:
   ```
   å¼€å§‹è®­ç»ƒï¼Œæœ€å¤§æ­¥æ•°: 100000
   Batch size: 32, æ¢¯åº¦ç´¯ç§¯: 4, æœ‰æ•ˆbatch: 128
   âœ… å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ (FP16)
   ```

## ğŸ“ ä¼˜åŒ–åŸç†

### ä¸ºä»€ä¹ˆGPUåˆ©ç”¨ç‡ä½ï¼Ÿ
1. **æ•°æ®åŠ è½½æ…¢** (num_workers=0)
   - å•è¿›ç¨‹åŠ è½½ï¼ŒGPUç­‰å¾…æ•°æ®
   - **è§£å†³**: 8ä¸ªworkerå¹¶è¡ŒåŠ è½½

2. **Batch sizeå¤ªå°** (batch_size=12)
   - GPUç®—åŠ›æœªå……åˆ†åˆ©ç”¨
   - **è§£å†³**: æå‡è‡³32

3. **æœªä½¿ç”¨æ··åˆç²¾åº¦**
   - æ˜¾å­˜å’Œå¸¦å®½æµªè´¹
   - **è§£å†³**: å¯ç”¨FP16

### ä¼˜åŒ–å¦‚ä½•æå‡æ€§èƒ½ï¼Ÿ

```
ä¼˜åŒ–å‰:
[CPUåŠ è½½] â†’ ç­‰å¾… â†’ [GPUè®¡ç®—(30%)] â†’ ç­‰å¾… â†’ [CPUåŠ è½½] â†’ ...
                â†‘ æ•°æ®ç“¶é¢ˆ        â†‘ batchå¤ªå°

ä¼˜åŒ–å:
[Worker1] â†’ é¢„å–4æ‰¹
[Worker2] â†’ é¢„å–4æ‰¹     [GPUè®¡ç®—(85%)]
[Worker3] â†’ é¢„å–4æ‰¹  â†’  æŒç»­ä¾›åº”   â†’ FP16åŠ é€Ÿ
...                     å¤§batch(32)   Tensor Core
[Worker8] â†’ é¢„å–4æ‰¹
```

## âš ï¸ æ•…éšœæ’æŸ¥

### å¦‚æœæ˜¾å­˜ä¸è¶³
```python
# è°ƒæ•´ config/training_config.py
batch_size = 24  # é™ä½
gradient_accumulation_steps = 5  # å¢åŠ 
```

### å¦‚æœæ•°æ®åŠ è½½æ…¢
```python
# è°ƒæ•´ config/training_config.py
num_workers = 12  # å¢åŠ 
prefetch_factor = 6  # å¢åŠ 
```

### å¦‚æœè®­ç»ƒä¸ç¨³å®š
```python
# ç¦ç”¨æ··åˆç²¾åº¦
mixed_precision = False
```

## ğŸ¯ è¿›ä¸€æ­¥ä¼˜åŒ–å»ºè®®

### 1. ç¼–è¯‘ä¼˜åŒ– (PyTorch 2.0+)
```python
model = torch.compile(model, mode="reduce-overhead")
```

### 2. Flash Attention 2
```bash
pip install flash-attn --no-build-isolation
```

### 3. æ•°æ®é¢„å¤„ç†ä¼˜åŒ–
- é¢„å…ˆtokenizeæ•°æ®å¹¶ç¼“å­˜
- ä½¿ç”¨mmapåŠ è½½å¤§æ–‡ä»¶
- WebDatasetæ ¼å¼

### 4. åˆ†å¸ƒå¼è®­ç»ƒ
```bash
torchrun --nproc_per_node=2 scripts/train.py
```

## ğŸ“š å‚è€ƒèµ„æ–™
- [PyTorch Performance Tuning](https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html)
- [Mixed Precision Training](https://pytorch.org/docs/stable/amp.html)
- [Efficient DataLoader](https://pytorch.org/docs/stable/data.html)
- [NVIDIA A6000 Specs](https://www.nvidia.com/en-us/design-visualization/rtx-a6000/)

---

**ä¼˜åŒ–å®Œæˆæ—¥æœŸ**: 2025-10-08
**ä¼˜åŒ–ç‰ˆæœ¬**: v1.0
**é¢„æœŸåŠ é€Ÿæ¯”**: 2-3x
**æ˜¾å­˜èŠ‚çœ**: 20-30%
