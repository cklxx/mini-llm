#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è®¡ç®—Mediumæ¨¡å‹ä¸Smallæ¨¡å‹çš„èµ„æºå¯¹æ¯”
"""
import os
import sys
import torch
import time

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from model.transformer import create_model


def calculate_model_params(model):
    """è®¡ç®—æ¨¡å‹å‚æ•°é‡"""
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    return total_params, trainable_params


def estimate_memory_usage(model, batch_size, seq_length):
    """ä¼°ç®—å†…å­˜ä½¿ç”¨é‡"""
    # æ¨¡å‹å‚æ•°å†…å­˜ (å‡è®¾float32)
    model_memory = sum(p.numel() * 4 for p in model.parameters()) / (1024**2)  # MB
    
    # å‰å‘ä¼ æ’­æ¿€æ´»å€¼å†…å­˜ä¼°ç®—
    d_model = model.d_model
    n_layers = len(model.transformer_blocks)
    
    # æ¯å±‚çš„æ¿€æ´»å€¼å†…å­˜ä¼°ç®—
    attention_memory = batch_size * seq_length * d_model * 4 / (1024**2)  # Q,K,V,O
    ffn_memory = batch_size * seq_length * model.transformer_blocks[0].feed_forward.w_1.out_features * 4 / (1024**2)
    
    # æ€»æ¿€æ´»å€¼å†…å­˜ (ä¹˜ä»¥å±‚æ•°)
    activation_memory = (attention_memory + ffn_memory) * n_layers
    
    # æ¢¯åº¦å†…å­˜ (ä¸å‚æ•°é‡ç›¸åŒ)
    gradient_memory = model_memory
    
    # ä¼˜åŒ–å™¨çŠ¶æ€å†…å­˜ (Adaméœ€è¦2å€å‚æ•°é‡)
    optimizer_memory = model_memory * 2
    
    total_memory = model_memory + activation_memory + gradient_memory + optimizer_memory
    
    return {
        'model_memory': model_memory,
        'activation_memory': activation_memory,
        'gradient_memory': gradient_memory,
        'optimizer_memory': optimizer_memory,
        'total_memory': total_memory
    }


def estimate_training_time_ratio(small_params, medium_params, small_batch, medium_batch):
    """ä¼°ç®—è®­ç»ƒæ—¶é—´æ¯”ä¾‹"""
    # å‡è®¾è®­ç»ƒæ—¶é—´ä¸»è¦ç”±å‚æ•°é‡å’Œæ‰¹æ¬¡å¤§å°å†³å®š
    param_ratio = medium_params / small_params
    
    # è€ƒè™‘æ‰¹æ¬¡å¤§å°çš„å½±å“ (å°æ‰¹æ¬¡éœ€è¦æ›´å¤šæ­¥éª¤)
    batch_ratio = small_batch / medium_batch
    
    # ç»¼åˆæ—¶é—´æ¯”ä¾‹ä¼°ç®—
    time_ratio = param_ratio * batch_ratio
    
    return time_ratio


def main():
    print("=== Medium vs Small æ¨¡å‹èµ„æºå¯¹æ¯”åˆ†æ ===\n")
    
    # æ¨¡å‹é…ç½®
    vocab_size = 10000
    
    # åˆ›å»ºæ¨¡å‹
    print("åˆ›å»ºæ¨¡å‹...")
    small_model = create_model(vocab_size, "small")
    medium_model = create_model(vocab_size, "medium")
    
    # è®¡ç®—å‚æ•°é‡
    small_params, small_trainable = calculate_model_params(small_model)
    medium_params, medium_trainable = calculate_model_params(medium_model)
    
    print(f"\nğŸ“Š å‚æ•°é‡å¯¹æ¯”:")
    print(f"  Smallæ¨¡å‹:  {small_params:,} å‚æ•° ({small_params/1e6:.1f}M)")
    print(f"  Mediumæ¨¡å‹: {medium_params:,} å‚æ•° ({medium_params/1e6:.1f}M)")
    print(f"  å‚æ•°é‡æ¯”ä¾‹: {medium_params/small_params:.2f}x")
    
    # é…ç½®ä¿¡æ¯
    small_config = {
        "batch_size": 8,
        "seq_length": 256,
        "d_model": 512,
        "n_layers": 6
    }
    
    medium_config = {
        "batch_size": 2,
        "seq_length": 512,
        "d_model": 640,
        "n_layers": 10
    }
    
    print(f"\nâš™ï¸  é…ç½®å¯¹æ¯”:")
    print(f"  Small:  batch_size={small_config['batch_size']}, seq_len={small_config['seq_length']}, d_model={small_config['d_model']}, layers={small_config['n_layers']}")
    print(f"  Medium: batch_size={medium_config['batch_size']}, seq_len={medium_config['seq_length']}, d_model={medium_config['d_model']}, layers={medium_config['n_layers']}")
    
    # å†…å­˜ä½¿ç”¨ä¼°ç®—
    small_memory = estimate_memory_usage(small_model, small_config["batch_size"], small_config["seq_length"])
    medium_memory = estimate_memory_usage(medium_model, medium_config["batch_size"], medium_config["seq_length"])
    
    print(f"\nğŸ’¾ å†…å­˜ä½¿ç”¨ä¼°ç®—:")
    print(f"  Smallæ¨¡å‹:")
    print(f"    - æ¨¡å‹å‚æ•°: {small_memory['model_memory']:.1f} MB")
    print(f"    - æ¿€æ´»å€¼:   {small_memory['activation_memory']:.1f} MB")
    print(f"    - æ¢¯åº¦:     {small_memory['gradient_memory']:.1f} MB")
    print(f"    - ä¼˜åŒ–å™¨:   {small_memory['optimizer_memory']:.1f} MB")
    print(f"    - æ€»è®¡:     {small_memory['total_memory']:.1f} MB ({small_memory['total_memory']/1024:.2f} GB)")
    
    print(f"\n  Mediumæ¨¡å‹:")
    print(f"    - æ¨¡å‹å‚æ•°: {medium_memory['model_memory']:.1f} MB")
    print(f"    - æ¿€æ´»å€¼:   {medium_memory['activation_memory']:.1f} MB")
    print(f"    - æ¢¯åº¦:     {medium_memory['gradient_memory']:.1f} MB")
    print(f"    - ä¼˜åŒ–å™¨:   {medium_memory['optimizer_memory']:.1f} MB")
    print(f"    - æ€»è®¡:     {medium_memory['total_memory']:.1f} MB ({medium_memory['total_memory']/1024:.2f} GB)")
    
    memory_ratio = medium_memory['total_memory'] / small_memory['total_memory']
    print(f"\n  å†…å­˜ä½¿ç”¨æ¯”ä¾‹: {memory_ratio:.2f}x")
    
    # è®­ç»ƒæ—¶é—´ä¼°ç®—
    time_ratio = estimate_training_time_ratio(
        small_params, medium_params,
        small_config["batch_size"], medium_config["batch_size"]
    )
    
    print(f"\nâ±ï¸  è®­ç»ƒæ—¶é—´ä¼°ç®—:")
    print(f"  å‚æ•°é‡å½±å“: {medium_params/small_params:.2f}x")
    print(f"  æ‰¹æ¬¡å¤§å°å½±å“: {small_config['batch_size']/medium_config['batch_size']:.2f}x")
    print(f"  é¢„ä¼°æ—¶é—´æ¯”ä¾‹: {time_ratio:.2f}x")
    
    # è®­ç»ƒæ­¥æ•°å¯¹æ¯”
    small_steps = 1500  # from small config
    medium_steps = 4000  # from medium config
    
    effective_batch_small = small_config["batch_size"] * 4  # gradient_accumulation_steps
    effective_batch_medium = medium_config["batch_size"] * 12  # gradient_accumulation_steps
    
    print(f"\nğŸ“ˆ è®­ç»ƒè®¾ç½®å¯¹æ¯”:")
    print(f"  Small:  {small_steps} æ­¥, æœ‰æ•ˆæ‰¹æ¬¡={effective_batch_small}")
    print(f"  Medium: {medium_steps} æ­¥, æœ‰æ•ˆæ‰¹æ¬¡={effective_batch_medium}")
    print(f"  æ€»æ­¥æ•°æ¯”ä¾‹: {medium_steps/small_steps:.2f}x")
    
    # å®é™…è®­ç»ƒæ—¶é—´é¢„ä¼°
    if small_memory['total_memory'] < 4000:  # 4GB
        small_estimated_time = 45  # 45åˆ†é’Ÿ
    else:
        small_estimated_time = 60  # 1å°æ—¶
        
    medium_estimated_time = small_estimated_time * time_ratio * (medium_steps/small_steps)
    
    print(f"\nğŸ• å®é™…è®­ç»ƒæ—¶é—´é¢„ä¼°:")
    print(f"  Smallæ¨¡å‹:  çº¦ {small_estimated_time} åˆ†é’Ÿ")
    print(f"  Mediumæ¨¡å‹: çº¦ {medium_estimated_time:.0f} åˆ†é’Ÿ ({medium_estimated_time/60:.1f} å°æ—¶)")
    print(f"  æ—¶é—´å¢åŠ :   {medium_estimated_time/small_estimated_time:.1f}x")
    
    # æ¨èé…ç½®
    print(f"\nğŸ’¡ æ¨èé…ç½®:")
    if medium_memory['total_memory'] > 6000:  # > 6GB
        print("  âš ï¸  Mediumæ¨¡å‹å†…å­˜éœ€æ±‚è¾ƒé«˜ï¼Œå»ºè®®:")
        print("     - ç¡®ä¿Macæœ‰å……è¶³å†…å­˜ (16GB+)")
        print("     - å…³é—­å…¶ä»–åº”ç”¨ç¨‹åº")
        print("     - è€ƒè™‘é™ä½batch_sizeåˆ°1")
        print("     - å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ (å¦‚æœå®ç°)")
    
    print(f"\nğŸ“‹ æ€»ç»“:")
    print(f"  Mediumæ¨¡å‹æ¯”Smallæ¨¡å‹:")
    print(f"  - å‚æ•°é‡å¢åŠ : {medium_params/small_params:.1f}å€")
    print(f"  - å†…å­˜éœ€æ±‚å¢åŠ : {memory_ratio:.1f}å€")
    print(f"  - è®­ç»ƒæ—¶é—´å¢åŠ : {medium_estimated_time/small_estimated_time:.1f}å€")
    print(f"  - ç†è®ºæ€§èƒ½æå‡: é¢„è®¡æ›´å¥½çš„ç”Ÿæˆè´¨é‡å’Œè¯­è¨€ç†è§£èƒ½åŠ›")


if __name__ == "__main__":
    main() 