#!/usr/bin/env python3
"""Orchestrate progressive MiniGPT training runs aligned with the scaling plan."""

from __future__ import annotations

import argparse
import os
import sys
from collections import OrderedDict
from collections.abc import Iterable
from dataclasses import dataclass, field

PROJECT_ROOT = os.path.dirname(os.path.dirname(__file__))
SRC_DIR = os.path.join(PROJECT_ROOT, "src")

if PROJECT_ROOT not in sys.path:
    sys.path.append(PROJECT_ROOT)
if SRC_DIR not in sys.path:
    sys.path.append(SRC_DIR)


@dataclass
class PhaseDefinition:
    """Describe a single training pass for a stage."""

    name: str
    mode: str
    description: str
    overrides: dict[str, int | float | bool] = field(default_factory=dict)
    resume_from_previous: bool = False
    auto_resume: bool = False
    retrain_tokenizer: bool = False
    config: str | None = None


@dataclass
class StageDefinition:
    """Describe a progressive stage composed of one or more phases."""

    id: str
    title: str
    target_params: str
    base_config: str
    focus: str
    dataset_scope: str
    checkpoints: str
    iteration_guidance: str
    phases: list[PhaseDefinition]


PROGRESSIVE_STAGES: OrderedDict[str, StageDefinition] = OrderedDict(
    (
        (
            "stage0",
            StageDefinition(
                id="stage0",
                title="Tokenizer ä¸æ•°æ®ç®¡çº¿å†’çƒŸéªŒè¯",
                target_params="â‰¤20M",
                base_config="small",
                focus="éªŒè¯ Tokenizer/æ•°æ®æ¸…æ´—/æ—¥å¿—æ˜¯å¦å·¥ä½œï¼Œå¿«é€Ÿè§‚å¯ŸæŸå¤±æ›²çº¿",
                dataset_scope="æŠ½æ · 1â€“2B tokenï¼Œä¸»è¯­è¨€ Python/TypeScript",
                checkpoints="é¦–æ¬¡å…¨é‡è®­ç»ƒï¼Œæ— éœ€ç»§æ‰¿ checkpoint",
                iteration_guidance="åœ¨å®Œæˆå†’çƒŸéªŒè¯åå†æ¬¡è¿­ä»£ 1â€“2 æ¬¡ä»¥ç¡®è®¤ä¿®å¤åçš„æ•°æ®/é…ç½®ç¨³å®š",
                phases=[
                    PhaseDefinition(
                        name="é˜¶æ®µ0 é¢„è®­ç»ƒ",
                        mode="pretrain",
                        description="ä»¥å°æ‰¹é‡è®­ç»ƒ 2â€“3k æ­¥ï¼Œç¡®è®¤ååä¸æŒ‡æ ‡é‡‡é›†",
                        overrides={
                            "max_steps": 3000,
                            "warmup_steps": 120,
                            "eval_steps": 200,
                            "save_steps": 600,
                        },
                    ),
                ],
            ),
        ),
        (
            "stage1",
            StageDefinition(
                id="stage1",
                title="è½»é‡å¯å¤ç°åŸºçº¿",
                target_params="60â€“80M",
                base_config="medium",
                focus="å»ºç«‹ç¨³å®šçš„å¤šè¯­è¨€è¡¥å…¨åŸºçº¿ï¼Œå¹¶éªŒè¯çŸ­ SFT æ¥å£",
                dataset_scope="4â€“6B token é¢„è®­ç»ƒ + çº¦ 20K æ¡æŒ‡ä»¤å¾®è°ƒæ ·æœ¬",
                checkpoints="ä»é˜¶æ®µ 0 äº§å‡ºçš„æƒé‡å¼€å§‹å¯åŠ é€Ÿæ”¶æ•›",
                iteration_guidance="å»ºè®®è‡³å°‘å¾ªç¯ä¸¤è½®ï¼šç¬¬ä¸€è½®è·å¾—åŸºçº¿ï¼Œç¬¬äºŒè½®é’ˆå¯¹è¯„æµ‹åé¦ˆè°ƒæ•´å­¦ä¹ ç‡/é‡‡æ ·",
                phases=[
                    PhaseDefinition(
                        name="é˜¶æ®µ1 é¢„è®­ç»ƒ",
                        mode="pretrain",
                        description="è·‘æ»¡ 40k æ­¥å·¦å³ï¼Œè§‚å¯Ÿ HumanEval/MBPP åˆå§‹åˆ†æ•°",
                        overrides={
                            "max_steps": 40000,
                            "warmup_steps": 800,
                            "eval_steps": 1000,
                            "save_steps": 4000,
                        },
                        resume_from_previous=True,
                        auto_resume=True,
                    ),
                    PhaseDefinition(
                        name="é˜¶æ®µ1 æŒ‡ä»¤å¾®è°ƒ",
                        mode="sft",
                        description="åŠ è½½é˜¶æ®µ1é¢„è®­ç»ƒæƒé‡ï¼Œè·‘ 2â€“3k æ­¥çŸ­ç¨‹æŒ‡ä»¤å¾®è°ƒ",
                        overrides={
                            "max_steps": 3000,
                            "warmup_steps": 60,
                            "eval_steps": 200,
                            "save_steps": 600,
                        },
                        resume_from_previous=True,
                        auto_resume=True,
                    ),
                ],
            ),
        ),
        (
            "stage2",
            StageDefinition(
                id="stage2",
                title="200M çº§æ€§èƒ½å†²åˆº",
                target_params="180â€“220M",
                base_config="foundation",
                focus="æ‰©å±•ä¸Šä¸‹æ–‡åˆ° 4Kï¼Œè¦†ç›– 15â€“25B token å¹¶æ‰©å¤§æŒ‡ä»¤é›†",
                dataset_scope="ä¸»è¯­è¨€é«˜è´¨é‡ä»“åº“ + 80Kâ€“120K æŒ‡ä»¤/æ‰§è¡Œåé¦ˆ",
                checkpoints="ç»§æ‰¿é˜¶æ®µ1æƒé‡ï¼Œä¿ç•™è¯„æµ‹æŒ‚é’©ä¸è’¸é¦æ¥å£",
                iteration_guidance="åœ¨ä¸åŒæ•°æ®æ··åˆæˆ–è’¸é¦ç­–ç•¥ä¹‹é—´åšå¤šæ¬¡ A/Bï¼Œå¯¹é½å…³é”®æŒ‡æ ‡åå†æ™‹çº§ä¸‹ä¸€é˜¶æ®µ",
                phases=[
                    PhaseDefinition(
                        name="é˜¶æ®µ2 é¢„è®­ç»ƒ",
                        mode="pretrain",
                        description="1â€“1.5 å¤©éå†æ•°æ®ï¼Œä¸»è¦å…³æ³¨æŸå¤±ç¨³å®šæ€§ä¸åå",
                        overrides={
                            "max_steps": 120000,
                            "warmup_steps": 3600,
                            "eval_steps": 3000,
                            "save_steps": 6000,
                        },
                        resume_from_previous=True,
                        auto_resume=True,
                    ),
                    PhaseDefinition(
                        name="é˜¶æ®µ2 æŒ‡ä»¤å¾®è°ƒ",
                        mode="sft",
                        description="ç»§ç»­æ‰©å……é«˜è´¨é‡æŒ‡ä»¤æ ·æœ¬ï¼Œç¡®ä¿ IDE ä½“éªŒ",
                        overrides={
                            "max_steps": 6000,
                            "warmup_steps": 120,
                            "eval_steps": 400,
                            "save_steps": 1200,
                        },
                        resume_from_previous=True,
                        auto_resume=True,
                    ),
                ],
            ),
        ),
        (
            "stage3",
            StageDefinition(
                id="stage3",
                title="å‘ 350M+ æ‰©å±•è¯•ç‚¹",
                target_params=">=350M",
                base_config="large",
                focus="åœ¨ç¡®è®¤ 200M æ»¡è¶³åº”ç”¨éœ€æ±‚åæ‰©å¤§æ·±åº¦ä¸å®½åº¦",
                dataset_scope="æ²¿ç”¨é˜¶æ®µ2æ¸…æ´—æˆæœï¼Œè¿½åŠ å¤§æ¨¡å‹ç‰¹åŒ–ä»»åŠ¡",
                checkpoints="æ‰¿æ¥é˜¶æ®µ2 æŒ‡ä»¤å¾®è°ƒåçš„æœ€æ–° checkpoint",
                iteration_guidance="é€šè¿‡å¤šè½®ç¼©çŸ­ç‰ˆè®­ç»ƒ (å¦‚ 20K æ­¥) å¿«é€ŸéªŒè¯æ˜¾å­˜/ååï¼Œå†è¿›å…¥æ­£å¼å…¨é‡è®­ç»ƒ",
                phases=[
                    PhaseDefinition(
                        name="é˜¶æ®µ3 é¢„è®­ç»ƒ",
                        mode="pretrain",
                        description="ä»¥ç»è¿‡éªŒè¯çš„è¶…å‚å¯åŠ¨ï¼Œé‡ç‚¹ç›‘æ§æ˜¾å­˜ä¸åå",
                        overrides={
                            "max_steps": 160000,
                            "warmup_steps": 4800,
                            "eval_steps": 4000,
                            "save_steps": 8000,
                        },
                        resume_from_previous=True,
                        auto_resume=True,
                    ),
                ],
            ),
        ),
    )
)


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="æ ¹æ®æ¸è¿›å¼é…ç½®æ‰§è¡Œ MiniGPT è®­ç»ƒé˜¶æ®µ",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    parser.add_argument(
        "--stages",
        nargs="+",
        default=["stage0", "stage1", "stage2", "stage3"],
        choices=list(PROGRESSIVE_STAGES.keys()),
        help="é€‰æ‹©éœ€è¦è¿è¡Œçš„é˜¶æ®µï¼Œé»˜è®¤å…¨é‡",
    )
    parser.add_argument(
        "--execute",
        action="store_true",
        help="æ‰§è¡Œå®é™…è®­ç»ƒã€‚é»˜è®¤ä»…æ‰“å°è®¡åˆ’ (dry-run)",
    )
    parser.add_argument(
        "--resume-from",
        type=str,
        default=None,
        help="é¦–ä¸ªé˜¶æ®µ/é˜¶æ®µå†…é¦–ä¸ªå­é˜¶æ®µèµ·ç‚¹çš„ checkpoint è·¯å¾„",
    )
    parser.add_argument(
        "--learning-rate",
        type=float,
        default=None,
        help="è¦†ç›–æ‰€æœ‰é˜¶æ®µçš„å­¦ä¹ ç‡",
    )
    parser.add_argument(
        "--max-steps",
        type=int,
        default=None,
        help="è¦†ç›–æ‰€æœ‰é˜¶æ®µçš„æœ€å¤§è®­ç»ƒæ­¥æ•°",
    )
    parser.add_argument(
        "--warmup-steps",
        type=int,
        default=None,
        help="è¦†ç›–æ‰€æœ‰é˜¶æ®µçš„ warmup æ­¥æ•°",
    )
    parser.add_argument(
        "--batch-size",
        type=int,
        default=None,
        help="è¦†ç›–æ‰€æœ‰é˜¶æ®µçš„ batch size",
    )
    parser.add_argument(
        "--gradient-accumulation-steps",
        type=int,
        default=None,
        help="è¦†ç›–æ‰€æœ‰é˜¶æ®µçš„æ¢¯åº¦ç´¯ç§¯æ­¥æ•°",
    )
    parser.add_argument(
        "--auto-resume",
        action="store_true",
        help="å¼ºåˆ¶æ‰€æœ‰å­é˜¶æ®µå¯ç”¨ auto resume",
    )
    parser.add_argument(
        "--retrain-tokenizer",
        action="store_true",
        help="å¼ºåˆ¶æ‰€æœ‰å­é˜¶æ®µé‡æ–°è®­ç»ƒ tokenizer",
    )
    return parser.parse_args()


def apply_overrides(config, overrides: dict[str, int | float | bool]) -> None:
    for key, value in overrides.items():
        if value is None:
            continue
        if not hasattr(config, key):
            print(f"âš ï¸  é…ç½® {config.model_size} æœªåŒ…å«å±æ€§ {key}ï¼Œå·²è·³è¿‡è¦†ç›–")
            continue
        setattr(config, key, value)


def render_plan(stage_ids: Iterable[str]) -> None:
    print("\n=== æ¸è¿›å¼è®­ç»ƒè·¯çº¿å›¾ ===")
    for stage_id in stage_ids:
        stage = PROGRESSIVE_STAGES[stage_id]
        print(
            f"\n[{stage.id}] {stage.title}\n"
            f"  ç›®æ ‡å‚æ•°é‡: {stage.target_params}\n"
            f"  è®­ç»ƒé…ç½®: {stage.base_config}\n"
            f"  æ ¸å¿ƒç›®æ ‡: {stage.focus}\n"
            f"  æ•°æ®èŒƒå›´: {stage.dataset_scope}\n"
            f"  checkpoint ç­–ç•¥: {stage.checkpoints}\n"
            f"  è¿­ä»£å»ºè®®: {stage.iteration_guidance}"
        )
        for phase in stage.phases:
            print(
                f"    - {phase.name} ({phase.mode})\n"
                f"      æè¿°: {phase.description}\n"
                f"      è¦†ç›–é¡¹: {phase.overrides or 'æ— '}\n"
                f"      ç»§æ‰¿ä¸Šä¸€é˜¶æ®µ: {'æ˜¯' if phase.resume_from_previous else 'å¦'}"
            )


def load_training_dependencies() -> tuple[object, type]:
    """Import heavy training dependencies lazily."""

    try:
        from config.training_config import get_config as get_training_config  # type: ignore
        from training.pipeline.app import MiniGPTTrainer  # type: ignore
    except ModuleNotFoundError as exc:  # pragma: no cover - import error messaging
        if exc.name == "torch":
            raise SystemExit(
                "æœªæ£€æµ‹åˆ° PyTorch (torch) åº“ã€‚è¯·å…ˆå®‰è£… GPU/CPU ç‰ˆ PyTorch åå†ä½¿ç”¨ --execute æ‰§è¡Œè®­ç»ƒã€‚"
            ) from exc
        raise

    return get_training_config, MiniGPTTrainer


def execute_plan(args: argparse.Namespace, stage_ids: Iterable[str]) -> None:
    get_training_config, MiniGPTTrainer = load_training_dependencies()
    last_checkpoint: str | None = args.resume_from

    for stage_id in stage_ids:
        stage = PROGRESSIVE_STAGES[stage_id]
        print(f"\n===== æ‰§è¡Œ {stage.id.upper()} : {stage.title} =====")
        for phase in stage.phases:
            config_name = phase.config or stage.base_config
            config = get_training_config(config_name)

            combined_overrides: dict[str, int | float | bool] = {}
            combined_overrides.update(phase.overrides)

            # Apply CLI overrides last so they always win
            if args.max_steps is not None:
                combined_overrides["max_steps"] = args.max_steps
            if args.warmup_steps is not None:
                combined_overrides["warmup_steps"] = args.warmup_steps
            if args.batch_size is not None:
                combined_overrides["batch_size"] = args.batch_size
            if args.gradient_accumulation_steps is not None:
                combined_overrides["gradient_accumulation_steps"] = args.gradient_accumulation_steps
            if args.learning_rate is not None:
                combined_overrides["learning_rate"] = args.learning_rate

            print(
                f"\nâ†’ {phase.name} [{phase.mode}] | é…ç½®: {config_name}\n"
                f"   æè¿°: {phase.description}"
            )
            apply_overrides(config, combined_overrides)

            for key in sorted(combined_overrides):
                value = getattr(config, key, None)
                print(f"   - {key}: {value}")

            resume_from: str | None = None
            if phase.resume_from_previous:
                resume_from = last_checkpoint
            if resume_from:
                print(f"   å°†ä» {resume_from} æ¢å¤")

            auto_resume = args.auto_resume or phase.auto_resume
            retrain_tokenizer = args.retrain_tokenizer or phase.retrain_tokenizer

            trainer = MiniGPTTrainer(config, mode=phase.mode)
            final_path = trainer.train(
                resume_from=resume_from,
                auto_resume=auto_resume,
                retrain_tokenizer=retrain_tokenizer,
            )
            last_checkpoint = final_path
            print(f"âœ… {phase.name} å®Œæˆï¼Œæ¨¡å‹å·²ä¿å­˜åˆ° {final_path}")


def main() -> None:
    args = parse_args()
    stage_ids = args.stages

    if not args.execute:
        render_plan(stage_ids)
        print("\nğŸ’¡ ä½¿ç”¨ --execute ä»¥å®é™…è¿è¡Œè®­ç»ƒï¼›æ”¯æŒ --resume-from æŒ‡å®šåˆå§‹ checkpointã€‚")
        return

    execute_plan(args, stage_ids)


if __name__ == "__main__":
    main()
