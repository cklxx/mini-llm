#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ä»æ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒè„šæœ¬
æ”¯æŒä»ç°æœ‰checkpointæ¢å¤è®­ç»ƒï¼Œä½¿ç”¨å®Œæ•´çš„é¢„è®­ç»ƒæ•°æ®é›†
"""
import os
import sys
import argparse
import time
import signal
import threading
from datetime import datetime
import torch
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯ï¼Œé€‚åˆæœåŠ¡å™¨ç¯å¢ƒ

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•å’Œsrcç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(__file__))
sys.path.append(project_root)
sys.path.append(os.path.join(project_root, 'src'))

from model.transformer import create_model
from tokenizer.bpe_tokenizer import BPETokenizer
from training.trainer import LanguageModelingDataset
from config.mac_optimized_config import (
    get_mac_medium_config, MacResourceConfig, MacResourceMonitor,
    estimate_model_size, validate_config_for_mac, get_system_info
)


def print_progress_bar(current, total, prefix='', suffix='', length=40, fill='â–ˆ', empty='â–‘'):
    """æ‰“å°åŠ¨æ€è¿›åº¦æ¡"""
    percent = 100 * (current / float(total))
    filled_length = int(length * current // total)
    bar = fill * filled_length + empty * (length - filled_length)
    print(f"\r{prefix} |{bar}| {percent:.1f}% {suffix}", end="", flush=True)


class ContinueTrainer:
    """ä»æ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒçš„è®­ç»ƒå™¨"""
    
    def __init__(self, checkpoint_path, config, resource_config: MacResourceConfig):
        self.checkpoint_path = checkpoint_path
        self.config = config
        self.resource_config = resource_config
        self.resource_monitor = MacResourceMonitor(resource_config)
        self.should_stop = False
        self.pause_training = False
        
        # æŸå¤±å†å²è®°å½•
        self.loss_history = []
        self.step_history = []
        
        # æ³¨å†Œä¿¡å·å¤„ç†å™¨
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
        
    def _signal_handler(self, signum, frame):
        """ä¿¡å·å¤„ç†å™¨"""
        print(f"\næ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨å®‰å…¨é€€å‡º...")
        self.should_stop = True
        
    def _monitor_resources(self):
        """èµ„æºç›‘æ§çº¿ç¨‹"""
        while not self.should_stop:
            try:
                resources = self.resource_monitor.check_resources()
                
                if self.resource_monitor.should_pause_training():
                    if not self.pause_training:
                        print(f"\nâš ï¸  èµ„æºä½¿ç”¨è¿‡é«˜ï¼Œæš‚åœè®­ç»ƒ:")
                        print(f"   CPU: {resources['cpu_percent']:.1f}% (é™åˆ¶: {self.resource_config.max_cpu_percent}%)")
                        print(f"   å†…å­˜: {resources['memory_percent']:.1f}% (é™åˆ¶: {self.resource_config.max_memory_percent}%)")
                        self.pause_training = True
                else:
                    if self.pause_training:
                        print(f"\nâœ… èµ„æºä½¿ç”¨æ¢å¤æ­£å¸¸ï¼Œç»§ç»­è®­ç»ƒ")
                        self.pause_training = False
                
                time.sleep(self.resource_config.monitoring_interval)
                
            except Exception as e:
                print(f"èµ„æºç›‘æ§é”™è¯¯: {e}")
                time.sleep(5)
    
    def load_checkpoint(self):
        """åŠ è½½æ£€æŸ¥ç‚¹"""
        print(f"ğŸ“‚ åŠ è½½æ£€æŸ¥ç‚¹: {self.checkpoint_path}")
        
        if not os.path.exists(self.checkpoint_path):
            raise FileNotFoundError(f"æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {self.checkpoint_path}")
        
        checkpoint = torch.load(self.checkpoint_path, map_location='cpu', weights_only=False)
        
        print(f"âœ… æ£€æŸ¥ç‚¹ä¿¡æ¯:")
        print(f"   æ­¥æ•°: {checkpoint.get('step', 'unknown')}")
        print(f"   æŸå¤±: {checkpoint.get('loss', 'unknown'):.4f}")
        
        # æ¢å¤æŸå¤±å†å²
        if 'loss_history' in checkpoint and 'step_history' in checkpoint:
            self.loss_history = checkpoint['loss_history']
            self.step_history = checkpoint['step_history']
            print(f"   å·²æ¢å¤ {len(self.loss_history)} ä¸ªå†å²æŸå¤±è®°å½•")
            
            # ç»˜åˆ¶æ¢å¤çš„æŸå¤±æ›²çº¿
            if len(self.loss_history) > 0:
                current_step = checkpoint.get('step', 0)
                print(f"ğŸ“Š ç»˜åˆ¶æ¢å¤çš„æŸå¤±æ›²çº¿...")
                self._plot_and_save_loss_curve(current_step, recovered=True)
        else:
            print("   æœªæ‰¾åˆ°å†å²æŸå¤±è®°å½•ï¼Œä»å½“å‰æ­¥å¼€å§‹è®°å½•")
        
        return checkpoint
    
    def setup_for_continue_training(self):
        """è®¾ç½®ç»§ç»­è®­ç»ƒæ‰€éœ€çš„ç»„ä»¶"""
        print("ğŸ”§ è®¾ç½®ç»§ç»­è®­ç»ƒç¯å¢ƒ...")
        
        # åŠ è½½æ£€æŸ¥ç‚¹
        checkpoint = self.load_checkpoint()
        
        # åŠ è½½åˆ†è¯å™¨
        tokenizer_path = os.path.join(os.path.dirname(self.checkpoint_path), "tokenizer.pkl")
        if not os.path.exists(tokenizer_path):
            # å°è¯•ä»checkpointsç›®å½•åŠ è½½
            tokenizer_path = "checkpoints/tokenizer.pkl"
        
        print(f"ğŸ”¤ åŠ è½½åˆ†è¯å™¨: {tokenizer_path}")
        tokenizer = BPETokenizer(vocab_size=self.config.tokenizer.vocab_size)
        tokenizer.load(tokenizer_path)
        
        # åˆ›å»ºæ¨¡å‹
        print("ğŸ§  åˆ›å»ºå¹¶åŠ è½½æ¨¡å‹...")
        device = torch.device(self.config.device)
        model = create_model(tokenizer.vocab_size, self.config.model.model_size)
        model.load_state_dict(checkpoint['model_state_dict'])
        model = model.to(device)
        
        # åˆ›å»ºä¼˜åŒ–å™¨å¹¶åŠ è½½çŠ¶æ€
        print("âš™ï¸ åˆ›å»ºå¹¶åŠ è½½ä¼˜åŒ–å™¨...")
        optimizer = torch.optim.AdamW(
            model.parameters(),
            lr=self.config.pretrain.learning_rate,
            weight_decay=self.config.pretrain.weight_decay
        )
        
        if 'optimizer_state_dict' in checkpoint:
            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        
        # è®¾ç½®æ•°æ®åŠ è½½å™¨ï¼ˆä½¿ç”¨å®Œæ•´æ•°æ®é›†ï¼‰
        print("ğŸ“š è®¾ç½®æ•°æ®åŠ è½½å™¨ï¼ˆå®Œæ•´é¢„è®­ç»ƒæ•°æ®ï¼‰...")
        data_loader = self._setup_data_loader(tokenizer)
        
        return model, tokenizer, optimizer, checkpoint, data_loader
    
    def _setup_data_loader(self, tokenizer):
        """è®¾ç½®æ•°æ®åŠ è½½å™¨ï¼Œä½¿ç”¨å®Œæ•´çš„é¢„è®­ç»ƒæ•°æ®é›†"""
        # ä½¿ç”¨å¤šä¸ªé¢„è®­ç»ƒæ–‡ä»¶
        train_files = [
            "pretrain_hq.jsonl",      # é«˜è´¨é‡é¢„è®­ç»ƒæ•°æ®
            "pretrain_large_sample.jsonl",  # å¤§æ ·æœ¬æ•°æ®
            "sft_1024.jsonl",         # ç›‘ç£å¾®è°ƒæ•°æ®
            "sft_2048.jsonl",         # æ›´é•¿åºåˆ—æ•°æ®
        ]
        
        all_texts = []
        
        for file_name in train_files:
            file_path = os.path.join(self.config.data.data_dir, file_name)
            if os.path.exists(file_path):
                print(f"ğŸ“– åŠ è½½æ•°æ®æ–‡ä»¶: {file_name}")
                
                try:
                    import json
                    with open(file_path, 'r', encoding='utf-8') as f:
                        file_texts = []
                        for line_num, line in enumerate(f):
                            try:
                                data = json.loads(line.strip())
                                if 'text' in data:
                                    file_texts.append(data['text'])
                                elif 'conversation' in data:
                                    # å¤„ç†å¯¹è¯æ ¼å¼
                                    conv_text = ""
                                    for turn in data['conversation']:
                                        conv_text += f"{turn.get('human', '')} {turn.get('assistant', '')} "
                                    if conv_text.strip():
                                        file_texts.append(conv_text.strip())
                                elif 'input' in data and 'output' in data:
                                    # å¤„ç†è¾“å…¥è¾“å‡ºæ ¼å¼
                                    file_texts.append(f"{data['input']} {data['output']}")
                            except json.JSONDecodeError as e:
                                if line_num < 10:  # åªæ˜¾ç¤ºå‰10ä¸ªé”™è¯¯
                                    print(f"   è·³è¿‡æ— æ•ˆè¡Œ {line_num}: {e}")
                                continue
                        
                        all_texts.extend(file_texts)
                        print(f"   åŠ è½½äº† {len(file_texts)} æ¡æ–‡æœ¬")
                        
                except Exception as e:
                    print(f"   âš ï¸  åŠ è½½æ–‡ä»¶å¤±è´¥: {e}")
                    continue
            else:
                print(f"   âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {file_name}")
        
        print(f"ğŸ“Š æ€»å…±åŠ è½½ {len(all_texts)} æ¡è®­ç»ƒæ–‡æœ¬")
        
        if not all_texts:
            # å¦‚æœæ²¡æœ‰åŠ è½½åˆ°æ•°æ®ï¼Œä½¿ç”¨fallback
            print("âš ï¸  æ²¡æœ‰åŠ è½½åˆ°æ•°æ®ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®é›†...")
            fallback_path = os.path.join(self.config.data.data_dir, "pretrain_200.jsonl")
            with open(fallback_path, 'r', encoding='utf-8') as f:
                import json
                for line in f:
                    data = json.loads(line.strip())
                    all_texts.append(data['text'])
            print(f"ä½¿ç”¨å¤‡ç”¨æ•°æ®é›†ï¼Œå…± {len(all_texts)} æ¡æ–‡æœ¬")
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = LanguageModelingDataset(
            texts=all_texts,
            tokenizer=tokenizer,
            max_length=self.config.data.max_seq_len
        )
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        data_loader = DataLoader(
            dataset,
            batch_size=self.config.data.batch_size,
            shuffle=self.config.data.shuffle,
            num_workers=self.config.data.num_workers,
            pin_memory=False
        )
        
        print(f"ğŸ“Š æ•°æ®æ‰¹æ¬¡æ•°: {len(data_loader)}")
        return data_loader
    
    def continue_training(self):
        """ç»§ç»­è®­ç»ƒ"""
        try:
            # æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯
            self._print_system_info()
            
            # éªŒè¯é…ç½®
            warnings = validate_config_for_mac(self.config)
            if warnings:
                print("âš ï¸  é…ç½®è­¦å‘Š:")
                for warning in warnings:
                    print(f"   - {warning}")
                input("æŒ‰å›è½¦é”®ç»§ç»­ï¼Œæˆ–Ctrl+Cé€€å‡º...")
            
            # å¯åŠ¨èµ„æºç›‘æ§
            if self.resource_config.enable_monitoring:
                print("ğŸ” å¯åŠ¨èµ„æºç›‘æ§...")
                monitor_thread = threading.Thread(target=self._monitor_resources, daemon=True)
                monitor_thread.start()
            
            # è®¾ç½®è®­ç»ƒç»„ä»¶
            model, tokenizer, optimizer, checkpoint, data_loader = self.setup_for_continue_training()
            
            # è·å–èµ·å§‹æ­¥æ•°
            start_step = checkpoint.get('step', 0)
            
            # æ‰§è¡Œç»§ç»­è®­ç»ƒ
            self._run_continue_training(model, tokenizer, optimizer, data_loader, start_step)
            
        except KeyboardInterrupt:
            print("\nç”¨æˆ·ä¸­æ–­è®­ç»ƒ")
        except Exception as e:
            print(f"\nè®­ç»ƒé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
        finally:
            self.should_stop = True
            print("ç»§ç»­è®­ç»ƒç»“æŸ")
    
    def _print_system_info(self):
        """æ‰“å°ç³»ç»Ÿä¿¡æ¯"""
        print("=" * 60)
        print("ğŸ”„ ä»æ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒ - Macä¼˜åŒ–ç‰ˆ")
        print("=" * 60)
        
        sys_info = get_system_info()
        print(f"ç³»ç»Ÿå¹³å°: {sys_info['platform']}")
        print(f"CPUæ ¸å¿ƒæ•°: {sys_info['cpu_count']}")
        print(f"æ€»å†…å­˜: {sys_info['memory_gb']:.1f}GB")
        print(f"å¯ç”¨å†…å­˜: {sys_info['available_memory_gb']:.1f}GB")
        
        model_info = estimate_model_size(self.config)
        print(f"\nğŸ“Š æ¨¡å‹ä¿¡æ¯:")
        print(f"é¢„ä¼°å‚æ•°é‡: {model_info['total_params']:,}")
        print(f"æ¨¡å‹å†…å­˜: {model_info['model_memory_mb']:.1f}MB")
        print(f"è®­ç»ƒå†…å­˜: {model_info['training_memory_mb']:.1f}MB")
        
        print(f"\nâš™ï¸  ç»§ç»­è®­ç»ƒé…ç½®:")
        print(f"æ£€æŸ¥ç‚¹è·¯å¾„: {self.checkpoint_path}")
        print(f"æ‰¹æ¬¡å¤§å°: {self.config.data.batch_size}")
        print(f"ç›®æ ‡æ­¥æ•°: {self.config.pretrain.max_steps}")
        print(f"å­¦ä¹ ç‡: {self.config.pretrain.learning_rate}")
        print(f"è®¾å¤‡: {self.config.device}")
        print("-" * 60)
    
    def _run_continue_training(self, model, tokenizer, optimizer, data_loader, start_step):
        """æ‰§è¡Œç»§ç»­è®­ç»ƒå¾ªç¯"""
        print(f"ğŸƒ ä»æ­¥éª¤ {start_step} ç»§ç»­è®­ç»ƒ...")
        
        # è®¾ç½®æŸå¤±å‡½æ•°
        criterion = torch.nn.CrossEntropyLoss(ignore_index=tokenizer.pad_id)
        
        # è®­ç»ƒç»Ÿè®¡
        self.step_count = start_step
        best_loss = float('inf')
        start_time = time.time()
        
        model.train()
        
        for epoch in range(1000):  # æœ€å¤§epochæ•°
            if self.should_stop:
                break
                
            epoch_loss = 0
            epoch_steps = 0
            
            for batch_idx, batch in enumerate(data_loader):
                if self.should_stop:
                    break
                
                # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§æ­¥æ•°
                if self.step_count >= self.config.pretrain.max_steps:
                    print(f"\nğŸ¯ è¾¾åˆ°æœ€å¤§è®­ç»ƒæ­¥æ•°: {self.config.pretrain.max_steps}")
                    self.should_stop = True
                    break
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æš‚åœ
                while self.pause_training and not self.should_stop:
                    time.sleep(1)
                
                if self.should_stop:
                    break
                
                try:
                    # æ•°æ®ç§»åˆ°è®¾å¤‡
                    device = next(model.parameters()).device
                    batch = batch.to(device)
                    
                    # å‡†å¤‡è¾“å…¥å’Œç›®æ ‡
                    input_ids = batch[:, :-1]
                    target_ids = batch[:, 1:]
                    
                    # å‰å‘ä¼ æ’­
                    optimizer.zero_grad()
                    outputs = model(input_ids)
                    
                    # è®¡ç®—æŸå¤±
                    loss = criterion(outputs.reshape(-1, outputs.size(-1)), target_ids.reshape(-1))
                    
                    # åå‘ä¼ æ’­
                    loss.backward()
                    
                    # æ¢¯åº¦è£å‰ª
                    torch.nn.utils.clip_grad_norm_(model.parameters(), self.config.pretrain.max_grad_norm)
                    
                    # æ›´æ–°å‚æ•°
                    optimizer.step()
                    
                    # æ›´æ–°ç»Ÿè®¡
                    epoch_loss += loss.item()
                    epoch_steps += 1
                    self.step_count += 1
                    
                    # è®°å½•æŸå¤±å†å²
                    self.loss_history.append(loss.item())
                    self.step_history.append(self.step_count)
                    
                    # è®°å½•æ—¥å¿—
                    if self.step_count % self.config.logging_steps == 0:
                        avg_loss = epoch_loss / epoch_steps
                        elapsed = time.time() - start_time
                        steps_per_sec = (self.step_count - start_step) / elapsed if elapsed > 0 else 0
                        progress = (self.step_count / self.config.pretrain.max_steps) * 100
                        
                        suffix = f"æŸå¤± {loss.item():.4f} | å¹³å‡ {avg_loss:.4f} | {steps_per_sec:.1f} steps/s"
                        print_progress_bar(self.step_count, self.config.pretrain.max_steps, 
                                         prefix=f'ğŸ”„ ç»§ç»­è®­ç»ƒ (è½®æ¬¡ {epoch})', suffix=suffix)
                    
                    # ä¿å­˜æ£€æŸ¥ç‚¹
                    if self.step_count % self.config.pretrain.save_steps == 0:
                        print(f"\nğŸ’¾ æ­¥éª¤ {self.step_count} - ä¿å­˜æ£€æŸ¥ç‚¹...")
                        self._save_checkpoint(model, tokenizer, optimizer, self.step_count, loss.item())
                        print()
                    
                    # è¯„ä¼°æ¨¡å‹
                    if self.step_count % self.config.pretrain.eval_steps == 0:
                        print(f"\nğŸ§ª æ­¥éª¤ {self.step_count} - æ¨¡å‹è¯„ä¼°...")
                        self._evaluate_model(model, tokenizer)
                        print()
                        
                except Exception as e:
                    print(f"\nè®­ç»ƒæ­¥éª¤é”™è¯¯: {e}")
                    continue
            
            if epoch_steps > 0:
                avg_epoch_loss = epoch_loss / epoch_steps
                print(f"\nğŸ“ˆ è½®æ¬¡ {epoch} å®Œæˆ - å¹³å‡æŸå¤±: {avg_epoch_loss:.4f}")
                
                if avg_epoch_loss < best_loss:
                    best_loss = avg_epoch_loss
                    print(f"ğŸ‰ æ–°çš„æœ€ä½³æŸå¤±: {best_loss:.4f}")
        
        print(f"\nğŸ ç»§ç»­è®­ç»ƒå®Œæˆ!")
        print(f"æ€»æ­¥æ•°: {self.step_count}")
        print(f"æœ€ä½³æŸå¤±: {best_loss:.4f}")
        print(f"è®­ç»ƒæ—¶é—´: {(time.time() - start_time) / 60:.1f}åˆ†é’Ÿ")
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        self._save_checkpoint(model, tokenizer, optimizer, self.step_count, best_loss, final=True)
        
        # ä¿å­˜æœ€ç»ˆæŸå¤±æ›²çº¿
        if len(self.loss_history) > 0:
            print("ğŸ“Š ä¿å­˜æœ€ç»ˆè®­ç»ƒæŸå¤±æ›²çº¿...")
            self._plot_and_save_loss_curve(self.step_count, final=True)
    
    def _save_checkpoint(self, model, tokenizer, optimizer, step, loss, final=False):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint_dir = self.config.output_dir
        os.makedirs(checkpoint_dir, exist_ok=True)
        
        if final:
            checkpoint_path = os.path.join(checkpoint_dir, "final_model.pt")
        else:
            checkpoint_path = os.path.join(checkpoint_dir, f"checkpoint_step_{step}.pt")
        
        torch.save({
            'step': step,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'loss': loss,
            'config': self.config,
            'loss_history': self.loss_history,
            'step_history': self.step_history,
        }, checkpoint_path)
        
        print(f"ğŸ’¾ æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_path}")
        
        # ç»˜åˆ¶å¹¶ä¿å­˜æŸå¤±æ›²çº¿
        if len(self.loss_history) > 0:
            self._plot_and_save_loss_curve(step)
    
    def _plot_and_save_loss_curve(self, current_step, final=False, recovered=False):
        """ç»˜åˆ¶å¹¶ä¿å­˜æŸå¤±æ›²çº¿"""
        try:
            plt.figure(figsize=(12, 8))
            
            # ä¸»æŸå¤±æ›²çº¿
            plt.subplot(2, 1, 1)
            plt.plot(self.step_history, self.loss_history, 'b-', linewidth=1.5, alpha=0.8, label='è®­ç»ƒæŸå¤±')
            plt.title(f'è®­ç»ƒæŸå¤±æ›²çº¿ (Step {current_step})', fontsize=14, fontweight='bold')
            plt.xlabel('è®­ç»ƒæ­¥æ•°', fontsize=12)
            plt.ylabel('æŸå¤±å€¼', fontsize=12)
            plt.grid(True, alpha=0.3)
            plt.legend()
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            if len(self.loss_history) > 1:
                current_loss = self.loss_history[-1]
                min_loss = min(self.loss_history)
                max_loss = max(self.loss_history)
                avg_loss = sum(self.loss_history) / len(self.loss_history)
                
                stats_text = f'å½“å‰: {current_loss:.4f} | æœ€å°: {min_loss:.4f} | æœ€å¤§: {max_loss:.4f} | å¹³å‡: {avg_loss:.4f}'
                plt.figtext(0.5, 0.46, stats_text, ha='center', fontsize=10, 
                           bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue"))
            
            # æœ€è¿‘1000æ­¥æŸå¤±æ›²çº¿ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            plt.subplot(2, 1, 2)
            if len(self.loss_history) > 1000:
                recent_steps = self.step_history[-1000:]
                recent_losses = self.loss_history[-1000:]
                plt.plot(recent_steps, recent_losses, 'r-', linewidth=1.5, label='æœ€è¿‘1000æ­¥')
                plt.title('æœ€è¿‘1000æ­¥æŸå¤±æ›²çº¿', fontsize=12)
            else:
                plt.plot(self.step_history, self.loss_history, 'r-', linewidth=1.5, label='æ‰€æœ‰æŸå¤±')
                plt.title('æŸå¤±æ›²çº¿ï¼ˆæ”¾å¤§è§†å›¾ï¼‰', fontsize=12)
            
            plt.xlabel('è®­ç»ƒæ­¥æ•°', fontsize=12)
            plt.ylabel('æŸå¤±å€¼', fontsize=12)
            plt.grid(True, alpha=0.3)
            plt.legend()
            
            plt.tight_layout()
            
            # ä¿å­˜å›¾ç‰‡
            plot_dir = os.path.join(self.config.output_dir, "plots")
            os.makedirs(plot_dir, exist_ok=True)
            
            # ä¿å­˜å½“å‰æŸå¤±æ›²çº¿
            if final:
                current_plot_path = os.path.join(plot_dir, f"loss_curve_final_step_{current_step}.png")
            elif recovered:
                current_plot_path = os.path.join(plot_dir, f"loss_curve_recovered_step_{current_step}.png")
            else:
                current_plot_path = os.path.join(plot_dir, f"loss_curve_step_{current_step}.png")
            plt.savefig(current_plot_path, dpi=300, bbox_inches='tight')
            
            # æ€»æ˜¯æ›´æ–°æœ€æ–°çš„æŸå¤±æ›²çº¿
            latest_plot_path = os.path.join(plot_dir, "loss_curve_latest.png")
            plt.savefig(latest_plot_path, dpi=300, bbox_inches='tight')
            
            plt.close()  # é‡Šæ”¾å†…å­˜
            
            if final:
                print(f"ğŸ¯ æœ€ç»ˆæŸå¤±æ›²çº¿å·²ä¿å­˜: {current_plot_path}")
            elif recovered:
                print(f"ğŸ”„ æ¢å¤çš„æŸå¤±æ›²çº¿å·²ä¿å­˜: {current_plot_path}")
            else:
                print(f"ğŸ“Š æŸå¤±æ›²çº¿å·²ä¿å­˜: {current_plot_path}")
            
        except Exception as e:
            print(f"âš ï¸  ç»˜åˆ¶æŸå¤±æ›²çº¿å¤±è´¥: {e}")
    
    def _evaluate_model(self, model, tokenizer):
        """ç®€å•è¯„ä¼°æ¨¡å‹"""
        model.eval()
        
        try:
            test_prompts = [
                "ä½ å¥½ï¼Œ",
                "äººå·¥æ™ºèƒ½",
                "ä»Šå¤©å¤©æ°”",
                "å­¦ä¹ ç¼–ç¨‹"
            ]
            
            for prompt in test_prompts:
                print(f"\nğŸ§ª æµ‹è¯•è¾“å…¥: '{prompt}'")
                
                # ç¼–ç è¾“å…¥
                input_ids = tokenizer.encode(prompt, add_special_tokens=True)
                device = next(model.parameters()).device
                input_tensor = torch.tensor([input_ids], device=device)
                
                # ç”Ÿæˆ
                with torch.no_grad():
                    for _ in range(15):  # ç”Ÿæˆ15ä¸ªtoken
                        outputs = model(input_tensor)
                        next_token_logits = outputs[0, -1, :]
                        next_token = torch.argmax(next_token_logits).item()
                        input_tensor = torch.cat([input_tensor, torch.tensor([[next_token]], device=device)], dim=1)
                
                # è§£ç ç»“æœ
                generated_ids = input_tensor[0].cpu().tolist()
                generated_text = tokenizer.decode(generated_ids)
                print(f"ğŸ¤– ç”Ÿæˆ: '{generated_text}'")
                
                # åªæ˜¾ç¤ºå‰ä¸¤ä¸ªæµ‹è¯•æ ·ä¾‹ï¼Œé¿å…è¾“å‡ºè¿‡é•¿
                if prompt == test_prompts[1]:
                    break
            
        except Exception as e:
            print(f"ç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")
        finally:
            model.train()


def main():
    parser = argparse.ArgumentParser(description='ä»æ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒè„šæœ¬')
    parser.add_argument('--checkpoint', type=str, 
                        default='checkpoints/mac_medium/final_model.pt',
                        help='æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--max-steps', type=int, default=8000,
                        help='ç»§ç»­è®­ç»ƒçš„æœ€å¤§æ­¥æ•°')
    parser.add_argument('--max-cpu', type=float, default=85.0,
                        help='æœ€å¤§CPUä½¿ç”¨ç‡ (%)')
    parser.add_argument('--max-memory', type=float, default=85.0,
                        help='æœ€å¤§å†…å­˜ä½¿ç”¨ç‡ (%)')
    parser.add_argument('--disable-monitoring', action='store_true',
                        help='ç¦ç”¨èµ„æºç›‘æ§')
    
    args = parser.parse_args()
    
    # è·å–mediumé…ç½®
    config = get_mac_medium_config()
    
    # æ›´æ–°æœ€å¤§æ­¥æ•°
    config.pretrain.max_steps = args.max_steps
    
    print(f"ä½¿ç”¨mediumæ¨¡å‹é…ç½®")
    print(f"ä»æ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒ: {args.checkpoint}")
    print(f"ç›®æ ‡æœ€å¤§æ­¥æ•°: {args.max_steps}")
    
    # èµ„æºç›‘æ§é…ç½®
    resource_config = MacResourceConfig(
        max_cpu_percent=args.max_cpu,
        max_memory_percent=args.max_memory,
        enable_monitoring=not args.disable_monitoring
    )
    
    # åˆ›å»ºç»§ç»­è®­ç»ƒå™¨
    trainer = ContinueTrainer(args.checkpoint, config, resource_config)
    
    # å¼€å§‹ç»§ç»­è®­ç»ƒ
    trainer.continue_training()


if __name__ == "__main__":
    main()