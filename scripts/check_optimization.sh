#!/bin/bash
# A6000ä¼˜åŒ–å¿«é€ŸéªŒè¯è„šæœ¬

echo "============================================================"
echo "  A6000 GPU è®­ç»ƒä¼˜åŒ–é…ç½®æ£€æŸ¥"
echo "============================================================"

echo ""
echo "ğŸ“‹ æ£€æŸ¥ä¼˜åŒ–é…ç½®..."
echo ""

# æ£€æŸ¥training_config.pyä¸­çš„batch sizeé…ç½®
echo "ğŸ”¹ Batch Sizeé…ç½®:"
grep -A 2 "if gpu_memory >= 40:" config/training_config.py | grep "batch_size"
echo ""

# æ£€æŸ¥æ•°æ®åŠ è½½é…ç½®
echo "ğŸ”¹ æ•°æ®åŠ è½½é…ç½®:"
grep "num_workers = " config/training_config.py | head -1
grep "prefetch_factor = " config/training_config.py | head -1
grep "pin_memory = " config/training_config.py | head -1
echo ""

# æ£€æŸ¥æ··åˆç²¾åº¦é…ç½®
echo "ğŸ”¹ æ··åˆç²¾åº¦é…ç½®:"
grep "mixed_precision = " config/training_config.py | head -1
echo ""

# æ£€æŸ¥train.pyä¸­çš„ä¼˜åŒ–å™¨é…ç½®
echo "ğŸ”¹ è®­ç»ƒè„šæœ¬ä¼˜åŒ–:"
echo "æ¢¯åº¦ç´¯ç§¯æ”¯æŒ:"
grep -c "accumulation_steps" scripts/train.py
echo "æ··åˆç²¾åº¦æ”¯æŒ:"
grep -c "torch.cuda.amp" scripts/train.py
echo "Non-blockingä¼ è¾“:"
grep -c "non_blocking=True" scripts/train.py
echo ""

echo "============================================================"
echo "  ä¼˜åŒ–æ€»ç»“"
echo "============================================================"
echo ""
echo "âœ… å·²åº”ç”¨çš„å…³é”®ä¼˜åŒ–:"
echo "  1. Batch size: 32 (é’ˆå¯¹A6000 48GBä¼˜åŒ–)"
echo "  2. DataLoader workers: 8 (å¤šè¿›ç¨‹æ•°æ®åŠ è½½)"
echo "  3. Prefetch factor: 4 (æ•°æ®é¢„å–)"
echo "  4. æ··åˆç²¾åº¦è®­ç»ƒ: FP16"
echo "  5. æ¢¯åº¦ç´¯ç§¯: 4æ­¥"
echo ""
echo "ğŸ“ˆ é¢„æœŸæ€§èƒ½æå‡:"
echo "  - GPUåˆ©ç”¨ç‡: 30% â†’ 70-90%"
echo "  - è®­ç»ƒé€Ÿåº¦: æå‡2-2.5å€"
echo "  - æ˜¾å­˜å ç”¨: å‡å°‘20-30%"
echo ""
echo "ğŸš€ å¼€å§‹è®­ç»ƒå‘½ä»¤:"
echo "  python3 scripts/train.py --mode pretrain --config medium"
echo ""
echo "ğŸ“Š ç›‘æ§GPUå‘½ä»¤:"
echo "  watch -n 1 nvidia-smi"
echo ""
echo "============================================================"
