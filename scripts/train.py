#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MiniGPT è®­ç»ƒè„šæœ¬
æ”¯æŒå®Œæ•´çš„è®­ç»ƒæµæ°´çº¿ï¼špretrain â†’ sft â†’ dpo â†’ rlhf
"""
import os
import sys
import argparse
import time
import json
import torch
from torch.utils.data import DataLoader
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•å’Œsrcç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(__file__))
sys.path.append(project_root)
sys.path.append(os.path.join(project_root, 'src'))

from model.transformer import create_model
from tokenizer.bpe_tokenizer import BPETokenizer
from training.trainer import create_trainer, LanguageModelingDataset, ConversationDataset
from config.training_config import get_config


class MiniGPTTrainer:
    """MiniGPTè®­ç»ƒå™¨ï¼Œæ”¯æŒå¤šç§è®­ç»ƒæ¨¡å¼"""

    def __init__(self, config, mode="pretrain"):
        self.config = config
        self.mode = mode
        self.device = self._setup_device()
        self.output_dir = os.path.join(config.checkpoint_dir, f"{mode}_{config.model_size}")
        os.makedirs(self.output_dir, exist_ok=True)

        print(f"=== MiniGPT {mode.upper()} è®­ç»ƒ ===")
        print(f"æ¨¡å‹é…ç½®: {config.model_size}")
        print(f"è®¾å¤‡: {self.device}")
        print(f"è¾“å‡ºç›®å½•: {self.output_dir}")

    def _setup_device(self):
        """è®¾ç½®è®­ç»ƒè®¾å¤‡"""
        if torch.backends.mps.is_available():
            device = "mps"
            print("ğŸ”§ ä½¿ç”¨Apple Silicon GPU (MPS)")
        elif torch.cuda.is_available():
            device = "cuda"
            print(f"ğŸ”§ ä½¿ç”¨CUDA GPU: {torch.cuda.get_device_name()}")
        else:
            device = "cpu"
            print("ğŸ”§ ä½¿ç”¨CPU")
        return device

    def setup_tokenizer(self, retrain=False):
        """è®¾ç½®åˆ†è¯å™¨"""
        print("ğŸ”¤ è®¾ç½®åˆ†è¯å™¨...")

        tokenizer_path = os.path.join(self.output_dir, "tokenizer.pkl")

        if os.path.exists(tokenizer_path) and not retrain:
            print(f"åŠ è½½ç°æœ‰åˆ†è¯å™¨: {tokenizer_path}")
            tokenizer = BPETokenizer(vocab_size=self.config.vocab_size)
            tokenizer.load(tokenizer_path)
        else:
            print("è®­ç»ƒæ–°çš„åˆ†è¯å™¨...")
            # æ”¶é›†è®­ç»ƒæ–‡æœ¬
            texts = self._collect_texts_for_tokenizer()

            tokenizer = BPETokenizer(vocab_size=self.config.vocab_size)
            tokenizer.train(texts)
            tokenizer.save(tokenizer_path)
            print(f"åˆ†è¯å™¨å·²ä¿å­˜: {tokenizer_path}")

        print(f"è¯æ±‡è¡¨å¤§å°: {tokenizer.vocab_size}")
        return tokenizer

    def _collect_texts_for_tokenizer(self):
        """æ”¶é›†ç”¨äºè®­ç»ƒåˆ†è¯å™¨çš„æ–‡æœ¬"""
        texts = []
        data_paths = self._get_data_paths()

        for data_path in data_paths:
            if not os.path.exists(data_path):
                print(f"âš ï¸  æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {data_path}")
                continue

            with open(data_path, 'r', encoding='utf-8') as f:
                for line_no, line in enumerate(f):
                    try:
                        data = json.loads(line.strip())
                        text = self._extract_text_from_data(data)
                        if text:
                            texts.append(text)

                        # é™åˆ¶åˆ†è¯å™¨è®­ç»ƒæ ·æœ¬æ•°é‡
                        if len(texts) >= 50000:
                            break
                    except json.JSONDecodeError:
                        continue

            if len(texts) >= 50000:
                break

        print(f"æ”¶é›†äº† {len(texts)} æ¡æ–‡æœ¬ç”¨äºè®­ç»ƒåˆ†è¯å™¨")
        return texts

    def _get_data_paths(self):
        """æ ¹æ®è®­ç»ƒæ¨¡å¼è·å–æ•°æ®è·¯å¾„"""
        base_dir = self.config.data_dir

        if self.mode == "pretrain":
            return [
                os.path.join(base_dir, "pretrain_hq.jsonl"),
                os.path.join(base_dir, "sft_mini_512.jsonl")  # è¡¥å……æ•°æ®
            ]
        elif self.mode == "sft":
            return [
                os.path.join(base_dir, "sft_mini_512.jsonl"),
                os.path.join(base_dir, "alex_identity.jsonl"),
                os.path.join(base_dir, "ultra_think.jsonl")
            ]
        elif self.mode == "dpo":
            return [
                os.path.join(base_dir, "dpo.jsonl")
            ]
        elif self.mode == "rlhf":
            return [
                os.path.join(base_dir, "alex_identity.jsonl"),
                os.path.join(base_dir, "ultra_think.jsonl")
            ]
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„è®­ç»ƒæ¨¡å¼: {self.mode}")

    def _extract_text_from_data(self, data):
        """ä»æ•°æ®ä¸­æå–æ–‡æœ¬"""
        if 'text' in data:
            return data['text']
        elif 'conversations' in data:
            # å¯¹è¯æ ¼å¼
            text = ""
            for turn in data['conversations']:
                if 'content' in turn:
                    text += turn['content'] + " "
            return text.strip()
        elif 'input' in data and 'output' in data:
            return f"{data['input']} {data['output']}"
        elif 'chosen' in data and 'rejected' in data:
            # DPOæ ¼å¼
            return data['chosen']
        return None

    def setup_data_loader(self, tokenizer):
        """è®¾ç½®æ•°æ®åŠ è½½å™¨"""
        print(f"ğŸ“š è®¾ç½®{self.mode}æ•°æ®åŠ è½½å™¨...")

        # åŠ è½½æ•°æ®
        all_data = []
        data_paths = self._get_data_paths()

        for data_path in data_paths:
            if not os.path.exists(data_path):
                print(f"âš ï¸  æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {data_path}")
                continue

            file_data = []
            with open(data_path, 'r', encoding='utf-8') as f:
                for line in f:
                    try:
                        data = json.loads(line.strip())
                        file_data.append(data)
                    except json.JSONDecodeError:
                        continue

            all_data.extend(file_data)
            print(f"ä» {os.path.basename(data_path)} åŠ è½½äº† {len(file_data)} æ¡æ•°æ®")

        print(f"æ€»å…±åŠ è½½ {len(all_data)} æ¡{self.mode}è®­ç»ƒæ•°æ®")

        # æ ¹æ®è®­ç»ƒæ¨¡å¼åˆ›å»ºæ•°æ®é›†
        if self.mode == "pretrain":
            dataset = self._create_pretrain_dataset(all_data, tokenizer)
        elif self.mode == "sft":
            dataset = self._create_sft_dataset(all_data, tokenizer)
        elif self.mode == "dpo":
            dataset = self._create_dpo_dataset(all_data, tokenizer)
        elif self.mode == "rlhf":
            dataset = self._create_rlhf_dataset(all_data, tokenizer)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„è®­ç»ƒæ¨¡å¼: {self.mode}")

        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        data_loader = DataLoader(
            dataset,
            batch_size=self.config.batch_size,
            shuffle=True,
            num_workers=0,  # ç®€åŒ–ä¸ºå•è¿›ç¨‹
            drop_last=True
        )

        print(f"æ•°æ®æ‰¹æ¬¡æ•°: {len(data_loader)}")
        return data_loader

    def _create_pretrain_dataset(self, data, tokenizer):
        """åˆ›å»ºé¢„è®­ç»ƒæ•°æ®é›†"""
        texts = []
        for item in data:
            text = self._extract_text_from_data(item)
            if text and len(text.strip()) > 10:
                texts.append(text)

        return LanguageModelingDataset(
            texts=texts,
            tokenizer=tokenizer,
            max_length=self.config.max_seq_len
        )

    def _create_sft_dataset(self, data, tokenizer):
        """åˆ›å»ºSFTæ•°æ®é›†"""
        conversations = []
        for item in data:
            if 'conversations' in item:
                conversations.append(item['conversations'])
            elif 'input' in item and 'output' in item:
                # è½¬æ¢ä¸ºå¯¹è¯æ ¼å¼
                conv = [
                    {"role": "user", "content": item['input']},
                    {"role": "assistant", "content": item['output']}
                ]
                conversations.append(conv)

        return ConversationDataset(
            conversations=conversations,
            tokenizer=tokenizer,
            max_length=self.config.max_seq_len
        )

    def _create_dpo_dataset(self, data, tokenizer):
        """åˆ›å»ºDPOæ•°æ®é›†"""
        # ç®€åŒ–å®ç°ï¼Œå°†chosenä½œä¸ºæ­£ä¾‹è®­ç»ƒ
        texts = []
        for item in data:
            if 'chosen' in item:
                texts.append(item['chosen'])

        return LanguageModelingDataset(
            texts=texts,
            tokenizer=tokenizer,
            max_length=self.config.max_seq_len
        )

    def _create_rlhf_dataset(self, data, tokenizer):
        """åˆ›å»ºRLHFæ•°æ®é›†"""
        # ä½¿ç”¨å¯¹è¯æ ¼å¼è¿›è¡Œå¼ºåŒ–å­¦ä¹ å¾®è°ƒ
        return self._create_sft_dataset(data, tokenizer)

    def setup_model(self, tokenizer, resume_from=None):
        """è®¾ç½®æ¨¡å‹"""
        print("ğŸ§  åˆ›å»ºæ¨¡å‹...")

        model = create_model(vocab_size=tokenizer.vocab_size, model_size=self.config.model_size)
        model = model.to(self.device)

        # å¦‚æœæœ‰é¢„è®­ç»ƒæ¨¡å‹ï¼ŒåŠ è½½æƒé‡
        if resume_from:
            print(f"ğŸ”„ ä»æ£€æŸ¥ç‚¹åŠ è½½æ¨¡å‹: {resume_from}")
            checkpoint = torch.load(resume_from, map_location=self.device, weights_only=False)
            if 'model_state_dict' in checkpoint:
                model.load_state_dict(checkpoint['model_state_dict'])
            else:
                model.load_state_dict(checkpoint)

        # æ‰“å°æ¨¡å‹ä¿¡æ¯
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        print(f"æ€»å‚æ•°é‡: {total_params:,}")
        print(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")

        return model

    def train(self, resume_from=None, retrain_tokenizer=False):
        """æ‰§è¡Œè®­ç»ƒ"""
        print(f"ğŸš€ å¼€å§‹{self.mode}è®­ç»ƒ...")
        start_time = time.time()

        # è®¾ç½®åˆ†è¯å™¨
        tokenizer = self.setup_tokenizer(retrain=retrain_tokenizer)

        # è®¾ç½®æ•°æ®åŠ è½½å™¨
        data_loader = self.setup_data_loader(tokenizer)

        # è®¾ç½®æ¨¡å‹
        model = self.setup_model(tokenizer, resume_from=resume_from)

        # è®¾ç½®ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
        optimizer = torch.optim.AdamW(
            model.parameters(),
            lr=self.config.learning_rate,
            weight_decay=self.config.weight_decay
        )

        criterion = torch.nn.CrossEntropyLoss(ignore_index=tokenizer.pad_id)

        # è®­ç»ƒå¾ªç¯
        model.train()
        step = 0
        best_loss = float('inf')

        print(f"å¼€å§‹è®­ç»ƒï¼Œæœ€å¤§æ­¥æ•°: {self.config.max_steps}")

        for epoch in range(1000):  # æœ€å¤§epochæ•°
            epoch_loss = 0
            epoch_steps = 0

            for batch in data_loader:
                if step >= self.config.max_steps:
                    break

                # æ•°æ®ç§»åˆ°è®¾å¤‡
                batch = batch.to(self.device)

                # éªŒè¯batchå°ºå¯¸
                if batch.size(1) < 2:
                    continue

                # å‡†å¤‡è¾“å…¥å’Œç›®æ ‡
                input_ids = batch[:, :-1]
                target_ids = batch[:, 1:]

                # å‰å‘ä¼ æ’­
                optimizer.zero_grad()
                outputs = model(input_ids)

                # è®¡ç®—æŸå¤±
                loss = criterion(outputs.reshape(-1, outputs.size(-1)), target_ids.reshape(-1))

                # åå‘ä¼ æ’­
                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                optimizer.step()

                # æ›´æ–°ç»Ÿè®¡
                epoch_loss += loss.item()
                epoch_steps += 1
                step += 1

                # è®°å½•æ—¥å¿—
                if step % 100 == 0:
                    avg_loss = epoch_loss / epoch_steps
                    elapsed = time.time() - start_time
                    print(f"Step {step:5d} | Loss: {loss.item():.4f} | Avg: {avg_loss:.4f} | "
                          f"Time: {elapsed/60:.1f}min")

                # ä¿å­˜æ£€æŸ¥ç‚¹
                if step % self.config.save_steps == 0:
                    self._save_checkpoint(model, tokenizer, optimizer, step, loss.item())

                # è¯„ä¼°æ¨¡å‹
                if step % self.config.eval_steps == 0:
                    self._evaluate_model(model, tokenizer)

                if step >= self.config.max_steps:
                    break

            if step >= self.config.max_steps:
                break

        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        final_path = os.path.join(self.output_dir, "final_model.pt")
        torch.save({
            'model_state_dict': model.state_dict(),
            'tokenizer_vocab_size': tokenizer.vocab_size,
            'config': self.config,
            'mode': self.mode,
            'step': step
        }, final_path)

        print(f"ğŸ‰ {self.mode}è®­ç»ƒå®Œæˆï¼")
        print(f"æ€»æ­¥æ•°: {step}")
        print(f"è®­ç»ƒæ—¶é—´: {(time.time() - start_time)/60:.1f}åˆ†é’Ÿ")
        print(f"æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜: {final_path}")

        return final_path

    def _save_checkpoint(self, model, tokenizer, optimizer, step, loss):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint_path = os.path.join(self.output_dir, f"checkpoint_step_{step}.pt")
        torch.save({
            'step': step,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'loss': loss,
            'config': self.config,
            'mode': self.mode
        }, checkpoint_path)
        print(f"ğŸ’¾ æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_path}")

    def _evaluate_model(self, model, tokenizer):
        """ç®€å•è¯„ä¼°æ¨¡å‹"""
        model.eval()
        try:
            test_prompt = "ä½ å¥½ï¼Œæˆ‘æ˜¯"
            input_ids = tokenizer.encode(test_prompt, add_special_tokens=True)
            input_tensor = torch.tensor([input_ids], device=self.device)

            with torch.no_grad():
                for _ in range(10):
                    outputs = model(input_tensor)
                    next_token_logits = outputs[0, -1, :]
                    next_token = torch.argmax(next_token_logits).item()
                    input_tensor = torch.cat([input_tensor, torch.tensor([[next_token]], device=self.device)], dim=1)

            generated_text = tokenizer.decode(input_tensor[0].cpu().tolist())
            print(f"ğŸ§ª ç”Ÿæˆæµ‹è¯•: '{generated_text}'")
        except Exception as e:
            print(f"ç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")
        finally:
            model.train()


def main():
    parser = argparse.ArgumentParser(description='MiniGPTè®­ç»ƒè„šæœ¬')

    # è®­ç»ƒæ¨¡å¼
    parser.add_argument('--mode', choices=['pretrain', 'sft', 'dpo', 'rlhf'], default='sft',
                        help='è®­ç»ƒæ¨¡å¼ (pretrain: é¢„è®­ç»ƒ, sft: ç›‘ç£å¾®è°ƒ, dpo: ç›´æ¥åå¥½ä¼˜åŒ–, rlhf: å¼ºåŒ–å­¦ä¹ )')

    # æ¨¡å‹é…ç½®
    parser.add_argument('--config', choices=['medium', 'large'], default='medium',
                        help='æ¨¡å‹é…ç½®å¤§å° (medium: ~200Må‚æ•°, large: ~500Må‚æ•°)')

    # æ•°æ®ç›¸å…³
    parser.add_argument('--retrain-tokenizer', action='store_true',
                        help='é‡æ–°è®­ç»ƒåˆ†è¯å™¨')

    # ç»§ç»­è®­ç»ƒ
    parser.add_argument('--resume', type=str, default=None,
                        help='ä»æ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒ')

    # è®­ç»ƒå‚æ•°è¦†ç›–
    parser.add_argument('--learning-rate', type=float, default=None,
                        help='å­¦ä¹ ç‡')
    parser.add_argument('--max-steps', type=int, default=None,
                        help='æœ€å¤§è®­ç»ƒæ­¥æ•°')
    parser.add_argument('--batch-size', type=int, default=None,
                        help='æ‰¹æ¬¡å¤§å°')

    args = parser.parse_args()

    # è·å–é…ç½®
    config = get_config(args.config)

    # åº”ç”¨å‘½ä»¤è¡Œå‚æ•°è¦†ç›–
    if args.learning_rate is not None:
        config.learning_rate = args.learning_rate
    if args.max_steps is not None:
        config.max_steps = args.max_steps
    if args.batch_size is not None:
        config.batch_size = args.batch_size

    # æ ¹æ®è®­ç»ƒæ¨¡å¼è°ƒæ•´é…ç½®
    if args.mode == "pretrain":
        config.max_steps = config.max_steps or 50000
        config.learning_rate = config.learning_rate or 1e-4
        print("ğŸ“š é¢„è®­ç»ƒæ¨¡å¼ï¼šå»ºç«‹åŸºç¡€è¯­è¨€ç†è§£èƒ½åŠ›")
    elif args.mode == "sft":
        config.max_steps = config.max_steps or 10000
        config.learning_rate = config.learning_rate or 5e-5
        print("ğŸ¯ ç›‘ç£å¾®è°ƒæ¨¡å¼ï¼šè®­ç»ƒå¯¹è¯å’Œç‰¹å®šä»»åŠ¡èƒ½åŠ›")
    elif args.mode == "dpo":
        config.max_steps = config.max_steps or 5000
        config.learning_rate = config.learning_rate or 1e-5
        print("âš–ï¸  ç›´æ¥åå¥½ä¼˜åŒ–æ¨¡å¼ï¼šæ ¹æ®äººç±»åå¥½è°ƒæ•´å“åº”")
    elif args.mode == "rlhf":
        config.max_steps = config.max_steps or 3000
        config.learning_rate = config.learning_rate or 1e-5
        print("ğŸ”„ å¼ºåŒ–å­¦ä¹ å¾®è°ƒæ¨¡å¼ï¼šé€šè¿‡å¥–åŠ±æ¨¡å‹ä¼˜åŒ–")

    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = MiniGPTTrainer(config, mode=args.mode)

    # å¼€å§‹è®­ç»ƒ
    final_model_path = trainer.train(
        resume_from=args.resume,
        retrain_tokenizer=args.retrain_tokenizer
    )

    print(f"\nâœ… è®­ç»ƒå®Œæˆï¼æ¨¡å‹ä¿å­˜åœ¨: {final_model_path}")

    # æç¤ºä¸‹ä¸€æ­¥è®­ç»ƒå»ºè®®
    if args.mode == "pretrain":
        print("\nğŸ’¡ å»ºè®®ä¸‹ä¸€æ­¥è¿è¡ŒSFTè®­ç»ƒ:")
        print(f"uv run python scripts/train.py --mode sft --config {args.config} --resume {final_model_path}")
    elif args.mode == "sft":
        print("\nğŸ’¡ å»ºè®®ä¸‹ä¸€æ­¥è¿è¡ŒDPOè®­ç»ƒ:")
        print(f"uv run python scripts/train.py --mode dpo --config {args.config} --resume {final_model_path}")


if __name__ == "__main__":
    main()