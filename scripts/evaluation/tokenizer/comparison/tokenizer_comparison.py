#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ“Š MiniGPTåˆ†è¯å™¨å¯¹æ¯”åˆ†æç³»ç»Ÿ
============================

ç³»ç»ŸåŒ–å¯¹æ¯”ä¸åŒåˆ†è¯å™¨çš„æ€§èƒ½ç‰¹å¾
æ‰§è¡Œé£æ ¼: ISTJè¯¦ç»†è®°å½•ä¸åˆ†æ

å¯¹æ¯”ç»´åº¦:
1. è¯æ±‡è¡¨æ•ˆç‡å¯¹æ¯”
2. è¯­è¨€æ”¯æŒèƒ½åŠ›å¯¹æ¯”
3. æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”
4. èµ„æºä½¿ç”¨å¯¹æ¯”
5. é€‚ç”¨åœºæ™¯åˆ†æ
"""

import sys
import os
import json
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯
import matplotlib.pyplot as plt
import pandas as pd
from typing import Dict, List, Any
import numpy as np

sys.path.append(os.path.join(os.path.dirname(__file__), '../../../..'))


class TokenizerComparison:
    """åˆ†è¯å™¨å¯¹æ¯”åˆ†æå™¨"""

    def __init__(self):
        self.comparison_categories = [
            'compression_ratio',
            'vocab_size',
            'encode_speed',
            'chinese_support',
            'english_support',
            'memory_usage_mb'
        ]

    def create_comparison_matrix(self, evaluation_results: Dict[str, Any]) -> pd.DataFrame:
        """åˆ›å»ºå¯¹æ¯”çŸ©é˜µ"""
        data = []

        for tokenizer_name, metrics in evaluation_results.items():
            if isinstance(metrics, dict):
                row = {'tokenizer': tokenizer_name}
                for category in self.comparison_categories:
                    row[category] = metrics.get(category, 0.0)
                data.append(row)

        return pd.DataFrame(data)

    def generate_comparison_charts(self, df: pd.DataFrame, output_dir: str):
        """ç”Ÿæˆå¯¹æ¯”å›¾è¡¨"""
        os.makedirs(output_dir, exist_ok=True)

        # 1. ç»¼åˆæ€§èƒ½é›·è¾¾å›¾
        self._create_radar_chart(df, os.path.join(output_dir, 'performance_radar.png'))

        # 2. æ€§èƒ½æŒ‡æ ‡æ¡å½¢å›¾
        self._create_performance_bars(df, os.path.join(output_dir, 'performance_bars.png'))

        # 3. è¯æ±‡è¡¨æ•ˆç‡æ•£ç‚¹å›¾
        self._create_efficiency_scatter(df, os.path.join(output_dir, 'efficiency_scatter.png'))

    def _create_radar_chart(self, df: pd.DataFrame, output_path: str):
        """åˆ›å»ºé›·è¾¾å›¾"""
        if df.empty:
            return

        fig, ax = plt.subplots(figsize=(10, 8), subplot_kw=dict(projection='polar'))

        # é€‰æ‹©å…³é”®æŒ‡æ ‡
        metrics = ['compression_ratio', 'encode_speed', 'chinese_support', 'english_support']

        angles = np.linspace(0, 2 * np.pi, len(metrics), endpoint=False)
        angles = np.concatenate((angles, [angles[0]]))  # é—­åˆé›·è¾¾å›¾

        for _, row in df.iterrows():
            values = []
            for metric in metrics:
                # æ ‡å‡†åŒ–åˆ°0-1èŒƒå›´
                max_val = df[metric].max()
                normalized = row[metric] / max_val if max_val > 0 else 0
                values.append(normalized)

            values = np.concatenate((values, [values[0]]))  # é—­åˆæ•°æ®

            ax.plot(angles, values, 'o-', linewidth=2, label=row['tokenizer'])
            ax.fill(angles, values, alpha=0.25)

        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(metrics)
        ax.set_ylim(0, 1)
        ax.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))

        plt.title('åˆ†è¯å™¨æ€§èƒ½é›·è¾¾å›¾', size=16, pad=20)
        plt.tight_layout()
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()

    def _create_performance_bars(self, df: pd.DataFrame, output_path: str):
        """åˆ›å»ºæ€§èƒ½æ¡å½¢å›¾"""
        if df.empty:
            return

        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        axes = axes.ravel()

        metrics = ['compression_ratio', 'encode_speed', 'chinese_support', 'english_support']
        titles = ['å‹ç¼©ç‡', 'ç¼–ç é€Ÿåº¦', 'ä¸­æ–‡æ”¯æŒ', 'è‹±æ–‡æ”¯æŒ']

        for i, (metric, title) in enumerate(zip(metrics, titles)):
            ax = axes[i]
            bars = ax.bar(df['tokenizer'], df[metric])
            ax.set_title(title, fontsize=12)
            ax.tick_params(axis='x', rotation=45)

            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar in bars:
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height,
                       f'{height:.2f}', ha='center', va='bottom')

        plt.tight_layout()
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()

    def _create_efficiency_scatter(self, df: pd.DataFrame, output_path: str):
        """åˆ›å»ºæ•ˆç‡æ•£ç‚¹å›¾"""
        if df.empty or len(df) < 2:
            return

        plt.figure(figsize=(10, 6))

        scatter = plt.scatter(df['vocab_size'], df['compression_ratio'],
                             s=df['encode_speed']*10, alpha=0.6, c=range(len(df)))

        for i, row in df.iterrows():
            plt.annotate(row['tokenizer'],
                        (row['vocab_size'], row['compression_ratio']),
                        xytext=(5, 5), textcoords='offset points')

        plt.xlabel('è¯æ±‡è¡¨å¤§å°')
        plt.ylabel('å‹ç¼©ç‡')
        plt.title('åˆ†è¯å™¨æ•ˆç‡åˆ†æ (æ°”æ³¡å¤§å°è¡¨ç¤ºç¼–ç é€Ÿåº¦)')
        plt.colorbar(scatter, label='åˆ†è¯å™¨ç¼–å·')

        plt.tight_layout()
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()

    def generate_comparison_report(self, evaluation_results: Dict[str, Any], output_path: str):
        """ç”Ÿæˆè¯¦ç»†å¯¹æ¯”æŠ¥å‘Š"""

        df = self.create_comparison_matrix(evaluation_results)

        report = {
            'summary': {
                'total_tokenizers': len(df),
                'evaluation_date': time.strftime('%Y-%m-%d %H:%M:%S')
            },
            'rankings': {},
            'analysis': {},
            'recommendations': []
        }

        # ç”Ÿæˆå„æŒ‡æ ‡æ’å
        for metric in self.comparison_categories:
            if metric in df.columns:
                ranking = df.nlargest(len(df), metric)[['tokenizer', metric]].to_dict('records')
                report['rankings'][metric] = ranking

        # åˆ†ææœ€ä½³é€‰æ‹©
        if not df.empty:
            # ç»¼åˆå¾—åˆ† (åŠ æƒ)
            weights = {
                'compression_ratio': 0.25,
                'encode_speed': 0.20,
                'chinese_support': 0.25,
                'english_support': 0.15,
                'memory_usage_mb': -0.15  # å†…å­˜ä½¿ç”¨è¶Šå°‘è¶Šå¥½
            }

            df_norm = df.copy()
            for metric, weight in weights.items():
                if metric in df.columns:
                    if weight > 0:
                        df_norm[f'{metric}_score'] = df[metric] / df[metric].max() * weight
                    else:
                        df_norm[f'{metric}_score'] = (1 - df[metric] / df[metric].max()) * abs(weight)

            score_columns = [f'{m}_score' for m in weights.keys() if f'{m}_score' in df_norm.columns]
            df_norm['total_score'] = df_norm[score_columns].sum(axis=1)

            best_overall = df_norm.loc[df_norm['total_score'].idxmax()]

            report['analysis']['best_overall'] = {
                'tokenizer': best_overall['tokenizer'],
                'score': best_overall['total_score'],
                'strengths': self._analyze_strengths(best_overall, df)
            }

        # ä¿å­˜æŠ¥å‘Š
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        return report

    def _analyze_strengths(self, best_tokenizer: pd.Series, df: pd.DataFrame) -> List[str]:
        """åˆ†ææœ€ä½³åˆ†è¯å™¨çš„ä¼˜åŠ¿"""
        strengths = []

        metrics_analysis = {
            'compression_ratio': 'å‹ç¼©æ•ˆç‡',
            'encode_speed': 'ç¼–ç é€Ÿåº¦',
            'chinese_support': 'ä¸­æ–‡å¤„ç†',
            'english_support': 'è‹±æ–‡å¤„ç†'
        }

        for metric, description in metrics_analysis.items():
            if metric in df.columns and metric in best_tokenizer:
                if best_tokenizer[metric] >= df[metric].quantile(0.75):
                    strengths.append(f'{description}è¡¨ç°ä¼˜å¼‚')

        return strengths