#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
âš¡ MiniGPTåˆ†è¯å™¨æ€§èƒ½åŸºå‡†æµ‹è¯•
==============================

ä¸“æ³¨äºé‡åŒ–æ€§èƒ½æŒ‡æ ‡çš„ç²¾ç¡®æµ‹é‡
æ‰§è¡Œé£æ ¼: ISTJç³»ç»ŸåŒ–æµ‹é‡ä¸è®°å½•

æµ‹è¯•é¡¹ç›®:
1. ç¼–ç /è§£ç é€Ÿåº¦åŸºå‡†æµ‹è¯•
2. å†…å­˜ä½¿ç”¨é‡æµ‹é‡
3. ååé‡æµ‹è¯•
4. å¹¶å‘æ€§èƒ½æµ‹è¯•
5. å¤§æ–‡æœ¬å¤„ç†èƒ½åŠ›æµ‹è¯•
"""

import sys
import os
import time
import threading
from concurrent.futures import ThreadPoolExecutor
from typing import Dict, List, Tuple
import statistics
import json

# å¯é€‰ä¾èµ–å¯¼å…¥
try:
    import psutil
    MEMORY_MONITORING_AVAILABLE = True
except ImportError:
    print("âš ï¸  psutilæ¨¡å—å¯¼å…¥å¤±è´¥ï¼Œå†…å­˜ç›‘æ§åŠŸèƒ½å°†è¢«ç¦ç”¨")
    print("ğŸ“ æç¤º: è¿è¡Œ 'pip install psutil' å®‰è£…ä¾èµ–")
    MEMORY_MONITORING_AVAILABLE = False

sys.path.append(os.path.join(os.path.dirname(__file__), '../../../..'))


class TokenizerBenchmark:
    """åˆ†è¯å™¨æ€§èƒ½åŸºå‡†æµ‹è¯•å™¨"""

    def __init__(self):
        self.benchmark_texts = self._prepare_benchmark_texts()

    def _prepare_benchmark_texts(self) -> Dict[str, str]:
        """å‡†å¤‡æ ‡å‡†åŒ–çš„åŸºå‡†æµ‹è¯•æ–‡æœ¬"""
        return {
            'short': "æµ‹è¯•çŸ­æ–‡æœ¬tokenizationæ€§èƒ½ã€‚" * 10,
            'medium': "è¿™æ˜¯ä¸€ä¸ªä¸­ç­‰é•¿åº¦çš„æ–‡æœ¬ï¼Œç”¨äºæµ‹è¯•åˆ†è¯å™¨çš„æ€§èƒ½è¡¨ç°ã€‚" * 100,
            'long': "é•¿æ–‡æœ¬æ€§èƒ½æµ‹è¯•ï¼ŒåŒ…å«ä¸­æ–‡ã€English mixed contentå’Œå„ç§ç¬¦å·!@#$%ã€‚" * 1000,
            'xlarge': "è¶…å¤§æ–‡æœ¬æµ‹è¯•ã€‚" * 10000
        }

    def run_speed_benchmark(self, tokenizer, iterations: int = 100) -> Dict[str, float]:
        """è¿è¡Œé€Ÿåº¦åŸºå‡†æµ‹è¯•"""
        results = {}

        for size, text in self.benchmark_texts.items():
            # ç¼–ç é€Ÿåº¦æµ‹è¯•
            encode_times = []
            for _ in range(iterations):
                start = time.perf_counter()
                try:
                    tokens = tokenizer.encode(text) if hasattr(tokenizer, 'encode') else tokenizer.tokenize(text)
                    end = time.perf_counter()
                    encode_times.append(end - start)
                except Exception as e:
                    print(f"ç¼–ç æµ‹è¯•å¤±è´¥: {e}")
                    break

            # è§£ç é€Ÿåº¦æµ‹è¯• (å¦‚æœæ”¯æŒ)
            decode_times = []
            if hasattr(tokenizer, 'decode') and encode_times:
                try:
                    tokens = tokenizer.encode(text)
                    for _ in range(min(iterations, 20)):  # è§£ç æµ‹è¯•æ¬¡æ•°è¾ƒå°‘
                        start = time.perf_counter()
                        decoded = tokenizer.decode(tokens)
                        end = time.perf_counter()
                        decode_times.append(end - start)
                except:
                    pass

            results[size] = {
                'encode_avg_ms': statistics.mean(encode_times) * 1000 if encode_times else 0,
                'encode_std_ms': statistics.stdev(encode_times) * 1000 if len(encode_times) > 1 else 0,
                'decode_avg_ms': statistics.mean(decode_times) * 1000 if decode_times else 0,
                'text_length': len(text),
                'throughput_chars_per_sec': len(text) / statistics.mean(encode_times) if encode_times else 0
            }

        return results

    def run_memory_benchmark(self, tokenizer) -> Dict[str, float]:
        """è¿è¡Œå†…å­˜ä½¿ç”¨åŸºå‡†æµ‹è¯•"""
        if not MEMORY_MONITORING_AVAILABLE:
            print("âš ï¸  å†…å­˜ç›‘æ§åŠŸèƒ½ä¸å¯ç”¨ï¼Œè·³è¿‡å†…å­˜åŸºå‡†æµ‹è¯•")
            return {}

        process = psutil.Process()

        # åŸºçº¿å†…å­˜
        baseline_memory = process.memory_info().rss / 1024 / 1024  # MB

        memory_results = {}

        for size, text in self.benchmark_texts.items():
            try:
                # æ‰§è¡Œåˆ†è¯æ“ä½œ
                tokens = tokenizer.encode(text) if hasattr(tokenizer, 'encode') else tokenizer.tokenize(text)

                # æµ‹é‡å†…å­˜ä½¿ç”¨
                current_memory = process.memory_info().rss / 1024 / 1024
                memory_delta = current_memory - baseline_memory

                memory_results[size] = {
                    'memory_usage_mb': memory_delta,
                    'tokens_count': len(tokens) if tokens else 0,
                    'memory_per_token_kb': (memory_delta * 1024) / max(len(tokens), 1) if tokens else 0
                }

            except Exception as e:
                print(f"å†…å­˜æµ‹è¯•å¤±è´¥ {size}: {e}")

        return memory_results

    def run_concurrent_benchmark(self, tokenizer, num_threads: int = 4) -> Dict[str, float]:
        """è¿è¡Œå¹¶å‘æ€§èƒ½æµ‹è¯•"""
        test_text = self.benchmark_texts['medium']

        def tokenize_text():
            try:
                start = time.perf_counter()
                tokens = tokenizer.encode(test_text) if hasattr(tokenizer, 'encode') else tokenizer.tokenize(test_text)
                end = time.perf_counter()
                return end - start, len(tokens) if tokens else 0
            except:
                return 0, 0

        # å•çº¿ç¨‹åŸºå‡†
        single_time, token_count = tokenize_text()

        # å¤šçº¿ç¨‹æµ‹è¯•
        with ThreadPoolExecutor(max_workers=num_threads) as executor:
            start_concurrent = time.perf_counter()
            futures = [executor.submit(tokenize_text) for _ in range(num_threads)]
            results = [f.result() for f in futures]
            end_concurrent = time.perf_counter()

        concurrent_times = [r[0] for r in results if r[0] > 0]

        return {
            'single_thread_ms': single_time * 1000,
            'concurrent_total_ms': (end_concurrent - start_concurrent) * 1000,
            'concurrent_avg_ms': statistics.mean(concurrent_times) * 1000 if concurrent_times else 0,
            'speedup_factor': (single_time * num_threads) / (end_concurrent - start_concurrent) if (end_concurrent - start_concurrent) > 0 else 0,
            'thread_count': num_threads
        }