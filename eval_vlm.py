"""Evaluate a trained MiniMind VLM checkpoint."""
from __future__ import annotations

import argparse
import os
import warnings

import torch
from PIL import Image
from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer

from model.model_vlm import MiniMindVLM, VLMConfig
from trainer.trainer_utils import setup_seed

warnings.filterwarnings('ignore')


def init_model(args):
    tokenizer = AutoTokenizer.from_pretrained(args.load_from)
    if 'model' in args.load_from:
        moe_suffix = '_moe' if args.use_moe else ''
        ckp = f'./{args.save_dir}/{args.weight}_{args.hidden_size}{moe_suffix}.pth'
        model = MiniMindVLM(
            VLMConfig(hidden_size=args.hidden_size, num_hidden_layers=args.num_hidden_layers, use_moe=bool(args.use_moe)),
            vision_model_path=args.vision_model_path,
        )
        state_dict = torch.load(ckp, map_location=args.device)
        model.load_state_dict({k: v for k, v in state_dict.items() if 'mask' not in k}, strict=False)
    else:
        model = AutoModelForCausalLM.from_pretrained(args.load_from, trust_remote_code=True)
        model.vision_encoder, model.processor = MiniMindVLM.get_vision_model(args.vision_model_path)

    print(f'VLMæ¨¡å‹å‚æ•°: {sum(p.numel() for p in model.parameters() if p.requires_grad) / 1e6:.2f} M(illion)')
    preprocess = model.processor
    return model.eval().to(args.device), tokenizer, preprocess


def main():
    parser = argparse.ArgumentParser(description='MiniMind-V Chat')
    parser.add_argument('--load_from', default='model', type=str, help='æ¨¡å‹åŠ è½½è·¯å¾„ï¼ˆmodel=åŸç”Ÿæƒé‡ï¼Œå…¶ä»–è·¯å¾„=transformersæ ¼å¼ï¼‰')
    parser.add_argument('--save_dir', default='out', type=str, help='æ¨¡å‹æƒé‡ç›®å½•')
    parser.add_argument('--weight', default='sft_vlm', type=str, help='æƒé‡åç§°å‰ç¼€ï¼ˆpretrain_vlm, sft_vlmï¼‰')
    parser.add_argument('--hidden_size', default=512, type=int, help='éšè—å±‚ç»´åº¦')
    parser.add_argument('--num_hidden_layers', default=8, type=int, help='éšè—å±‚æ•°é‡')
    parser.add_argument('--use_moe', default=0, type=int, choices=[0, 1], help='æ˜¯å¦ä½¿ç”¨MoEæ¶æ„')
    parser.add_argument('--max_new_tokens', default=256, type=int, help='æœ€å¤§ç”Ÿæˆé•¿åº¦')
    parser.add_argument('--temperature', default=0.65, type=float, help='ç”Ÿæˆæ¸©åº¦')
    parser.add_argument('--top_p', default=0.85, type=float, help='nucleusé‡‡æ ·é˜ˆå€¼')
    parser.add_argument('--image_dir', default='./dataset/vlm/eval_images', type=str, help='æµ‹è¯•å›¾åƒç›®å½•')
    parser.add_argument('--device', default='cuda' if torch.cuda.is_available() else 'cpu', type=str, help='è¿è¡Œè®¾å¤‡')
    parser.add_argument('--vision_model_path', default='./model/vision_model/clip-vit-base-patch16', type=str, help='è§†è§‰æ¨¡å‹è·¯å¾„')
    args = parser.parse_args()

    model, tokenizer, preprocess = init_model(args)
    streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)
    prompt = "ä»”ç»†çœ‹ä¸€ä¸‹è¿™å¼ å›¾ï¼š\n\n<image>\n\næè¿°ä¸€ä¸‹è¿™ä¸ªå›¾åƒçš„å†…å®¹ã€‚"

    for image_file in sorted(os.listdir(args.image_dir)):
        if image_file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):
            setup_seed(2026)
            image_path = os.path.join(args.image_dir, image_file)
            image = Image.open(image_path).convert('RGB')
            pixel_values = MiniMindVLM.image2tensor(image, preprocess).to(args.device).unsqueeze(0)

            messages = [{"role": "user", "content": prompt.replace('<image>', model.params.image_special_token)}]
            inputs_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
            inputs = tokenizer(inputs_text, return_tensors='pt', truncation=True).to(args.device)

            print(f'[å›¾åƒ]: {image_file}')
            prompt_display = prompt.replace("\n", "\\n")
            print(f'ğŸ‘¶: {prompt_display}')
            print('ğŸ¤–ï¸: ', end='')
            model.generate(
                inputs=inputs['input_ids'],
                attention_mask=inputs['attention_mask'],
                max_new_tokens=args.max_new_tokens,
                do_sample=True,
                streamer=streamer,
                pad_token_id=tokenizer.pad_token_id,
                eos_token_id=tokenizer.eos_token_id,
                top_p=args.top_p,
                temperature=args.temperature,
                pixel_values=pixel_values,
            )
            print('\n')


if __name__ == '__main__':
    main()
