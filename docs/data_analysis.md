# MiniGPT 数据构成分析与优化方案

## 1. 数据集总览
- 目录结构：`data/` 下包含主训练集 (`pretrain_hq.jsonl`、`sft_mini_512.jsonl`)、身份与辅助语料 (`minigpt_identity.jsonl`)、评测集 (`eval/regression_prompts.jsonl`)，以及 `dataset/minimind_dataset/` 中的大体量备份与派生集（SFT 512/1024/2048、DPO、R1 等）。
- 规模统计：
  - 预训练候选：`pretrain_hq.jsonl` 约 141 万条（与 `dataset/minimind_dataset/pretrain_hq.jsonl` 相同）。
  - 监督微调：`sft_mini_512.jsonl` 约 121 万条；完整版本 `sft_512.jsonl`、`sft_1024.jsonl`、`sft_2048.jsonl` 分别约 680 万、420 万、540 万条。
  - 其它：`dpo.jsonl` 约 20.7 万条，`r1_mix_1024.jsonl` 约 19 万条，医药类 LoRA 语料 2.5 万条。

## 2. 预训练数据评估（`pretrain_hq.jsonl`）
### 2.1 内容形态
- 样本由 `<|im_start|>`/`<|im_end|>` 包裹的问答对组成，平均长度约 437 字、2.5 段对话，缺乏原始长文本。
- 语种以中文为主（约 75% 汉字），英语比例极低，领域覆盖集中在日常问答、写作、摘要等指令场景。

### 2.2 质量与偏差
- 高度模板化和安全告知语：在 20 万条抽样中，“无法”“抱歉”类表达占比 >15%，"作为一个AI" 约 1%，易导致模型过度拒答。
- 任务单一且缺少事实核查、知识密集场景；几乎无代码、百科、推理等多样任务。
- 与典型 SFT 格式接近，易在预训练阶段过早灌输“对话式”输出，使模型基础语言建模与多域知识学习不足。

### 2.3 风险
- 作为基础预训练语料，无法支撑语言广覆盖和长上下文建模；若直接使用，模型将表现出窄域知识、过度守规和模板化输出。

## 3. 监督微调数据评估（`sft_mini_512.jsonl` 及扩展集）
### 3.1 结构特征
- 平均 4.15 轮对话，用户提示 20 字左右、助手回复均值 118 字。
- 数据以中文任务为主（>88% 中文字符），英文及多语场景缺乏。

### 3.2 质量问题
- 占位与未完成输出：含 “...”“省略”“待补充” 等共 1.3 万余条，部分样本只给出“请提供更多信息”。
- 重复度：去重后重复约 3.3%，主要集中于模板化写作或分类题目。
- 指令多为简单请求（排序、定义、摘要），复杂推理、多工具协作等任务稀缺。
- 不同子集中还混入 `<think>`/`<answer>`（思维链）等内部标记，若未经处理直接训练，会引发模型在推理时泄露“思考”文本。

### 3.3 风险
- 微调后模型易延续“索要更多信息”或输出不完整文本的问题；缺少真实复杂任务会降低对真实用户输入的鲁棒性。

## 4. 其他语料评估
- `minigpt_identity.jsonl`（21 条）明确品牌设定，但量级过小，难以稳定 persona，且内容高度重复。
- `dpo.jsonl`、`r1_mix_1024.jsonl` 提供偏好和思维链数据，可在后续对齐阶段使用，但需先统一格式与标签。

## 5. 对训练与模型效果的影响
- 使用当前“预训练”集作为基础语料会导致模型语言知识面窄、长文本生成弱、跨语种能力差。
- SFT 集合中的占位与重复数据会放大敷衍回答与模板化问题，影响用户体验；安全拒答模板可能被进一步强化。
- Persona 数据不足易造成模型在开放域中频繁重复“来自 alex-ckl.com”类描述，影响通用场景。
- `<think>` 等机密 token 未清洗可能导致推理时输出内部链路，增加部署风险。

## 6. 优化方案
### 6.1 预训练阶段
1. **扩充原始语料**：引入大规模多域文本（百科、书籍、新闻、论坛、代码、技术文档等），确保语言覆盖和知识广度。
2. **分层混合策略**：保持原有指令数据占比低于 10%，将其作为“指令 seed” 融入基础语料，防止提前过拟合格式。
3. **语言与任务多样化**：扩展英文、双语以及专业领域（金融、法律、STEM）语料，满足跨场景需求。

### 6.2 监督微调阶段
1. **数据清洗**：剔除含占位符、未完成回复、重复样本；修正语法错误和逻辑不通的回答。
2. **任务补充**：新增复杂、多轮、多步骤任务（工具调用、代码调试、实务问答、长文总结）；引入真实用户日志或人工合成的多轮对话。
3. **标记规范**：对 `<think>` 等特殊标记进行分离或使用特殊监督方式（如思维链单独微调），避免泄露。
4. **Persona 重训**：扩充身份与安全提示语料，并控制训练阶段混入比例，使模型在通用场景不过度自我强调。
5. **质量评估闭环**：建立自动化脚本监测拒答率、模板词频、重复率，训练前后对比指标。

### 6.3 对齐与测试
1. **DPO/RLHF 配置**：在清洗后的 SFT 基础上，利用 `dpo.jsonl`、`r1_mix_1024.jsonl` 进行偏好优化，但需确保“chosen/rejected”质量。
2. **验证集扩展**：在 `data/eval/regression_prompts.jsonl` 基础上新增多领域评测（长文本生成、代码、数学），跟踪模型改进。
3. **逐步试训**：先小规模实训验证拒答率、回答完整度及英文表现，再逐步放大。

---
本文档路径：`docs/data_analysis.md`

## 7. 数据清洗脚本
脚本路径：`scripts/clean_datasets.py`，支持以下核心能力：
- **去重**：`--dedupe` 基于规范化哈希去除完全重复样本。
- **占位/未完成过滤**：`--drop-placeholders` 可过滤含 “...”“省略”“待补充”等占位符的样本。
- **跟进请求过滤**：`--drop-followups` 针对只索要更多信息的助手回复予以移除。
- **思维链剥离**：`--strip-think` 删除 `<think>` 内容并解包 `<answer>` 节点。
- **拒答阈值**：`--max-refusal-count` 控制拒答语（“抱歉”“无法”等）的最大出现次数。

使用示例：
```bash
# 清洗 SFT
python scripts/clean_datasets.py \
  --input data/sft_mini_512.jsonl \
  --output data/clean/sft_mini_512.cleaned.jsonl \
  --dataset-type sft --dedupe --drop-placeholders --drop-followups --strip-think

# 清洗预训练指令集，限制拒答频率
python scripts/clean_datasets.py \
  --input data/pretrain_hq.jsonl \
  --output data/clean/pretrain_hq.cleaned.jsonl \
  --dataset-type pretrain --dedupe --drop-placeholders --strip-think --max-refusal-count 2
```
脚本执行后将在终端输出 JSON 格式的统计信息（总条数、写入条数、删除原因计数等），便于纳入数据处理流水线。
