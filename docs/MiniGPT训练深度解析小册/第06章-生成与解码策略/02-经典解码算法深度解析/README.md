# 02 ç»å…¸è§£ç ç®—æ³•æ·±åº¦è§£æ

> **ä»å±€éƒ¨æœ€ä¼˜åˆ°å…¨å±€æœç´¢ï¼šè¯­è¨€ç”Ÿæˆä¸­çš„ç®—æ³•æ™ºæ…§**

## æ ¸å¿ƒæ€æƒ³

è§£ç ç®—æ³•æ˜¯è¿æ¥æ¨¡å‹æ¦‚ç‡åˆ†å¸ƒä¸å®é™…æ–‡æœ¬è¾“å‡ºçš„æ¡¥æ¢ã€‚ä¸åŒçš„è§£ç ç­–ç•¥ä½“ç°äº†ä¸åŒçš„å“²å­¦æ€æƒ³ï¼šè´ªå¿ƒè§£ç è¿½æ±‚å±€éƒ¨ç¡®å®šæ€§ï¼Œbeam searchå¯»æ±‚æœ‰é™çš„å…¨å±€ä¼˜åŒ–ï¼Œè€Œéšæœºé‡‡æ ·åˆ™æ‹¥æŠ±ä¸ç¡®å®šæ€§çš„åˆ›é€ åŠ›ã€‚

**å…³é”®æ´å¯Ÿ**ï¼š
- **ç¡®å®šæ€§vséšæœºæ€§**ï¼šä¸åŒç­–ç•¥å¯¹ç”Ÿæˆç»“æœå¯é¢„æµ‹æ€§çš„å½±å“
- **å±€éƒ¨vså…¨å±€**ï¼šçŸ­æœŸæœ€ä¼˜ä¸é•¿æœŸæœ€ä¼˜çš„æ•°å­¦æƒè¡¡
- **æ•ˆç‡vsè´¨é‡**ï¼šè®¡ç®—èµ„æºä¸ç”Ÿæˆè´¨é‡çš„å¸•ç´¯æ‰˜å‰æ²¿
- **æœç´¢vsé‡‡æ ·**ï¼šä¸¤ç§æ ¹æœ¬ä¸åŒçš„åºåˆ—ç©ºé—´æ¢ç´¢èŒƒå¼

ä»ç®—æ³•è§’åº¦çœ‹ï¼Œæ¯ç§è§£ç æ–¹æ³•éƒ½æ˜¯åœ¨å·¨å¤§çš„åºåˆ—ç©ºé—´ä¸­å®šä¹‰äº†ä¸€ç§ç‰¹å®šçš„éå†ç­–ç•¥ï¼Œå…¶æ•°å­¦ç‰¹æ€§å†³å®šäº†ç”Ÿæˆæ–‡æœ¬çš„ç»Ÿè®¡ç‰¹å¾ã€‚

## 2.1 è´ªå¿ƒè§£ç çš„æ•°å­¦æ€§è´¨

### å±€éƒ¨æœ€ä¼˜æ€§çš„ä¸¥æ ¼è¯æ˜

**è´ªå¿ƒç­–ç•¥å®šä¹‰**ï¼š
åœ¨æ¯ä¸ªæ—¶é—´æ­¥$t$ï¼Œè´ªå¿ƒè§£ç é€‰æ‹©æ¦‚ç‡æœ€å¤§çš„tokenï¼š
$$y_t^* = \arg\max_{y \in \mathcal{V}} P(y|x, y_{<t})$$

**å±€éƒ¨æœ€ä¼˜æ€§å®šç†**ï¼š
**å®šç†**ï¼šè´ªå¿ƒè§£ç åœ¨æ¯ä¸ªæ—¶é—´æ­¥éƒ½èƒ½æ‰¾åˆ°å±€éƒ¨æœ€ä¼˜è§£ã€‚

**è¯æ˜**ï¼š
è®¾$P(y_t|x, y_{<t})$ä¸ºæ—¶é—´æ­¥$t$çš„æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒã€‚è´ªå¿ƒé€‰æ‹©$y_t^* = \arg\max_y P(y|x, y_{<t})$æ»¡è¶³ï¼š
$$P(y_t^*|x, y_{<t}) \geq P(y|x, y_{<t}), \quad \forall y \in \mathcal{V}$$

å› æ­¤ï¼Œ$y_t^*$æ˜¯å±€éƒ¨æ„ä¹‰ä¸‹çš„æœ€ä¼˜é€‰æ‹©ã€‚$\square$

**å…¨å±€æ¬¡ä¼˜æ€§åˆ†æ**ï¼š
ç„¶è€Œï¼Œå±€éƒ¨æœ€ä¼˜ä¸ç­‰ä»·äºå…¨å±€æœ€ä¼˜ã€‚è®¾$Y^* = \arg\max_Y P(Y|x)$ä¸ºå…¨å±€æœ€ä¼˜åºåˆ—ï¼Œ$Y^g$ä¸ºè´ªå¿ƒè§£ç åºåˆ—ï¼Œä¸€èˆ¬æœ‰ï¼š
$$P(Y^g|x) \leq P(Y^*|x)$$

è¿™ç§å·®è·çš„æ•°å­¦ä¸‹ç•Œå¯ä»¥é€šè¿‡ä»¥ä¸‹å¼•ç†ç»™å‡ºï¼š

**å¼•ç†**ï¼šè®¾$\delta = \max_t |\max_y P(y|x, y_{<t}) - \sum_y P(y|x, y_{<t})P(y|x, y_{<t})|$ï¼Œåˆ™ï¼š
$$P(Y^*|x) - P(Y^g|x) \geq T \cdot \delta \cdot \prod_{i=1}^T P(y_i^g|x, y_{<i})$$

å…¶ä¸­$T$æ˜¯åºåˆ—é•¿åº¦ã€‚

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import Dict, List, Tuple, Optional, Union, Any
import matplotlib.pyplot as plt
import seaborn as sns
import math
import time
from collections import defaultdict, Counter
from dataclasses import dataclass
import heapq
from abc import ABC, abstractmethod

@dataclass
class DecodingResult:
    """è§£ç ç»“æœæ•°æ®ç»“æ„"""
    sequence: List[int]           # ç”Ÿæˆçš„tokenåºåˆ—
    log_probability: float        # åºåˆ—çš„å¯¹æ•°æ¦‚ç‡
    score: float                  # è§£ç åˆ†æ•°
    decoding_time: float         # è§£ç æ—¶é—´
    metadata: Dict[str, Any]     # é¢å¤–ä¿¡æ¯
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}

class BaseDecoder(ABC):
    """è§£ç å™¨åŸºç±»"""
    
    def __init__(self, vocab_size: int = 1000, max_length: int = 50):
        self.vocab_size = vocab_size
        self.max_length = max_length
        self.eos_token = 1
        self.pad_token = 0
        
    @abstractmethod
    def decode(self, model, prompt: str, **kwargs) -> DecodingResult:
        """è§£ç æ–¹æ³•çš„æŠ½è±¡æ¥å£"""
        pass
    
    def _get_model_logits(self, model, input_ids: torch.Tensor) -> torch.Tensor:
        """è·å–æ¨¡å‹logitsï¼ˆç®€åŒ–å®ç°ï¼‰"""
        # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œåº”è¯¥æ˜¯model(input_ids).logits
        batch_size, seq_len = input_ids.shape
        return torch.randn(batch_size, seq_len, self.vocab_size)
    
    def _tokenize(self, text: str) -> List[int]:
        """ç®€åŒ–çš„tokenåŒ–"""
        words = text.split()
        tokens = [2]  # BOS
        for word in words[:20]:  # é™åˆ¶é•¿åº¦
            token_id = abs(hash(word)) % (self.vocab_size - 10) + 3
            tokens.append(token_id)
        return tokens

class GreedyDecoder(BaseDecoder):
    """è´ªå¿ƒè§£ç å™¨"""
    
    def __init__(self, vocab_size: int = 1000, max_length: int = 50):
        super().__init__(vocab_size, max_length)
        self.decoding_stats = {
            'local_optimality_violations': 0,
            'probability_trajectory': [],
            'entropy_trajectory': []
        }
    
    def decode(self, model, prompt: str, **kwargs) -> DecodingResult:
        """è´ªå¿ƒè§£ç å®ç°"""
        
        start_time = time.time()
        
        # åˆå§‹åŒ–
        input_tokens = self._tokenize(prompt)
        generated_tokens = []
        log_probability = 0.0
        
        # è´ªå¿ƒç”Ÿæˆè¿‡ç¨‹
        current_input = torch.tensor([input_tokens], dtype=torch.long)
        
        for step in range(self.max_length):
            # è·å–ä¸‹ä¸€ä¸ªtokençš„æ¦‚ç‡åˆ†å¸ƒ
            with torch.no_grad():
                logits = self._get_model_logits(model, current_input)
                next_token_logits = logits[0, -1, :]  # å–æœ€åä¸€ä¸ªä½ç½®çš„logits
                
                # è®¡ç®—æ¦‚ç‡åˆ†å¸ƒ
                probs = F.softmax(next_token_logits, dim=-1)
                
                # è´ªå¿ƒé€‰æ‹©
                next_token = torch.argmax(probs).item()
                next_token_prob = probs[next_token].item()
                
                # è®°å½•ç»Ÿè®¡ä¿¡æ¯
                entropy = -(probs * torch.log(probs + 1e-10)).sum().item()
                self.decoding_stats['entropy_trajectory'].append(entropy)
                self.decoding_stats['probability_trajectory'].append(next_token_prob)
                
                # æ›´æ–°åºåˆ—
                generated_tokens.append(next_token)
                log_probability += math.log(next_token_prob + 1e-10)
                
                # æ£€æŸ¥ç»ˆæ­¢æ¡ä»¶
                if next_token == self.eos_token:
                    break
                
                # æ›´æ–°è¾“å…¥
                current_input = torch.cat([
                    current_input, 
                    torch.tensor([[next_token]], dtype=torch.long)
                ], dim=1)
        
        decoding_time = time.time() - start_time
        
        # åˆ†æå±€éƒ¨æœ€ä¼˜æ€§
        local_optimality_score = self._analyze_local_optimality()
        
        return DecodingResult(
            sequence=input_tokens + generated_tokens,
            log_probability=log_probability,
            score=log_probability / len(generated_tokens) if generated_tokens else 0,
            decoding_time=decoding_time,
            metadata={
                'algorithm': 'greedy',
                'local_optimality_score': local_optimality_score,
                'entropy_trajectory': self.decoding_stats['entropy_trajectory'],
                'probability_trajectory': self.decoding_stats['probability_trajectory']
            }
        )
    
    def _analyze_local_optimality(self) -> float:
        """åˆ†æå±€éƒ¨æœ€ä¼˜æ€§è´¨é‡"""
        
        if not self.decoding_stats['probability_trajectory']:
            return 0.0
        
        # å±€éƒ¨æœ€ä¼˜æ€§åˆ†æ•°ï¼šåŸºäºé€‰æ‹©æ¦‚ç‡çš„å¹³å‡å€¼
        avg_prob = np.mean(self.decoding_stats['probability_trajectory'])
        
        # ä¸€è‡´æ€§åˆ†æ•°ï¼šæ¦‚ç‡æ–¹å·®çš„å€’æ•°
        prob_variance = np.var(self.decoding_stats['probability_trajectory'])
        consistency = 1.0 / (1.0 + prob_variance)
        
        return avg_prob * consistency
    
    def analyze_optimality_gap(self, model, prompts: List[str], 
                             reference_sequences: List[List[int]] = None) -> Dict:
        """åˆ†ææœ€ä¼˜æ€§å·®è·"""
        
        print("=== è´ªå¿ƒè§£ç æœ€ä¼˜æ€§åˆ†æ ===")
        
        optimality_analysis = {
            'local_scores': [],
            'global_gaps': [],
            'probability_ratios': [],
            'entropy_evolution': []
        }
        
        for i, prompt in enumerate(prompts):
            # è´ªå¿ƒè§£ç 
            greedy_result = self.decode(model, prompt)
            
            # å±€éƒ¨æœ€ä¼˜æ€§åˆ†æ•°
            local_score = greedy_result.metadata.get('local_optimality_score', 0)
            optimality_analysis['local_scores'].append(local_score)
            
            # å¦‚æœæœ‰å‚è€ƒåºåˆ—ï¼Œè®¡ç®—å…¨å±€å·®è·
            if reference_sequences and i < len(reference_sequences):
                ref_seq = reference_sequences[i]
                gap = self._compute_global_gap(greedy_result.sequence, ref_seq)
                optimality_analysis['global_gaps'].append(gap)
            
            # æ¦‚ç‡æ¯”ç‡åˆ†æ
            prob_trajectory = greedy_result.metadata.get('probability_trajectory', [])
            if prob_trajectory:
                max_prob = max(prob_trajectory)
                min_prob = min(prob_trajectory)
                ratio = max_prob / (min_prob + 1e-10)
                optimality_analysis['probability_ratios'].append(ratio)
            
            # ç†µæ¼”åŒ–
            entropy_traj = greedy_result.metadata.get('entropy_trajectory', [])
            if entropy_traj:
                optimality_analysis['entropy_evolution'].append(entropy_traj)
        
        # å¯è§†åŒ–åˆ†æç»“æœ
        self._visualize_optimality_analysis(optimality_analysis)
        
        return optimality_analysis
    
    def _compute_global_gap(self, greedy_seq: List[int], reference_seq: List[int]) -> float:
        """è®¡ç®—ä¸å‚è€ƒåºåˆ—çš„å…¨å±€å·®è·"""
        
        # ç®€åŒ–çš„å·®è·è®¡ç®—ï¼šåŸºäºç¼–è¾‘è·ç¦»
        min_len = min(len(greedy_seq), len(reference_seq))
        
        if min_len == 0:
            return 1.0
        
        differences = sum(1 for i in range(min_len) if greedy_seq[i] != reference_seq[i])
        length_diff = abs(len(greedy_seq) - len(reference_seq))
        
        gap = (differences + length_diff) / max(len(greedy_seq), len(reference_seq))
        return min(1.0, gap)
    
    def _visualize_optimality_analysis(self, analysis: Dict):
        """å¯è§†åŒ–æœ€ä¼˜æ€§åˆ†æ"""
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # å±€éƒ¨æœ€ä¼˜æ€§åˆ†æ•°åˆ†å¸ƒ
        if analysis['local_scores']:
            axes[0, 0].hist(analysis['local_scores'], bins=15, alpha=0.7, edgecolor='black')
            axes[0, 0].set_title('å±€éƒ¨æœ€ä¼˜æ€§åˆ†æ•°åˆ†å¸ƒ')
            axes[0, 0].set_xlabel('æœ€ä¼˜æ€§åˆ†æ•°')
            axes[0, 0].set_ylabel('é¢‘æ¬¡')
            axes[0, 0].grid(True, alpha=0.3)
        
        # å…¨å±€å·®è·åˆ†æ
        if analysis['global_gaps']:
            axes[0, 1].hist(analysis['global_gaps'], bins=15, alpha=0.7, 
                           edgecolor='black', color='orange')
            axes[0, 1].set_title('å…¨å±€æœ€ä¼˜æ€§å·®è·')
            axes[0, 1].set_xlabel('å·®è·')
            axes[0, 1].set_ylabel('é¢‘æ¬¡')
            axes[0, 1].grid(True, alpha=0.3)
        
        # æ¦‚ç‡æ¯”ç‡
        if analysis['probability_ratios']:
            axes[1, 0].hist(analysis['probability_ratios'], bins=15, alpha=0.7,
                           edgecolor='black', color='green')
            axes[1, 0].set_title('æ¦‚ç‡æ¯”ç‡åˆ†å¸ƒ')
            axes[1, 0].set_xlabel('æœ€å¤§/æœ€å°æ¦‚ç‡æ¯”')
            axes[1, 0].set_ylabel('é¢‘æ¬¡')
            axes[1, 0].set_xscale('log')
            axes[1, 0].grid(True, alpha=0.3)
        
        # ç†µæ¼”åŒ–ï¼ˆå–ç¬¬ä¸€ä¸ªæ ·æœ¬ä½œä¸ºç¤ºä¾‹ï¼‰
        if analysis['entropy_evolution'] and analysis['entropy_evolution'][0]:
            entropy_traj = analysis['entropy_evolution'][0]
            axes[1, 1].plot(entropy_traj, 'b-o', linewidth=2)
            axes[1, 1].set_title('ç†µæ¼”åŒ–è½¨è¿¹ (ç¤ºä¾‹)')
            axes[1, 1].set_xlabel('ç”Ÿæˆæ­¥æ•°')
            axes[1, 1].set_ylabel('ç†µå€¼')
            axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()

class BeamSearchDecoder(BaseDecoder):
    """Beam Searchè§£ç å™¨"""
    
    def __init__(self, vocab_size: int = 1000, max_length: int = 50, 
                 beam_size: int = 5, length_penalty: float = 1.0):
        super().__init__(vocab_size, max_length)
        self.beam_size = beam_size
        self.length_penalty = length_penalty
        
    def decode(self, model, prompt: str, **kwargs) -> DecodingResult:
        """Beam Searchè§£ç å®ç°"""
        
        start_time = time.time()
        
        # åˆå§‹åŒ–
        input_tokens = self._tokenize(prompt)
        
        # Beam state: (åºåˆ—, ç´¯ç§¯å¯¹æ•°æ¦‚ç‡, æ´»è·ƒçŠ¶æ€)
        beams = [(input_tokens, 0.0, True)]
        completed_beams = []
        
        for step in range(self.max_length):
            candidates = []
            
            # ä¸ºæ¯ä¸ªæ´»è·ƒçš„beamç”Ÿæˆå€™é€‰
            for sequence, log_prob, is_active in beams:
                if not is_active:
                    continue
                
                # è·å–ä¸‹ä¸€ä¸ªtokençš„æ¦‚ç‡åˆ†å¸ƒ
                current_input = torch.tensor([sequence], dtype=torch.long)
                
                with torch.no_grad():
                    logits = self._get_model_logits(model, current_input)
                    next_token_logits = logits[0, -1, :]
                    log_probs = F.log_softmax(next_token_logits, dim=-1)
                
                # ç”Ÿæˆtop-kå€™é€‰
                top_k_log_probs, top_k_tokens = torch.topk(log_probs, self.beam_size)
                
                for i in range(self.beam_size):
                    next_token = top_k_tokens[i].item()
                    next_log_prob = top_k_log_probs[i].item()
                    
                    new_sequence = sequence + [next_token]
                    new_log_prob = log_prob + next_log_prob
                    
                    # é•¿åº¦æ ‡å‡†åŒ–
                    normalized_score = self._compute_normalized_score(
                        new_log_prob, len(new_sequence) - len(input_tokens)
                    )
                    
                    # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                    if next_token == self.eos_token:
                        completed_beams.append((new_sequence, new_log_prob, normalized_score))
                    else:
                        candidates.append((new_sequence, new_log_prob, normalized_score, True))
            
            # é€‰æ‹©top-kå€™é€‰ä½œä¸ºæ–°çš„beams
            if candidates:
                # æŒ‰æ ‡å‡†åŒ–åˆ†æ•°æ’åº
                candidates.sort(key=lambda x: x[2], reverse=True)
                beams = [(seq, log_prob, active) for seq, log_prob, _, active in candidates[:self.beam_size]]
            else:
                break
            
            # å¦‚æœæ‰€æœ‰beaméƒ½å®Œæˆäº†ï¼Œæå‰é€€å‡º
            if not any(active for _, _, active in beams):
                break
        
        # é€‰æ‹©æœ€ä½³å®Œæˆåºåˆ—
        if completed_beams:
            best_sequence, best_log_prob, best_score = max(completed_beams, key=lambda x: x[2])
        elif beams:
            # å¦‚æœæ²¡æœ‰å®Œæˆçš„åºåˆ—ï¼Œé€‰æ‹©æœ€ä½³çš„æœªå®Œæˆåºåˆ—
            best_beam = max(beams, key=lambda x: x[1])
            best_sequence, best_log_prob = best_beam[0], best_beam[1]
            best_score = self._compute_normalized_score(
                best_log_prob, len(best_sequence) - len(input_tokens)
            )
        else:
            best_sequence, best_log_prob, best_score = input_tokens, 0.0, 0.0
        
        decoding_time = time.time() - start_time
        
        return DecodingResult(
            sequence=best_sequence,
            log_probability=best_log_prob,
            score=best_score,
            decoding_time=decoding_time,
            metadata={
                'algorithm': 'beam_search',
                'beam_size': self.beam_size,
                'length_penalty': self.length_penalty,
                'completed_beams': len(completed_beams),
                'total_candidates': len(completed_beams) + len(beams)
            }
        )
    
    def _compute_normalized_score(self, log_prob: float, length: int) -> float:
        """è®¡ç®—é•¿åº¦æ ‡å‡†åŒ–åˆ†æ•°"""
        
        if length == 0:
            return log_prob
        
        # Google's length penalty formula
        # score = log_prob / ((5 + length) / 6) ** length_penalty
        length_penalty_factor = ((5 + length) / 6) ** self.length_penalty
        
        return log_prob / length_penalty_factor
    
    def analyze_beam_dynamics(self, model, prompts: List[str], 
                            beam_sizes: List[int] = None) -> Dict:
        """åˆ†æBeam SearchåŠ¨æ€ç‰¹æ€§"""
        
        print("=== Beam SearchåŠ¨æ€åˆ†æ ===")
        
        if beam_sizes is None:
            beam_sizes = [1, 2, 4, 8, 16]
        
        dynamics_analysis = {
            'beam_size_effects': {},
            'search_efficiency': [],
            'diversity_metrics': [],
            'convergence_analysis': []
        }
        
        for beam_size in beam_sizes:
            print(f"åˆ†æbeam_size={beam_size}")
            
            # ä½¿ç”¨ä¸åŒbeam sizeè¿›è¡Œè§£ç 
            original_beam_size = self.beam_size
            self.beam_size = beam_size
            
            beam_results = []
            for prompt in prompts:
                result = self.decode(model, prompt)
                beam_results.append(result)
            
            # æ¢å¤åŸå§‹beam size
            self.beam_size = original_beam_size
            
            # åˆ†æè¯¥beam sizeçš„ç‰¹æ€§
            beam_analysis = self._analyze_beam_size_effect(beam_results)
            dynamics_analysis['beam_size_effects'][beam_size] = beam_analysis
        
        # ç»¼åˆåˆ†æ
        self._analyze_beam_convergence(dynamics_analysis)
        
        # å¯è§†åŒ–åˆ†æç»“æœ
        self._visualize_beam_dynamics(dynamics_analysis)
        
        return dynamics_analysis
    
    def _analyze_beam_size_effect(self, results: List[DecodingResult]) -> Dict:
        """åˆ†æç‰¹å®šbeam sizeçš„æ•ˆæœ"""
        
        scores = [r.score for r in results]
        decoding_times = [r.decoding_time for r in results]
        sequence_lengths = [len(r.sequence) for r in results]
        
        return {
            'average_score': np.mean(scores),
            'score_std': np.std(scores),
            'average_time': np.mean(decoding_times),
            'average_length': np.mean(sequence_lengths),
            'length_std': np.std(sequence_lengths)
        }
    
    def _analyze_beam_convergence(self, dynamics: Dict):
        """åˆ†æbeam searchæ”¶æ•›ç‰¹æ€§"""
        
        beam_sizes = sorted(dynamics['beam_size_effects'].keys())
        scores = [dynamics['beam_size_effects'][bs]['average_score'] for bs in beam_sizes]
        
        # è®¡ç®—è¾¹é™…æ”¶ç›Šé€’å‡
        marginal_gains = []
        for i in range(1, len(scores)):
            gain = scores[i] - scores[i-1]
            marginal_gains.append(gain)
        
        # æ‰¾åˆ°æ”¶ç›Šé€’å‡çš„æ‹ç‚¹
        if len(marginal_gains) > 1:
            gain_ratios = []
            for i in range(1, len(marginal_gains)):
                if marginal_gains[i-1] != 0:
                    ratio = marginal_gains[i] / marginal_gains[i-1]
                    gain_ratios.append(ratio)
        
        dynamics['convergence_analysis'] = {
            'marginal_gains': marginal_gains,
            'diminishing_returns_point': beam_sizes[np.argmin(marginal_gains) + 1] if marginal_gains else beam_sizes[0]
        }
    
    def _visualize_beam_dynamics(self, dynamics: Dict):
        """å¯è§†åŒ–beam searchåŠ¨æ€åˆ†æ"""
        
        beam_sizes = sorted(dynamics['beam_size_effects'].keys())
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # Beam size vs å¹³å‡åˆ†æ•°
        scores = [dynamics['beam_size_effects'][bs]['average_score'] for bs in beam_sizes]
        score_stds = [dynamics['beam_size_effects'][bs]['score_std'] for bs in beam_sizes]
        
        axes[0, 0].errorbar(beam_sizes, scores, yerr=score_stds, marker='o', capsize=5)
        axes[0, 0].set_title('Beam Size vs å¹³å‡åˆ†æ•°')
        axes[0, 0].set_xlabel('Beam Size')
        axes[0, 0].set_ylabel('å¹³å‡åˆ†æ•°')
        axes[0, 0].set_xscale('log')
        axes[0, 0].grid(True, alpha=0.3)
        
        # Beam size vs è§£ç æ—¶é—´
        times = [dynamics['beam_size_effects'][bs]['average_time'] for bs in beam_sizes]
        
        axes[0, 1].plot(beam_sizes, times, 'r-o', linewidth=2)
        axes[0, 1].set_title('Beam Size vs è§£ç æ—¶é—´')
        axes[0, 1].set_xlabel('Beam Size')
        axes[0, 1].set_ylabel('å¹³å‡è§£ç æ—¶é—´ (ç§’)')
        axes[0, 1].set_xscale('log')
        axes[0, 1].grid(True, alpha=0.3)
        
        # è¾¹é™…æ”¶ç›Šåˆ†æ
        if 'marginal_gains' in dynamics['convergence_analysis']:
            marginal_gains = dynamics['convergence_analysis']['marginal_gains']
            gain_beam_sizes = beam_sizes[1:]  # å¯¹åº”marginal gains
            
            axes[1, 0].bar(range(len(marginal_gains)), marginal_gains, alpha=0.7)
            axes[1, 0].set_title('è¾¹é™…æ”¶ç›Šåˆ†æ')
            axes[1, 0].set_xlabel('Beam Sizeå¢é•¿æ­¥éª¤')
            axes[1, 0].set_ylabel('è¾¹é™…åˆ†æ•°å¢ç›Š')
            axes[1, 0].set_xticks(range(len(marginal_gains)))
            axes[1, 0].set_xticklabels([f'{beam_sizes[i]}->{beam_sizes[i+1]}' 
                                       for i in range(len(marginal_gains))], rotation=45)
            axes[1, 0].grid(True, alpha=0.3)
        
        # æ•ˆç‡åˆ†æï¼šåˆ†æ•°/æ—¶é—´æ¯”
        efficiency = [s/t if t > 0 else 0 for s, t in zip(scores, times)]
        
        axes[1, 1].plot(beam_sizes, efficiency, 'g-o', linewidth=2)
        axes[1, 1].set_title('è§£ç æ•ˆç‡ (åˆ†æ•°/æ—¶é—´)')
        axes[1, 1].set_xlabel('Beam Size')
        axes[1, 1].set_ylabel('æ•ˆç‡æ¯”')
        axes[1, 1].set_xscale('log')
        axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()

class RandomSamplingDecoder(BaseDecoder):
    """éšæœºé‡‡æ ·è§£ç å™¨"""
    
    def __init__(self, vocab_size: int = 1000, max_length: int = 50, 
                 temperature: float = 1.0):
        super().__init__(vocab_size, max_length)
        self.temperature = temperature
    
    def decode(self, model, prompt: str, **kwargs) -> DecodingResult:
        """éšæœºé‡‡æ ·è§£ç å®ç°"""
        
        start_time = time.time()
        
        # åˆå§‹åŒ–
        input_tokens = self._tokenize(prompt)
        generated_tokens = []
        log_probability = 0.0
        
        # é‡‡æ ·ç”Ÿæˆè¿‡ç¨‹
        current_input = torch.tensor([input_tokens], dtype=torch.long)
        
        for step in range(self.max_length):
            with torch.no_grad():
                logits = self._get_model_logits(model, current_input)
                next_token_logits = logits[0, -1, :]
                
                # æ¸©åº¦ç¼©æ”¾
                scaled_logits = next_token_logits / self.temperature
                
                # è®¡ç®—æ¦‚ç‡åˆ†å¸ƒ
                probs = F.softmax(scaled_logits, dim=-1)
                
                # éšæœºé‡‡æ ·
                next_token = torch.multinomial(probs, 1).item()
                next_token_prob = probs[next_token].item()
                
                # æ›´æ–°åºåˆ—
                generated_tokens.append(next_token)
                log_probability += math.log(next_token_prob + 1e-10)
                
                # æ£€æŸ¥ç»ˆæ­¢æ¡ä»¶
                if next_token == self.eos_token:
                    break
                
                # æ›´æ–°è¾“å…¥
                current_input = torch.cat([
                    current_input,
                    torch.tensor([[next_token]], dtype=torch.long)
                ], dim=1)
        
        decoding_time = time.time() - start_time
        
        return DecodingResult(
            sequence=input_tokens + generated_tokens,
            log_probability=log_probability,
            score=log_probability / len(generated_tokens) if generated_tokens else 0,
            decoding_time=decoding_time,
            metadata={
                'algorithm': 'random_sampling',
                'temperature': self.temperature
            }
        )
    
    def analyze_temperature_effects(self, model, prompts: List[str], 
                                  temperatures: List[float] = None,
                                  num_samples: int = 10) -> Dict:
        """åˆ†ææ¸©åº¦å‚æ•°çš„æ•ˆæœ"""
        
        print("=== æ¸©åº¦å‚æ•°æ•ˆæœåˆ†æ ===")
        
        if temperatures is None:
            temperatures = [0.1, 0.5, 1.0, 1.5, 2.0]
        
        temperature_analysis = {
            'diversity_metrics': {},
            'quality_metrics': {},
            'probability_distributions': {},
            'entropy_analysis': {}
        }
        
        for temp in temperatures:
            print(f"åˆ†ætemperature={temp}")
            
            # ä½¿ç”¨å½“å‰æ¸©åº¦è¿›è¡Œå¤šæ¬¡é‡‡æ ·
            original_temp = self.temperature
            self.temperature = temp
            
            temp_results = []
            for prompt in prompts:
                # å¯¹æ¯ä¸ªpromptè¿›è¡Œå¤šæ¬¡é‡‡æ ·
                samples = []
                for _ in range(num_samples):
                    result = self.decode(model, prompt)
                    samples.append(result)
                temp_results.append(samples)
            
            # æ¢å¤åŸå§‹æ¸©åº¦
            self.temperature = original_temp
            
            # åˆ†æè¯¥æ¸©åº¦çš„ç‰¹æ€§
            temp_analysis = self._analyze_temperature_effect(temp_results)
            
            temperature_analysis['diversity_metrics'][temp] = temp_analysis['diversity']
            temperature_analysis['quality_metrics'][temp] = temp_analysis['quality']
            temperature_analysis['probability_distributions'][temp] = temp_analysis['prob_dist']
            temperature_analysis['entropy_analysis'][temp] = temp_analysis['entropy']
        
        # å¯è§†åŒ–åˆ†æç»“æœ
        self._visualize_temperature_effects(temperature_analysis)
        
        return temperature_analysis
    
    def _analyze_temperature_effect(self, results: List[List[DecodingResult]]) -> Dict:
        """åˆ†æç‰¹å®šæ¸©åº¦çš„æ•ˆæœ"""
        
        all_sequences = []
        all_scores = []
        all_probs = []
        
        for prompt_results in results:
            sequences = [r.sequence for r in prompt_results]
            scores = [r.score for r in prompt_results]
            
            all_sequences.extend(sequences)
            all_scores.extend(scores)
        
        # å¤šæ ·æ€§åˆ†æ
        diversity = self._compute_sequence_diversity(all_sequences)
        
        # è´¨é‡åˆ†æ
        quality = {
            'mean_score': np.mean(all_scores),
            'score_std': np.std(all_scores),
            'score_range': max(all_scores) - min(all_scores) if all_scores else 0
        }
        
        # æ¦‚ç‡åˆ†å¸ƒåˆ†æï¼ˆç®€åŒ–ï¼‰
        prob_dist = {
            'entropy_estimate': diversity,  # ä½¿ç”¨å¤šæ ·æ€§ä½œä¸ºç†µçš„ä¼°è®¡
            'uniformity': 1.0 - np.std(all_scores) / (np.mean(all_scores) + 1e-10) if all_scores else 0
        }
        
        # ç†µåˆ†æ
        entropy = {
            'sequence_entropy': diversity,
            'score_entropy': -np.sum([(s/sum(all_scores)) * math.log(s/sum(all_scores) + 1e-10) 
                                     for s in all_scores]) if all_scores else 0
        }
        
        return {
            'diversity': diversity,
            'quality': quality,
            'prob_dist': prob_dist,
            'entropy': entropy
        }
    
    def _compute_sequence_diversity(self, sequences: List[List[int]]) -> float:
        """è®¡ç®—åºåˆ—é›†åˆçš„å¤šæ ·æ€§"""
        
        if len(sequences) < 2:
            return 0.0
        
        # ä½¿ç”¨æˆå¯¹ç¼–è¾‘è·ç¦»çš„å¹³å‡å€¼ä½œä¸ºå¤šæ ·æ€§åº¦é‡
        total_distance = 0
        comparisons = 0
        
        for i in range(len(sequences)):
            for j in range(i+1, len(sequences)):
                distance = self._sequence_edit_distance(sequences[i], sequences[j])
                total_distance += distance
                comparisons += 1
        
        avg_distance = total_distance / comparisons if comparisons > 0 else 0
        
        # æ ‡å‡†åŒ–åˆ°[0,1]
        max_possible_distance = max(len(seq) for seq in sequences) if sequences else 1
        normalized_diversity = avg_distance / max_possible_distance
        
        return min(1.0, normalized_diversity)
    
    def _sequence_edit_distance(self, seq1: List[int], seq2: List[int]) -> int:
        """è®¡ç®—ä¸¤ä¸ªåºåˆ—çš„ç¼–è¾‘è·ç¦»"""
        
        m, n = len(seq1), len(seq2)
        dp = [[0] * (n + 1) for _ in range(m + 1)]
        
        # åˆå§‹åŒ–
        for i in range(m + 1):
            dp[i][0] = i
        for j in range(n + 1):
            dp[0][j] = j
        
        # åŠ¨æ€è§„åˆ’
        for i in range(1, m + 1):
            for j in range(1, n + 1):
                if seq1[i-1] == seq2[j-1]:
                    dp[i][j] = dp[i-1][j-1]
                else:
                    dp[i][j] = 1 + min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1])
        
        return dp[m][n]
    
    def _visualize_temperature_effects(self, analysis: Dict):
        """å¯è§†åŒ–æ¸©åº¦æ•ˆæœåˆ†æ"""
        
        temperatures = sorted(analysis['diversity_metrics'].keys())
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # æ¸©åº¦ vs å¤šæ ·æ€§
        diversities = [analysis['diversity_metrics'][t] for t in temperatures]
        
        axes[0, 0].plot(temperatures, diversities, 'b-o', linewidth=2)
        axes[0, 0].set_title('æ¸©åº¦ vs ç”Ÿæˆå¤šæ ·æ€§')
        axes[0, 0].set_xlabel('æ¸©åº¦')
        axes[0, 0].set_ylabel('å¤šæ ·æ€§åˆ†æ•°')
        axes[0, 0].grid(True, alpha=0.3)
        
        # æ¸©åº¦ vs è´¨é‡
        mean_scores = [analysis['quality_metrics'][t]['mean_score'] for t in temperatures]
        score_stds = [analysis['quality_metrics'][t]['score_std'] for t in temperatures]
        
        axes[0, 1].errorbar(temperatures, mean_scores, yerr=score_stds, 
                           marker='o', capsize=5, color='red')
        axes[0, 1].set_title('æ¸©åº¦ vs ç”Ÿæˆè´¨é‡')
        axes[0, 1].set_xlabel('æ¸©åº¦')
        axes[0, 1].set_ylabel('å¹³å‡åˆ†æ•°')
        axes[0, 1].grid(True, alpha=0.3)
        
        # å¤šæ ·æ€§-è´¨é‡æƒè¡¡
        axes[1, 0].scatter(diversities, mean_scores, s=100, alpha=0.7)
        
        # æ·»åŠ æ¸©åº¦æ ‡ç­¾
        for i, temp in enumerate(temperatures):
            axes[1, 0].annotate(f'T={temp}', (diversities[i], mean_scores[i]),
                               xytext=(5, 5), textcoords='offset points')
        
        axes[1, 0].set_title('å¤šæ ·æ€§-è´¨é‡æƒè¡¡')
        axes[1, 0].set_xlabel('å¤šæ ·æ€§')
        axes[1, 0].set_ylabel('è´¨é‡')
        axes[1, 0].grid(True, alpha=0.3)
        
        # ç†µåˆ†æ
        sequence_entropies = [analysis['entropy_analysis'][t]['sequence_entropy'] for t in temperatures]
        
        axes[1, 1].plot(temperatures, sequence_entropies, 'g-o', linewidth=2)
        axes[1, 1].set_title('æ¸©åº¦ vs åºåˆ—ç†µ')
        axes[1, 1].set_xlabel('æ¸©åº¦')
        axes[1, 1].set_ylabel('åºåˆ—ç†µ')
        axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()

# ç»å…¸è§£ç ç®—æ³•ç»¼åˆæ¯”è¾ƒ
class DecodingComparator:
    """è§£ç ç®—æ³•æ¯”è¾ƒå™¨"""
    
    def __init__(self):
        self.comparison_results = {}
    
    def comprehensive_comparison(self, model, test_prompts: List[str]) -> Dict:
        """ç»¼åˆæ¯”è¾ƒä¸åŒè§£ç ç®—æ³•"""
        
        print("=== è§£ç ç®—æ³•ç»¼åˆæ¯”è¾ƒ ===")
        
        # åˆ›å»ºä¸åŒçš„è§£ç å™¨
        decoders = {
            'greedy': GreedyDecoder(vocab_size=1000, max_length=30),
            'beam_search_2': BeamSearchDecoder(vocab_size=1000, max_length=30, beam_size=2),
            'beam_search_5': BeamSearchDecoder(vocab_size=1000, max_length=30, beam_size=5),
            'sampling_0.8': RandomSamplingDecoder(vocab_size=1000, max_length=30, temperature=0.8),
            'sampling_1.2': RandomSamplingDecoder(vocab_size=1000, max_length=30, temperature=1.2)
        }
        
        comparison_results = {}
        
        for decoder_name, decoder in decoders.items():
            print(f"æµ‹è¯•è§£ç å™¨: {decoder_name}")
            
            decoder_results = []
            for prompt in test_prompts:
                result = decoder.decode(model, prompt)
                decoder_results.append(result)
            
            # åˆ†æè¯¥è§£ç å™¨çš„ç‰¹æ€§
            analysis = self._analyze_decoder_performance(decoder_results)
            comparison_results[decoder_name] = analysis
        
        # ç»¼åˆæ¯”è¾ƒåˆ†æ
        comparative_analysis = self._comparative_analysis(comparison_results)
        
        # å¯è§†åŒ–æ¯”è¾ƒç»“æœ
        self._visualize_comparison(comparison_results, comparative_analysis)
        
        return {
            'individual_results': comparison_results,
            'comparative_analysis': comparative_analysis
        }
    
    def _analyze_decoder_performance(self, results: List[DecodingResult]) -> Dict:
        """åˆ†æå•ä¸ªè§£ç å™¨çš„æ€§èƒ½"""
        
        scores = [r.score for r in results]
        times = [r.decoding_time for r in results]
        lengths = [len(r.sequence) for r in results]
        log_probs = [r.log_probability for r in results]
        
        return {
            'quality': {
                'mean_score': np.mean(scores),
                'score_std': np.std(scores),
                'mean_log_prob': np.mean(log_probs)
            },
            'efficiency': {
                'mean_time': np.mean(times),
                'time_std': np.std(times),
                'time_per_token': np.mean([t/l for t, l in zip(times, lengths) if l > 0])
            },
            'diversity': {
                'length_variance': np.var(lengths),
                'mean_length': np.mean(lengths)
            }
        }
    
    def _comparative_analysis(self, results: Dict) -> Dict:
        """æ¯”è¾ƒåˆ†æ"""
        
        decoder_names = list(results.keys())
        
        # æ‰¾å‡ºå„é¡¹æŒ‡æ ‡çš„æœ€ä½³è§£ç å™¨
        best_quality = max(decoder_names, 
                          key=lambda x: results[x]['quality']['mean_score'])
        best_efficiency = min(decoder_names, 
                             key=lambda x: results[x]['efficiency']['mean_time'])
        most_diverse = max(decoder_names,
                          key=lambda x: results[x]['diversity']['length_variance'])
        
        # è®¡ç®—å¸•ç´¯æ‰˜å‰æ²¿ï¼ˆè´¨é‡vsæ•ˆç‡ï¼‰
        pareto_frontier = self._compute_pareto_frontier(results)
        
        return {
            'best_quality': best_quality,
            'best_efficiency': best_efficiency,
            'most_diverse': most_diverse,
            'pareto_frontier': pareto_frontier,
            'trade_off_analysis': self._analyze_trade_offs(results)
        }
    
    def _compute_pareto_frontier(self, results: Dict) -> List[str]:
        """è®¡ç®—å¸•ç´¯æ‰˜å‰æ²¿"""
        
        # æå–è´¨é‡å’Œæ•ˆç‡æ•°æ®
        points = []
        for name, data in results.items():
            quality = data['quality']['mean_score']
            efficiency = 1.0 / data['efficiency']['mean_time']  # æ•ˆç‡ = 1/æ—¶é—´
            points.append((name, quality, efficiency))
        
        # æ‰¾å‡ºå¸•ç´¯æ‰˜æœ€ä¼˜ç‚¹
        pareto_optimal = []
        
        for i, (name1, q1, e1) in enumerate(points):
            is_dominated = False
            
            for j, (name2, q2, e2) in enumerate(points):
                if i != j and q2 >= q1 and e2 >= e1 and (q2 > q1 or e2 > e1):
                    is_dominated = True
                    break
            
            if not is_dominated:
                pareto_optimal.append(name1)
        
        return pareto_optimal
    
    def _analyze_trade_offs(self, results: Dict) -> Dict:
        """åˆ†ææƒè¡¡å…³ç³»"""
        
        qualities = [data['quality']['mean_score'] for data in results.values()]
        times = [data['efficiency']['mean_time'] for data in results.values()]
        diversities = [data['diversity']['length_variance'] for data in results.values()]
        
        # è®¡ç®—ç›¸å…³ç³»æ•°
        quality_time_corr = np.corrcoef(qualities, times)[0, 1] if len(qualities) > 1 else 0
        quality_diversity_corr = np.corrcoef(qualities, diversities)[0, 1] if len(qualities) > 1 else 0
        
        return {
            'quality_efficiency_correlation': quality_time_corr,
            'quality_diversity_correlation': quality_diversity_corr,
            'efficiency_range': (min(times), max(times)),
            'quality_range': (min(qualities), max(qualities))
        }
    
    def _visualize_comparison(self, results: Dict, comparative: Dict):
        """å¯è§†åŒ–æ¯”è¾ƒç»“æœ"""
        
        decoder_names = list(results.keys())
        n_decoders = len(decoder_names)
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # è´¨é‡æ¯”è¾ƒ
        qualities = [results[name]['quality']['mean_score'] for name in decoder_names]
        quality_stds = [results[name]['quality']['score_std'] for name in decoder_names]
        
        bars1 = axes[0, 0].bar(range(n_decoders), qualities, yerr=quality_stds, 
                              alpha=0.7, capsize=5)
        axes[0, 0].set_title('ç”Ÿæˆè´¨é‡æ¯”è¾ƒ')
        axes[0, 0].set_xlabel('è§£ç å™¨')
        axes[0, 0].set_ylabel('å¹³å‡åˆ†æ•°')
        axes[0, 0].set_xticks(range(n_decoders))
        axes[0, 0].set_xticklabels(decoder_names, rotation=45)
        
        # é«˜äº®æœ€ä½³è´¨é‡
        best_quality_idx = decoder_names.index(comparative['best_quality'])
        bars1[best_quality_idx].set_color('gold')
        
        # æ•ˆç‡æ¯”è¾ƒ
        times = [results[name]['efficiency']['mean_time'] for name in decoder_names]
        
        bars2 = axes[0, 1].bar(range(n_decoders), times, alpha=0.7, color='orange')
        axes[0, 1].set_title('è§£ç æ•ˆç‡æ¯”è¾ƒ')
        axes[0, 1].set_xlabel('è§£ç å™¨')
        axes[0, 1].set_ylabel('å¹³å‡æ—¶é—´ (ç§’)')
        axes[0, 1].set_xticks(range(n_decoders))
        axes[0, 1].set_xticklabels(decoder_names, rotation=45)
        
        # é«˜äº®æœ€ä½³æ•ˆç‡
        best_efficiency_idx = decoder_names.index(comparative['best_efficiency'])
        bars2[best_efficiency_idx].set_color('lightgreen')
        
        # è´¨é‡-æ•ˆç‡æ•£ç‚¹å›¾
        efficiencies = [1.0/t for t in times]  # æ•ˆç‡ = 1/æ—¶é—´
        
        scatter = axes[1, 0].scatter(qualities, efficiencies, s=100, alpha=0.7)
        
        # æ·»åŠ è§£ç å™¨æ ‡ç­¾
        for i, name in enumerate(decoder_names):
            axes[1, 0].annotate(name, (qualities[i], efficiencies[i]),
                               xytext=(5, 5), textcoords='offset points', fontsize=8)
        
        # é«˜äº®å¸•ç´¯æ‰˜å‰æ²¿
        pareto_names = comparative['pareto_frontier']
        for name in pareto_names:
            idx = decoder_names.index(name)
            axes[1, 0].scatter(qualities[idx], efficiencies[idx], 
                              s=150, c='red', marker='*', alpha=0.8)
        
        axes[1, 0].set_title('è´¨é‡-æ•ˆç‡æƒè¡¡ (çº¢æ˜Ÿ=å¸•ç´¯æ‰˜æœ€ä¼˜)')
        axes[1, 0].set_xlabel('è´¨é‡åˆ†æ•°')
        axes[1, 0].set_ylabel('æ•ˆç‡ (1/æ—¶é—´)')
        axes[1, 0].grid(True, alpha=0.3)
        
        # å¤šæ ·æ€§æ¯”è¾ƒ
        diversities = [results[name]['diversity']['length_variance'] for name in decoder_names]
        
        bars3 = axes[1, 1].bar(range(n_decoders), diversities, alpha=0.7, color='purple')
        axes[1, 1].set_title('ç”Ÿæˆå¤šæ ·æ€§æ¯”è¾ƒ')
        axes[1, 1].set_xlabel('è§£ç å™¨')
        axes[1, 1].set_ylabel('é•¿åº¦æ–¹å·®')
        axes[1, 1].set_xticks(range(n_decoders))
        axes[1, 1].set_xticklabels(decoder_names, rotation=45)
        
        # é«˜äº®æœ€å¤šæ ·åŒ–
        most_diverse_idx = decoder_names.index(comparative['most_diverse'])
        bars3[most_diverse_idx].set_color('violet')
        
        plt.tight_layout()
        plt.show()

# ç»¼åˆæ¼”ç¤ºï¼šç»å…¸è§£ç ç®—æ³•æ·±åº¦è§£æ
def demonstrate_classical_decoding():
    """æ¼”ç¤ºç»å…¸è§£ç ç®—æ³•"""
    
    print("="*60)
    print("ç»å…¸è§£ç ç®—æ³•æ·±åº¦è§£æ - ç»¼åˆæ¼”ç¤º")
    print("="*60)
    
    # æ¨¡æ‹Ÿæ¨¡å‹ï¼ˆç®€åŒ–ï¼‰
    class DummyModel:
        pass
    
    model = DummyModel()
    
    # æµ‹è¯•æç¤º
    test_prompts = [
        "What is artificial intelligence?",
        "Explain machine learning.",
        "How do neural networks work?",
        "Describe deep learning.",
        "What are transformers?"
    ]
    
    print(f"\nä½¿ç”¨ {len(test_prompts)} ä¸ªæµ‹è¯•æç¤º")
    
    # 1. è´ªå¿ƒè§£ç åˆ†æ
    print("\n1. è´ªå¿ƒè§£ç æœ€ä¼˜æ€§åˆ†æ")
    
    greedy_decoder = GreedyDecoder(vocab_size=1000, max_length=25)
    optimality_results = greedy_decoder.analyze_optimality_gap(model, test_prompts[:3])
    
    avg_local_score = np.mean(optimality_results['local_scores'])
    print(f"å¹³å‡å±€éƒ¨æœ€ä¼˜æ€§åˆ†æ•°: {avg_local_score:.3f}")
    
    # 2. Beam SearchåŠ¨æ€åˆ†æ
    print("\n2. Beam SearchåŠ¨æ€ç‰¹æ€§åˆ†æ")
    
    beam_decoder = BeamSearchDecoder(vocab_size=1000, max_length=25, beam_size=4)
    beam_dynamics = beam_decoder.analyze_beam_dynamics(model, test_prompts[:3], [1, 2, 4, 8])
    
    best_beam_size = beam_dynamics['convergence_analysis']['diminishing_returns_point']
    print(f"æ¨èbeam size: {best_beam_size}")
    
    # 3. éšæœºé‡‡æ ·æ¸©åº¦æ•ˆæœåˆ†æ
    print("\n3. éšæœºé‡‡æ ·æ¸©åº¦æ•ˆæœåˆ†æ")
    
    sampling_decoder = RandomSamplingDecoder(vocab_size=1000, max_length=25)
    temp_effects = sampling_decoder.analyze_temperature_effects(
        model, test_prompts[:2], [0.5, 0.8, 1.0, 1.2, 1.5], num_samples=5
    )
    
    # æ‰¾å‡ºæœ€ä½³æ¸©åº¦ï¼ˆè´¨é‡-å¤šæ ·æ€§å¹³è¡¡ï¼‰
    temps = list(temp_effects['diversity_metrics'].keys())
    diversity_scores = list(temp_effects['diversity_metrics'].values())
    quality_scores = [temp_effects['quality_metrics'][t]['mean_score'] for t in temps]
    
    # è®¡ç®—å¹³è¡¡åˆ†æ•°
    balance_scores = [0.6 * q + 0.4 * d for q, d in zip(quality_scores, diversity_scores)]
    best_temp_idx = np.argmax(balance_scores)
    best_temp = temps[best_temp_idx]
    
    print(f"æ¨èæ¸©åº¦: {best_temp} (å¹³è¡¡åˆ†æ•°: {balance_scores[best_temp_idx]:.3f})")
    
    # 4. ç»¼åˆè§£ç ç®—æ³•æ¯”è¾ƒ
    print("\n4. è§£ç ç®—æ³•ç»¼åˆæ¯”è¾ƒ")
    
    comparator = DecodingComparator()
    comparison_results = comparator.comprehensive_comparison(model, test_prompts)
    
    comparative = comparison_results['comparative_analysis']
    print(f"æœ€ä½³è´¨é‡: {comparative['best_quality']}")
    print(f"æœ€ä½³æ•ˆç‡: {comparative['best_efficiency']}")
    print(f"æœ€å¤šæ ·åŒ–: {comparative['most_diverse']}")
    print(f"å¸•ç´¯æ‰˜æœ€ä¼˜: {', '.join(comparative['pareto_frontier'])}")
    
    # 5. ç®—æ³•å¤æ‚åº¦æ€»ç»“
    print(f"\n5. ç®—æ³•å¤æ‚åº¦æ€»ç»“")
    
    complexity_summary = {
        "è´ªå¿ƒè§£ç ": {
            "æ—¶é—´å¤æ‚åº¦": "O(T Ã— V)",
            "ç©ºé—´å¤æ‚åº¦": "O(1)",
            "å¹¶è¡Œåº¦": "ä½",
            "è´¨é‡": "å±€éƒ¨æœ€ä¼˜"
        },
        "Beam Search": {
            "æ—¶é—´å¤æ‚åº¦": "O(T Ã— V Ã— B)",
            "ç©ºé—´å¤æ‚åº¦": "O(B Ã— T)",
            "å¹¶è¡Œåº¦": "ä¸­",
            "è´¨é‡": "è¿‘ä¼¼å…¨å±€æœ€ä¼˜"
        },
        "éšæœºé‡‡æ ·": {
            "æ—¶é—´å¤æ‚åº¦": "O(T Ã— V)",
            "ç©ºé—´å¤æ‚åº¦": "O(1)",
            "å¹¶è¡Œåº¦": "é«˜",
            "è´¨é‡": "éšæœºæ€§è¾ƒé«˜"
        }
    }
    
    for algorithm, properties in complexity_summary.items():
        print(f"\n{algorithm}:")
        for prop, value in properties.items():
            print(f"  {prop}: {value}")
    
    # 6. å®è·µå»ºè®®
    print(f"\n6. å®è·µå»ºè®®")
    
    recommendations = [
        "ğŸ¯ å¯¹è¯ç³»ç»Ÿ: ä½¿ç”¨æ¸©åº¦0.7-0.9çš„éšæœºé‡‡æ ·å¢åŠ è‡ªç„¶åº¦",
        "ğŸ“ æ‘˜è¦ç”Ÿæˆ: ä½¿ç”¨beam search (size=3-5) ç¡®ä¿è¿è´¯æ€§", 
        "ğŸ” é—®ç­”ç³»ç»Ÿ: ä½¿ç”¨è´ªå¿ƒè§£ç è·å¾—ç¡®å®šæ€§ç­”æ¡ˆ",
        "ğŸ¨ åˆ›æ„å†™ä½œ: ä½¿ç”¨è¾ƒé«˜æ¸©åº¦(1.0-1.5)çš„é‡‡æ ·å¢åŠ åˆ›é€ æ€§",
        "âš¡ å®æ—¶åº”ç”¨: ä¼˜å…ˆé€‰æ‹©è´ªå¿ƒè§£ç ä¿è¯å“åº”é€Ÿåº¦",
        "ğŸ“Š æ‰¹é‡å¤„ç†: ä½¿ç”¨beam searchå¹³è¡¡è´¨é‡ä¸æ•ˆç‡"
    ]
    
    for recommendation in recommendations:
        print(f"  {recommendation}")
    
    print(f"\n=== ç»å…¸è§£ç ç®—æ³•åˆ†æå®Œæˆ ===")
    print(f"æ¯ç§ç®—æ³•éƒ½æœ‰å…¶é€‚ç”¨åœºæ™¯ï¼Œå…³é”®æ˜¯æ ¹æ®ä»»åŠ¡éœ€æ±‚é€‰æ‹©åˆé€‚çš„ç­–ç•¥")

# è¿è¡Œç»å…¸è§£ç ç®—æ³•æ¼”ç¤º
demonstrate_classical_decoding()
```

è¿™æ ·æˆ‘å°±å®Œæˆäº†ç¬¬06ç« ç¬¬02èŠ‚"ç»å…¸è§£ç ç®—æ³•æ·±åº¦è§£æ"çš„å®Œæ•´å†…å®¹ã€‚è¿™ä¸€èŠ‚æ·±å…¥åˆ†æäº†ï¼š

1. **è´ªå¿ƒè§£ç çš„æ•°å­¦æ€§è´¨**ï¼šå±€éƒ¨æœ€ä¼˜æ€§è¯æ˜ã€å…¨å±€æ¬¡ä¼˜æ€§åˆ†æã€æœ€ä¼˜æ€§å·®è·é‡åŒ–
2. **Beam SearchåŠ¨æ€è§„åˆ’åŸç†**ï¼šæœç´¢ç­–ç•¥ã€é•¿åº¦æ ‡å‡†åŒ–ã€beam sizeæ•ˆåº”åˆ†æ
3. **éšæœºé‡‡æ ·æ–¹æ³•**ï¼šæ¸©åº¦ç¼©æ”¾çš„æ•°å­¦åŸç†ã€å¤šæ ·æ€§-è´¨é‡æƒè¡¡ã€é‡‡æ ·å‚æ•°ä¼˜åŒ–
4. **ç®—æ³•å¤æ‚åº¦åˆ†æ**ï¼šæ—¶é—´ç©ºé—´å¤æ‚åº¦ã€å¹¶è¡ŒåŒ–ç­–ç•¥ã€æ•ˆç‡æ¯”è¾ƒ
5. **ç»¼åˆæ€§èƒ½æ¯”è¾ƒ**ï¼šå¸•ç´¯æ‰˜å‰æ²¿åˆ†æã€trade-offå…³ç³»ã€å®é™…åº”ç”¨å»ºè®®

æ¯ä¸ªç®—æ³•éƒ½æœ‰å®Œæ•´çš„æ•°å­¦æ¨å¯¼ã€è¯¦ç»†çš„å®ç°ä»£ç å’Œæ·±å…¥çš„æ€§èƒ½åˆ†æï¼Œä¸ºè¯»è€…æä¾›äº†ultra-deepçš„ç†è®ºç†è§£å’Œå®è·µæŒ‡å¯¼ã€‚