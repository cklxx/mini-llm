# A6000 GPU å¿«é€Ÿå¼€å§‹æŒ‡å—

## ğŸ¯ ä¸€é”®å¯åŠ¨ä¼˜åŒ–è®­ç»ƒ

### 1ï¸âƒ£ éªŒè¯ä¼˜åŒ–é…ç½®
```bash
# å¿«é€Ÿæ£€æŸ¥æ‰€æœ‰ä¼˜åŒ–æ˜¯å¦æ­£ç¡®åº”ç”¨
bash scripts/check_optimization.sh
```

### 2ï¸âƒ£ å¼€å§‹è®­ç»ƒ
```bash
# Mediumæ¨¡å‹é¢„è®­ç»ƒ (è‡ªåŠ¨åº”ç”¨æ‰€æœ‰A6000ä¼˜åŒ–)
python3 scripts/train.py --mode pretrain --config medium

# å¦‚æœä½¿ç”¨uvåŒ…ç®¡ç†å™¨
uv run python scripts/train.py --mode pretrain --config medium
```

### 3ï¸âƒ£ ç›‘æ§è®­ç»ƒ
```bash
# ç»ˆç«¯1: ç›‘æ§GPUä½¿ç”¨ç‡
watch -n 1 nvidia-smi

# ç»ˆç«¯2: æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
tail -f logs/training.log
```

## âœ… ä¼˜åŒ–æ£€æŸ¥æ¸…å•

è®­ç»ƒå¼€å§‹æ—¶åº”è¯¥çœ‹åˆ°ï¼š
```
=== MEDIUM æ¨¡å‹é…ç½® ===
è®¾å¤‡: cuda
GPU: NVIDIA RTX A6000 (48.0 GB)
æ‰¹é‡å¤§å°: 32
æ¢¯åº¦ç´¯ç§¯: 4
æœ‰æ•ˆæ‰¹é‡: 128
æ··åˆç²¾åº¦: True
...
å¼€å§‹è®­ç»ƒï¼Œæœ€å¤§æ­¥æ•°: 100000
Batch size: 32, æ¢¯åº¦ç´¯ç§¯: 4, æœ‰æ•ˆbatch: 128
âœ… å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ (FP16)
```

## ğŸ“Š é¢„æœŸæ€§èƒ½æŒ‡æ ‡

### GPUç›‘æ§ (nvidia-smi)
- **GPUåˆ©ç”¨ç‡**: 70-90% âœ…
- **æ˜¾å­˜ä½¿ç”¨**: 20-25GB (FP16æ¨¡å¼) âœ…
- **æ¸©åº¦**: æ ¹æ®æ•£çƒ­æƒ…å†µ

### è®­ç»ƒé€Ÿåº¦
- **æ¯æ­¥æ—¶é—´**: æ¯”ä¼˜åŒ–å‰å¿«2-2.5å€ âœ…
- **æ•°æ®åŠ è½½**: æ— æ˜æ˜¾ç­‰å¾… âœ…

## ğŸ”§ å·²åº”ç”¨çš„ä¼˜åŒ–

| ä¼˜åŒ–é¡¹ | é…ç½® | æ•ˆæœ |
|--------|------|------|
| Batch Size | 32 | GPUåˆ©ç”¨ç‡â†‘ |
| æ¢¯åº¦ç´¯ç§¯ | 4æ­¥ | æœ‰æ•ˆbatch=128 |
| Data Workers | 8ä¸ª | å¹¶è¡ŒåŠ è½½ |
| Prefetch | 4æ‰¹/worker | é¢„å–32æ‰¹ |
| æ··åˆç²¾åº¦ | FP16 | æ˜¾å­˜â†“40% |
| Pin Memory | å¯ç”¨ | ä¼ è¾“åŠ é€Ÿ |
| Non-blocking | å¯ç”¨ | å¼‚æ­¥ä¼ è¾“ |

## ğŸ“ ä¼˜åŒ–æ–‡æ¡£

- **è¯¦ç»†æŒ‡å—**: `docs/A6000_OPTIMIZATION_GUIDE.md`
- **ä¼˜åŒ–æ€»ç»“**: `OPTIMIZATION_SUMMARY.md`
- **éªŒè¯è„šæœ¬**: `scripts/verify_optimization.py`
- **å¿«é€Ÿæ£€æŸ¥**: `scripts/check_optimization.sh`

## ğŸ’¡ å¸¸ç”¨å‘½ä»¤

### è®­ç»ƒå‘½ä»¤
```bash
# é¢„è®­ç»ƒ
python3 scripts/train.py --mode pretrain --config medium

# SFTå¾®è°ƒ
python3 scripts/train.py --mode sft --config medium

# ä»checkpointæ¢å¤
python3 scripts/train.py --mode pretrain --config medium --auto-resume

# è‡ªå®šä¹‰å‚æ•°
python3 scripts/train.py --mode pretrain --config medium \
    --batch-size 32 --learning-rate 3e-4 --max-steps 50000
```

### ç›‘æ§å‘½ä»¤
```bash
# GPUå®æ—¶ç›‘æ§
nvidia-smi dmon -s um

# æ˜¾å­˜è¯¦æƒ…
nvidia-smi --query-gpu=memory.used,memory.total --format=csv

# è®­ç»ƒè¿›åº¦
tail -f logs/training.log | grep "Step"
```

## âš™ï¸ è°ƒä¼˜å»ºè®®

### å¦‚æœæ˜¾å­˜ä¸è¶³ (OOM)
```bash
# å‡å°batch size
python3 scripts/train.py --mode pretrain --config medium --batch-size 24
```

### å¦‚æœGPUåˆ©ç”¨ç‡ä»ç„¶ä½
```bash
# å¢åŠ data workers
# ç¼–è¾‘ config/training_config.py
num_workers = 12  # æ”¹ä¸º12
```

### å¦‚æœæƒ³è¦æ›´å¿«è®­ç»ƒ
```bash
# å‡å°åºåˆ—é•¿åº¦
# ç¼–è¾‘ config/training_config.py
max_seq_len = 1024  # ä»2048æ”¹ä¸º1024
```

## ğŸ¯ ä¸‹ä¸€æ­¥

1. **ç›‘æ§é¦–ä¸ªepoch**: ç¡®è®¤GPUåˆ©ç”¨ç‡è¾¾åˆ°70-90%
2. **æ£€æŸ¥æ˜¾å­˜**: ç¡®è®¤åœ¨20-25GBå·¦å³ï¼ˆFP16ï¼‰
3. **è§‚å¯ŸæŸå¤±**: ç¡®è®¤lossæ­£å¸¸ä¸‹é™
4. **é•¿æœŸè®­ç»ƒ**: å¦‚æœä¸€åˆ‡æ­£å¸¸ï¼Œç»§ç»­å®Œæ•´è®­ç»ƒ

## ğŸ“ æ•…éšœæ’æŸ¥

### GPUåˆ©ç”¨ç‡ä»ç„¶ä½ (<50%)
1. æ£€æŸ¥æ•°æ®åŠ è½½: `scripts/check_optimization.sh`
2. å¢åŠ workers: ç¼–è¾‘`config/training_config.py`
3. æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–è¿›ç¨‹å ç”¨GPU

### æ˜¾å­˜æº¢å‡º (OOM)
1. é™ä½batch size: `--batch-size 24`
2. å‡å°åºåˆ—é•¿åº¦: ä¿®æ”¹`max_seq_len`
3. ç¦ç”¨æ··åˆç²¾åº¦: ç¼–è¾‘é…ç½®æ–‡ä»¶

### è®­ç»ƒä¸ç¨³å®š
1. é™ä½å­¦ä¹ ç‡: `--learning-rate 1e-4`
2. æ£€æŸ¥æ•°æ®è´¨é‡
3. æŸ¥çœ‹æ¢¯åº¦normæ˜¯å¦å¼‚å¸¸

---

**å¿«é€Ÿæ”¯æŒ**:
- è¯¦ç»†æ–‡æ¡£: `docs/A6000_OPTIMIZATION_GUIDE.md`
- ä¼˜åŒ–æ€»ç»“: `OPTIMIZATION_SUMMARY.md`
