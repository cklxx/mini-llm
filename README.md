# MiniGPTè®­ç»ƒæ¡†æ¶

<div align="center">

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Mac Optimized](https://img.shields.io/badge/Mac-Optimized-silver.svg)](README_MAC_OPTIMIZED.md)

**å®Œæ•´çš„å¤§è¯­è¨€æ¨¡å‹è®­ç»ƒæ¡†æ¶ï¼Œæ”¯æŒé¢„è®­ç»ƒã€ç›‘ç£å¾®è°ƒ(SFT)ã€DPOå’ŒRLHFå…¨æµç¨‹**

[ğŸ“š æŠ€æœ¯æ‰‹å†Œ](docs/MiniGPTè®­ç»ƒæ·±åº¦è§£æå°å†Œ/) â€¢
[ğŸš€ å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹) â€¢
[ğŸ Macä¼˜åŒ–ç‰ˆ](README_MAC_OPTIMIZED.md) â€¢
[ğŸ“– å¼€å‘ç¬”è®°](CLAUDE.md)

</div>

## âœ¨ é¡¹ç›®ç‰¹è‰²

### ğŸš€ å®Œæ•´è®­ç»ƒæµç¨‹
- **é¢„è®­ç»ƒï¼ˆPretrainï¼‰**: ä»é›¶å¼€å§‹è®­ç»ƒè¯­è¨€æ¨¡å‹
- **ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰**: æŒ‡ä»¤è·Ÿéšå’Œå¯¹è¯èƒ½åŠ›è®­ç»ƒ
- **DPOè®­ç»ƒ**: ç›´æ¥åå¥½ä¼˜åŒ–ï¼Œæ— éœ€å¥–åŠ±æ¨¡å‹
- **RLHFæµç¨‹**: åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ 

### ğŸ Macä¼˜åŒ–æ”¯æŒ
- **èµ„æºè‡ªé€‚åº”**: è‡ªåŠ¨æ£€æµ‹Macç¡¬ä»¶é…ç½®
- **å†…å­˜ä¼˜åŒ–**: è¶…å°æ¨¡å‹é…ç½®ï¼Œé¿å…ç³»ç»Ÿå¡æ­»
- **å¿«é€ŸéªŒè¯**: 200æ¡æ•°æ®10åˆ†é’ŸéªŒè¯æ™ºèƒ½æ•ˆæœ
- **ä¸€é”®å¯åŠ¨**: ç®€åŒ–çš„Macä¼˜åŒ–è®­ç»ƒè„šæœ¬

### ğŸ—ï¸ æ¨¡å—åŒ–æ¶æ„
- **å¯æ‰©å±•è®¾è®¡**: æ¸…æ™°çš„æ¨¡å—åˆ’åˆ†ï¼Œæ˜“äºæ‰©å±•
- **é…ç½®é©±åŠ¨**: çµæ´»çš„é…ç½®ç³»ç»Ÿæ”¯æŒå¤šç§è®­ç»ƒåœºæ™¯
- **å®Œæ•´å·¥å…·é“¾**: æ•°æ®å¤„ç†ã€è®­ç»ƒã€æ¨ç†ã€è¯„ä¼°ä¸€ä½“åŒ–

### ğŸ“š æ·±åº¦æŠ€æœ¯æ‰‹å†Œ
- **å®Œæ•´çŸ¥è¯†ä½“ç³»**: 8ç« æŠ€æœ¯æ‰‹å†Œè¦†ç›–ä»æ•°å­¦åŸºç¡€åˆ°å·¥ç¨‹å®è·µ
- **ç†è®ºä¸å®è·µç»“åˆ**: æ¯ç« åŒ…å«æ•°å­¦æ¨å¯¼ã€ä»£ç å®ç°å’Œåº”ç”¨æ¡ˆä¾‹
- **ç³»ç»Ÿæ€§å­¦ä¹ è·¯å¾„**: ä»åŸºç¡€æ¦‚å¿µåˆ°é«˜çº§æŠ€æœ¯çš„è¿›é˜¶è·¯çº¿
- **ç”Ÿäº§çº§æŒ‡å¯¼**: åŸºäºå®é™…é¡¹ç›®ç»éªŒçš„æœ€ä½³å®è·µ

## ğŸ¯ é€‚ç”¨åœºæ™¯

- **å­¦ä¹ ç ”ç©¶**: æ·±å…¥ç†è§£å¤§æ¨¡å‹è®­ç»ƒåŸç†
- **å¿«é€ŸåŸå‹**: éªŒè¯æƒ³æ³•å’Œç®—æ³•æ•ˆæœ
- **æ•™å­¦æ¼”ç¤º**: å®Œæ•´çš„è®­ç»ƒæµç¨‹å±•ç¤º
- **Macå¼€å‘**: åœ¨Macè®¾å¤‡ä¸Šè¿›è¡Œæ¨¡å‹è®­ç»ƒ

## ğŸ“š æ ¸å¿ƒæŠ€æœ¯æ‰‹å†Œ

> **æ·±åº¦è§£ææ‰‹å†Œæ˜¯æœ¬é¡¹ç›®çš„æ ¸å¿ƒæ–‡æ¡£ï¼Œä»æ•°å­¦åŸç†åˆ°å·¥ç¨‹å®è·µï¼Œå…¨é¢è§£æå¤§æ¨¡å‹è®­ç»ƒæŠ€æœ¯**

### ğŸ§® [ç¬¬01ç«  - æ•°å­¦åŸºç¡€ä¸ç†è®ºæ¡†æ¶](docs/MiniGPTè®­ç»ƒæ·±åº¦è§£æå°å†Œ/ç¬¬01ç« -æ•°å­¦åŸºç¡€ä¸ç†è®ºæ¡†æ¶/)
- **ä¿¡æ¯è®ºä¸æ¦‚ç‡åŸºç¡€**: è¯­è¨€å»ºæ¨¡çš„æ•°å­¦åŸºç¡€
- **çº¿æ€§ä»£æ•°ä¸çŸ©é˜µè¿ç®—**: Transformerçš„æ ¸å¿ƒæ•°å­¦å·¥å…·
- **ä¼˜åŒ–ç†è®ºä¸æ¢¯åº¦ä¸‹é™**: è®­ç»ƒç®—æ³•çš„ç†è®ºåŸºç¡€
- **ç»Ÿè®¡å­¦ä¹ ç†è®º**: æ³›åŒ–èƒ½åŠ›çš„ç†è®ºä¿è¯

### ğŸ—ï¸ [ç¬¬02ç«  - Transformeræ ¸å¿ƒæ¶æ„](docs/MiniGPTè®­ç»ƒæ·±åº¦è§£æå°å†Œ/ç¬¬02ç« -Transformeræ ¸å¿ƒæ¶æ„/)
- **æ³¨æ„åŠ›æœºåˆ¶æ•°å­¦åŸç†**: è‡ªæ³¨æ„åŠ›çš„å®Œæ•´æ¨å¯¼
- **å¤šå¤´æ³¨æ„åŠ›å­ç©ºé—´åˆ†è§£**: å¹¶è¡Œå¤„ç†çš„æ•°å­¦åŸç†
- **ä½ç½®ç¼–ç å‡ ä½•å­¦**: åºåˆ—ä½ç½®çš„å·§å¦™ç¼–ç 
- **æ®‹å·®è¿æ¥ä¸å±‚å½’ä¸€åŒ–**: æ·±åº¦ç½‘ç»œè®­ç»ƒç¨³å®šæ€§

### ğŸ“– [ç¬¬03ç«  - é¢„è®­ç»ƒç†è®ºä¸å®ç°](docs/MiniGPTè®­ç»ƒæ·±åº¦è§£æå°å†Œ/ç¬¬03ç« -é¢„è®­ç»ƒç†è®ºä¸å®ç°/)
- **è¯­è¨€å»ºæ¨¡æ¦‚ç‡åŸºç¡€**: è‡ªå›å½’æ¨¡å‹çš„æ•°å­¦åŸºç¡€
- **è‡ªå›å½’å»ºæ¨¡ä¸å› æœæ©ç **: å¹¶è¡Œè®­ç»ƒçš„æŠ€æœ¯å®ç°
- **åˆ†è¯ç­–ç•¥ä¸ä¿¡æ¯å‹ç¼©**: BPEç®—æ³•çš„æ·±åº¦åˆ†æ
- **ä¼˜åŒ–ç®—æ³•æ·±åº¦è§£æ**: AdamWä¸å­¦ä¹ ç‡è°ƒåº¦

### ğŸ¯ [ç¬¬04ç«  - ç›‘ç£å¾®è°ƒæ·±åº¦è§£æ](docs/MiniGPTè®­ç»ƒæ·±åº¦è§£æå°å†Œ/ç¬¬04ç« -ç›‘ç£å¾®è°ƒæ·±åº¦è§£æ/)
- **ä»»åŠ¡é€‚åº”ç†è®ºæ¡†æ¶**: ä»é¢„è®­ç»ƒåˆ°ä»»åŠ¡ç‰¹åŒ–
- **æŒ‡ä»¤è·Ÿéšä¸å¯¹è¯å»ºæ¨¡**: äººæœºäº¤äº’çš„æ•°å­¦å»ºæ¨¡
- **æŸå¤±å‡½æ•°è®¾è®¡ä¸ä¼˜åŒ–**: SFTè®­ç»ƒçš„æ ¸å¿ƒæŠ€æœ¯
- **è¯„ä¼°æŒ‡æ ‡ä¸æ•ˆæœåˆ†æ**: å¾®è°ƒæ•ˆæœçš„é‡åŒ–è¯„ä¼°

### ğŸ”„ [ç¬¬05ç«  - å¼ºåŒ–å­¦ä¹ äººç±»åé¦ˆ](docs/MiniGPTè®­ç»ƒæ·±åº¦è§£æå°å†Œ/ç¬¬05ç« -å¼ºåŒ–å­¦ä¹ äººç±»åé¦ˆ/)
- **RLHFç†è®ºä¸æ•°å­¦åŸºç¡€**: äººç±»åå¥½å­¦ä¹ çš„ç†è®º
- **å¥–åŠ±å»ºæ¨¡ä¸åå¥½å­¦ä¹ **: äººç±»åé¦ˆçš„æ•°å­¦å»ºæ¨¡
- **PPOç®—æ³•è¯­è¨€æ¨¡å‹å¾®è°ƒ**: ç­–ç•¥ä¼˜åŒ–çš„å…·ä½“å®ç°
- **DPOä¸æ›¿ä»£RLHFæ–¹æ³•**: ç›´æ¥åå¥½ä¼˜åŒ–æŠ€æœ¯

### ğŸ² [ç¬¬06ç«  - ç”Ÿæˆä¸è§£ç ç­–ç•¥](docs/MiniGPTè®­ç»ƒæ·±åº¦è§£æå°å†Œ/ç¬¬06ç« -ç”Ÿæˆä¸è§£ç ç­–ç•¥/)
- **è‡ªå›å½’ç”Ÿæˆæ•°å­¦åŸç†**: åºåˆ—ç”Ÿæˆçš„æ¦‚ç‡å»ºæ¨¡
- **ç»å…¸è§£ç ç®—æ³•æ·±åº¦è§£æ**: Greedyã€Beam Searchç­‰ç®—æ³•
- **é«˜çº§é‡‡æ ·ç­–ç•¥ä¸æ§åˆ¶**: Top-kã€Top-pã€Temperatureé‡‡æ ·
- **ç”Ÿæˆè´¨é‡æ§åˆ¶ä¸ä¼˜åŒ–**: ç”Ÿæˆæ–‡æœ¬çš„è´¨é‡è¯„ä¼°ä¸æ§åˆ¶

### ğŸ“Š [ç¬¬07ç«  - è¯„ä¼°ä¸åˆ†ææ–¹æ³•](docs/MiniGPTè®­ç»ƒæ·±åº¦è§£æå°å†Œ/ç¬¬07ç« -è¯„ä¼°ä¸åˆ†ææ–¹æ³•/)
- **è‡ªåŠ¨è¯„ä¼°æŒ‡æ ‡æ·±åº¦è§£æ**: BLEUã€ROUGEã€å›°æƒ‘åº¦ç­‰æŒ‡æ ‡
- **äººç±»è¯„ä¼°æ¡†æ¶è®¾è®¡**: ä¸»è§‚è¯„ä¼°çš„æ ‡å‡†åŒ–æ–¹æ³•
- **é”™è¯¯åˆ†æä¸è¯Šæ–­æŠ€æœ¯**: æ¨¡å‹å¤±è´¥æ¡ˆä¾‹çš„ç³»ç»Ÿåˆ†æ
- **åŸºå‡†æµ‹è¯•ä¸æ¯”è¾ƒåˆ†æ**: æ ‡å‡†æ•°æ®é›†ä¸Šçš„æ€§èƒ½å¯¹æ¯”

### ğŸ”§ [ç¬¬08ç«  - å·¥ç¨‹å®è·µä¸ä¼˜åŒ–](docs/MiniGPTè®­ç»ƒæ·±åº¦è§£æå°å†Œ/ç¬¬08ç« -å·¥ç¨‹å®è·µä¸ä¼˜åŒ–/)
- **è®­ç»ƒåŸºç¡€è®¾æ–½ä¸å¯æ‰©å±•æ€§**: åˆ†å¸ƒå¼è®­ç»ƒçš„å·¥ç¨‹å®ç°
- **æ€§èƒ½ä¼˜åŒ–æŠ€æœ¯**: å†…å­˜ä¼˜åŒ–ã€è®¡ç®—åŠ é€Ÿã€æ··åˆç²¾åº¦
- **éƒ¨ç½²ä¸ç”Ÿäº§ç³»ç»Ÿ**: æ¨¡å‹æœåŠ¡åŒ–çš„å®Œæ•´æ–¹æ¡ˆ
- **ç›‘æ§ä¸ç»´æŠ¤**: ç”Ÿäº§ç¯å¢ƒçš„æ¨¡å‹ç›‘æ§ä¸æ›´æ–°

> **ğŸ’¡ æç¤º**: æŠ€æœ¯æ‰‹å†Œé‡‡ç”¨ç†è®ºä¸å®è·µç›¸ç»“åˆçš„æ–¹å¼ï¼Œæ¯ç« éƒ½åŒ…å«è¯¦ç»†çš„æ•°å­¦æ¨å¯¼ã€ä»£ç å®ç°å’Œå®é™…åº”ç”¨æ¡ˆä¾‹ã€‚å¼ºçƒˆå»ºè®®æŒ‰ç« èŠ‚é¡ºåºå­¦ä¹ ï¼Œå»ºç«‹å®Œæ•´çš„çŸ¥è¯†ä½“ç³»ã€‚

## ğŸ“‹ ç›®å½•

- [æ ¸å¿ƒæŠ€æœ¯æ‰‹å†Œ](#-æ ¸å¿ƒæŠ€æœ¯æ‰‹å†Œ)
- [å®‰è£…é…ç½®](#-å®‰è£…é…ç½®)
- [å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹)
- [è®­ç»ƒæµç¨‹](#-è®­ç»ƒæµç¨‹)
- [é¡¹ç›®æ¶æ„](#-é¡¹ç›®æ¶æ„)
- [é…ç½®è¯´æ˜](#-é…ç½®è¯´æ˜)
- [é«˜çº§åŠŸèƒ½](#-é«˜çº§åŠŸèƒ½)
- [æ–‡æ¡£èµ„æº](#-æ–‡æ¡£èµ„æº)
- [è´¡çŒ®æŒ‡å—](#-è´¡çŒ®æŒ‡å—)

## ğŸ”§ å®‰è£…é…ç½®

### ç¯å¢ƒè¦æ±‚

- **Python**: 3.11+
- **PyTorch**: 2.0+
- **ç³»ç»Ÿ**: macOS/Linux/Windows
- **å†…å­˜**: æœ€ä½4GBï¼Œæ¨è8GB+

### æ–¹å¼ä¸€ï¼šä½¿ç”¨UVï¼ˆæ¨èï¼‰

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/your-repo/minigpt-training.git
cd minigpt-training

# ä¸€é”®è®¾ç½®UVç¯å¢ƒ
./setup_uv.sh

# æ¿€æ´»ç¯å¢ƒ
source .venv/bin/activate
```

### æ–¹å¼äºŒï¼šä¼ ç»Ÿpipå®‰è£…

```bash
# å®‰è£…ä¾èµ–
pip install torch numpy matplotlib tqdm psutil

# æˆ–ä½¿ç”¨pyproject.toml
pip install -e .
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### Macç”¨æˆ·ï¼ˆæ¨èï¼‰

```bash
# ä¸€é”®å¯åŠ¨Macä¼˜åŒ–è®­ç»ƒ
python quick_start.py
```

è¿™å°†æ‰“å¼€äº¤äº’å¼èœå•ï¼Œæ”¯æŒï¼š
- **Tinyæ¨¡å‹**: 13Kå‚æ•°ï¼Œ10-20åˆ†é’Ÿè®­ç»ƒ
- **Smallæ¨¡å‹**: 66Kå‚æ•°ï¼Œ30-45åˆ†é’Ÿè®­ç»ƒ
- **é…ç½®æµ‹è¯•**: éªŒè¯ç¯å¢ƒå’Œé…ç½®

### æ ‡å‡†è®­ç»ƒæµç¨‹

```bash
# 1. é¢„è®­ç»ƒ
python scripts/train.py --stage pretrain --config config/training_config.py

# 2. ç›‘ç£å¾®è°ƒ
python scripts/train.py --stage sft --config config/training_config.py

# 3. DPOè®­ç»ƒ
python scripts/train.py --stage dpo --config config/training_config.py

# 4. æ¨ç†æµ‹è¯•
python scripts/generate.py --model checkpoints/sft_model.pt
```

### ä½¿ç”¨ä¼˜åŒ–é…ç½®

```bash
# ä½¿ç”¨Macä¼˜åŒ–é…ç½®
python scripts/train_optimized.py --config tiny

# è‡ªå®šä¹‰èµ„æºé™åˆ¶
python scripts/train_optimized.py --config small --max-cpu 60 --max-memory 70
```

## ğŸ”„ è®­ç»ƒæµç¨‹

### è®­ç»ƒé˜¶æ®µæ¦‚è§ˆ

1. **é¢„è®­ç»ƒï¼ˆPretrainï¼‰**
   - **ç›®æ ‡**: å­¦ä¹ è¯­è¨€åŸºç¡€èƒ½åŠ›
   - **æ•°æ®**: å¤§è§„æ¨¡æ— æ ‡æ³¨æ–‡æœ¬
   - **æŸå¤±**: ä¸‹ä¸€ä¸ªtokené¢„æµ‹

2. **ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰**
   - **ç›®æ ‡**: å­¦ä¹ æŒ‡ä»¤è·Ÿéšèƒ½åŠ›
   - **æ•°æ®**: æŒ‡ä»¤-å›ç­”å¯¹
   - **æŸå¤±**: äº¤å‰ç†µæŸå¤±ï¼ˆä»…å›ç­”éƒ¨åˆ†ï¼‰

3. **DPOè®­ç»ƒ**
   - **ç›®æ ‡**: ä¼˜åŒ–ç”Ÿæˆè´¨é‡å’Œåå¥½å¯¹é½
   - **æ•°æ®**: åå¥½å¯¹æ¯”æ•°æ®
   - **æŸå¤±**: DPOæŸå¤±å‡½æ•°

4. **RLHFè®­ç»ƒ**
   - **ç›®æ ‡**: åŸºäºäººç±»åé¦ˆæŒç»­ä¼˜åŒ–
   - **æ–¹æ³•**: PPOç®—æ³•
   - **ç»„ä»¶**: å¥–åŠ±æ¨¡å‹ã€ä»·å€¼æ¨¡å‹ã€ç­–ç•¥æ¨¡å‹

## ğŸ—ï¸ é¡¹ç›®æ¶æ„

```
minigpt-training/
â”œâ”€â”€ src/                    # æ ¸å¿ƒä»£ç 
â”‚   â”œâ”€â”€ model/             # æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ training/          # è®­ç»ƒé€»è¾‘
â”‚   â”œâ”€â”€ data/              # æ•°æ®å¤„ç†
â”‚   â”œâ”€â”€ tokenizer/         # åˆ†è¯å™¨
â”‚   â”œâ”€â”€ inference/         # æ¨ç†ç”Ÿæˆ
â”‚   â”œâ”€â”€ rl/                # å¼ºåŒ–å­¦ä¹ 
â”‚   â””â”€â”€ utils/             # å·¥å…·å‡½æ•°
â”œâ”€â”€ config/                # é…ç½®æ–‡ä»¶
â”œâ”€â”€ scripts/               # è®­ç»ƒè„šæœ¬
â”œâ”€â”€ data/                  # æ•°æ®é›†
â”œâ”€â”€ docs/                  # æ–‡æ¡£
â”œâ”€â”€ tests/                 # æµ‹è¯•ä»£ç 
â””â”€â”€ checkpoints/           # æ¨¡å‹æ£€æŸ¥ç‚¹
```

### æ ¸å¿ƒæ¨¡å—è¯´æ˜

| æ¨¡å— | åŠŸèƒ½ | ä¸»è¦æ–‡ä»¶ |
|------|------|----------|
| `src.model` | Transformeræ¨¡å‹å®ç° | `transformer.py` |
| `src.training` | è®­ç»ƒæµç¨‹æ§åˆ¶ | `trainer.py` |
| `src.data` | æ•°æ®åŠ è½½å’Œå¤„ç† | `dataset_loader.py` |
| `src.tokenizer` | BPEåˆ†è¯å™¨ | `bpe_tokenizer.py` |
| `src.rl` | å¼ºåŒ–å­¦ä¹ è®­ç»ƒ | `rlhf_pipeline.py` |
| `src.inference` | æ–‡æœ¬ç”Ÿæˆ | `generator.py` |

## âš™ï¸ é…ç½®è¯´æ˜

### æ¨¡å‹é…ç½®

```python
# è¶…å°æ¨¡å‹ï¼ˆMacä¼˜åŒ–ï¼‰
tiny_config = {
    "d_model": 128,
    "n_heads": 2,
    "n_layers": 4,
    "vocab_size": 5000
}

# å°æ¨¡å‹ï¼ˆæ¨èå­¦ä¹ ï¼‰
small_config = {
    "d_model": 512,
    "n_heads": 8,
    "n_layers": 6,
    "vocab_size": 10000
}
```

### è®­ç»ƒé…ç½®

```python
# é¢„è®­ç»ƒé…ç½®
pretrain_config = {
    "learning_rate": 1e-4,
    "batch_size": 32,
    "max_steps": 50000,
    "warmup_steps": 1000
}

# SFTé…ç½®
sft_config = {
    "learning_rate": 5e-5,
    "batch_size": 16,
    "max_epochs": 10,
    "gradient_accumulation_steps": 2
}
```

## ğŸš€ é«˜çº§åŠŸèƒ½

### LoRAå¾®è°ƒ

```python
# å¯ç”¨LoRA
config.sft.use_lora = True
config.sft.lora_rank = 16
config.sft.lora_alpha = 32
```

### æ··åˆç²¾åº¦è®­ç»ƒ

```python
# å¯ç”¨FP16
config.optimization.use_fp16 = True
```

### åˆ†å¸ƒå¼è®­ç»ƒ

```bash
# å¤šGPUè®­ç»ƒ
python -m torch.distributed.launch --nproc_per_node=4 scripts/train.py
```

### è‡ªå®šä¹‰æ•°æ®é›†

```jsonl
# é¢„è®­ç»ƒæ•°æ®æ ¼å¼
{"text": "è¿™æ˜¯ä¸€æ®µç”¨äºé¢„è®­ç»ƒçš„æ–‡æœ¬..."}

# SFTæ•°æ®æ ¼å¼
{"instruction": "é—®é¢˜", "input": "è¾“å…¥", "output": "å›ç­”"}

# DPOæ•°æ®æ ¼å¼
{"prompt": "æç¤º", "chosen": "æ›´å¥½çš„å›ç­”", "rejected": "è¾ƒå·®çš„å›ç­”"}
```

## ğŸ“š æ–‡æ¡£èµ„æº

### å®ç”¨æŒ‡å—
- [Macä¼˜åŒ–æŒ‡å—](README_MAC_OPTIMIZED.md) - Macè®¾å¤‡è®­ç»ƒå®Œæ•´æŒ‡å—
- [å¼€å‘ç¬”è®°](CLAUDE.md) - é¡¹ç›®å¼€å‘è¿‡ç¨‹ä¸æ€è€ƒè®°å½•
- [é¡¹ç›®ç»“æ„è¯´æ˜](PROJECT_STRUCTURE.md) - é¡¹ç›®æ–‡ä»¶ç»„ç»‡å’Œæ¨¡å—è¯´æ˜

## ğŸ” æ€§èƒ½å¯¹æ¯”

| é…ç½® | å‚æ•°é‡ | å†…å­˜éœ€æ±‚ | è®­ç»ƒæ—¶é—´ | æ¨èç”¨é€” |
|------|--------|----------|----------|----------|
| Tiny | ~13K | ~0.2MB | 10-20åˆ†é’Ÿ | å¿«é€ŸéªŒè¯/Macä¼˜åŒ– |
| Small | ~66K | ~0.8MB | 30-45åˆ†é’Ÿ | å­¦ä¹ ç ”ç©¶/å°è§„æ¨¡å®éªŒ |
| Medium | ~2.5M | ~30MB | 2-4å°æ—¶ | ä¸­ç­‰è§„æ¨¡è®­ç»ƒ |
| Large | ~25M | ~300MB | æ•°å°æ—¶ | å®Œæ•´æ¨¡å‹è®­ç»ƒ |

## ğŸ§ª æµ‹è¯•å’Œè¯„ä¼°

### è¿è¡Œæµ‹è¯•

```bash
# æ¨¡å‹ç»“æ„æµ‹è¯•
python tests/test_correct_small.py

# ä¸­ç­‰æ¨¡å‹æµ‹è¯•
python tests/test_medium_model.py

# æ¨¡å‹æ£€æŸ¥
python tests/inspect_model.py
```

### æ€§èƒ½è¯„ä¼°

```bash
# ç”Ÿæˆè´¨é‡è¯„ä¼°
python scripts/evaluate.py --model checkpoints/model.pt --dataset test

# æ€§èƒ½åŸºå‡†æµ‹è¯•
python calculate_model_comparison.py
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

### å¼€å‘ç¯å¢ƒè®¾ç½®

```bash
# 1. Forkå¹¶å…‹éš†ä»“åº“
git clone https://github.com/your-username/minigpt-training.git

# 2. åˆ›å»ºå¼€å‘åˆ†æ”¯
git checkout -b feature/your-feature

# 3. å®‰è£…å¼€å‘ä¾èµ–
pip install -e ".[dev]"

# 4. è¿è¡Œæµ‹è¯•
python -m pytest tests/
```

### æäº¤è§„èŒƒ

```bash
# æäº¤ä¿¡æ¯æ ¼å¼
git commit -m "feat: æ·»åŠ æ–°åŠŸèƒ½"
git commit -m "fix: ä¿®å¤bug"
git commit -m "docs: æ›´æ–°æ–‡æ¡£"
```

### è´¡çŒ®ç±»å‹

- ğŸ› **Bugä¿®å¤**: ä¿®å¤å·²çŸ¥é—®é¢˜
- âœ¨ **æ–°åŠŸèƒ½**: æ·»åŠ æ–°çš„è®­ç»ƒæ–¹æ³•æˆ–å·¥å…·
- ğŸ“š **æ–‡æ¡£**: æ”¹è¿›æ–‡æ¡£å’Œç¤ºä¾‹
- ğŸ¨ **ä¼˜åŒ–**: æ€§èƒ½ä¼˜åŒ–å’Œä»£ç é‡æ„
- ğŸ§ª **æµ‹è¯•**: æ·»åŠ æˆ–æ”¹è¿›æµ‹è¯•ç”¨ä¾‹

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ [MIT License](LICENSE) å¼€æºåè®®ã€‚

## ğŸ™ è‡´è°¢

æ„Ÿè°¢æ‰€æœ‰ä¸ºæ­¤é¡¹ç›®åšå‡ºè´¡çŒ®çš„å¼€å‘è€…å’Œç ”ç©¶è€…ã€‚

## ğŸ“ æ”¯æŒä¸åé¦ˆ

- **é—®é¢˜åé¦ˆ**: [GitHub Issues](https://github.com/your-repo/minigpt-training/issues)
- **åŠŸèƒ½å»ºè®®**: [GitHub Discussions](https://github.com/your-repo/minigpt-training/discussions)
- **æ–‡æ¡£é—®é¢˜**: æŸ¥çœ‹ [docs/](docs/) ç›®å½•æˆ–æäº¤Issue

---

<div align="center">

**â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ªStaræ”¯æŒä¸€ä¸‹ï¼ â­**

</div> 